<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>徐建峰的博客</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2021-04-05T10:04:03.478Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>徐建峰</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>CAP定理</title>
    <link href="http://example.com/2021/04/05/%E5%88%86%E5%B8%83%E5%BC%8F/CAP/"/>
    <id>http://example.com/2021/04/05/%E5%88%86%E5%B8%83%E5%BC%8F/CAP/</id>
    <published>2021-04-05T09:52:56.000Z</published>
    <updated>2021-04-05T10:04:03.478Z</updated>
    
    <content type="html"><![CDATA[<p>分布式系统的最大难点，就是各个节点的状态如何同步。</p><p>CAP 定理是这方面的基本定理，也是理解分布式系统的起点。</p><h2 id="一、分布式系统的三个指标"><a href="#一、分布式系统的三个指标" class="headerlink" title="一、分布式系统的三个指标"></a>一、分布式系统的三个指标</h2><img src="/2021/04/05/%E5%88%86%E5%B8%83%E5%BC%8F/CAP/image-20210405175903359.png" class="" title="image-20210405175903359"><blockquote><ul><li>Consistency  一致性</li><li>Availability  可用性</li><li>Partition tolerance  分区容错</li></ul><p>这三个指标不可能同时做到。这个结论就叫做 CAP 定理。</p></blockquote><h2 id="二、Partition-tolerance"><a href="#二、Partition-tolerance" class="headerlink" title="二、Partition tolerance"></a>二、Partition tolerance</h2><p>大多数分布式系统都分布在多个子网络。每个子网络就叫做一个区（partition）。分区容错的意思是，区间通信可能失败。比如，一台服务器放在中国，另一台服务器放在美国，这就是两个区，它们之间可能无法通信。</p><img src="/2021/04/05/%E5%88%86%E5%B8%83%E5%BC%8F/CAP/image-20210405175847147.png" class="" title="image-20210405175847147"><p>上图中，G1 和 G2 是两台跨区的服务器。G1 向 G2 发送一条消息，G2 可能无法收到。系统设计的时候，必须考虑到这种情况。</p><p>一般来说，分区容错无法避免，因此可以认为 CAP 的 P 总是成立。CAP 定理告诉我们，剩下的 C 和 A 无法同时做到。</p><h2 id="三、Consistency"><a href="#三、Consistency" class="headerlink" title="三、Consistency"></a>三、Consistency</h2><p>举例来说，某条记录是 v0，用户向 G1 发起一个写操作，将其改为 v1。</p><img src="/2021/04/05/%E5%88%86%E5%B8%83%E5%BC%8F/CAP/image-20210405175832086.png" class="" title="image-20210405175832086"><p>接下来，用户的读操作就会得到 v1。这就叫一致性。</p><img src="/2021/04/05/%E5%88%86%E5%B8%83%E5%BC%8F/CAP/image-20210405175948520.png" class="" title="image-20210405175948520"><p>问题是，用户有可能向 G2 发起读操作，由于 G2 的值没有发生变化，因此返回的是 v0。G1 和 G2 读操作的结果不一致，这就不满足一致性了。</p><img src="/2021/04/05/%E5%88%86%E5%B8%83%E5%BC%8F/CAP/image-20210405180011013.png" class="" title="image-20210405180011013"><p>为了让 G2 也能变为 v1，就要在 G1 写操作的时候，让 G1 向 G2 发送一条消息，要求 G2 也改成 v1。</p><img src="/2021/04/05/%E5%88%86%E5%B8%83%E5%BC%8F/CAP/image-20210405180026995.png" class="" title="image-20210405180026995"><p>这样的话，用户向 G2 发起读操作，也能得到 v1。</p><img src="/2021/04/05/%E5%88%86%E5%B8%83%E5%BC%8F/CAP/image-20210405180038257.png" class="" title="image-20210405180038257"><h2 id="四、Availability"><a href="#四、Availability" class="headerlink" title="四、Availability"></a>四、Availability</h2><p>用户可以选择向 G1 或 G2 发起读操作。不管是哪台服务器，只要收到请求，就必须告诉用户，到底是 v0 还是 v1，否则就不满足可用性。</p><h2 id="五、Consistency-和-Availability-的矛盾"><a href="#五、Consistency-和-Availability-的矛盾" class="headerlink" title="五、Consistency 和 Availability 的矛盾"></a>五、Consistency 和 Availability 的矛盾</h2><p>一致性和可用性，为什么不可能同时成立？答案很简单，因为可能通信失败（即出现分区容错）。</p><p>如果保证 G2 的一致性，那么 G1 必须在写操作时，锁定 G2 的读操作和写操作。只有数据同步后，才能重新开放读写。锁定期间，G2 不能读写，没有可用性不。</p><p>如果保证 G2 的可用性，那么势必不能锁定 G2，所以一致性不成立。</p><p>综上所述，G2 无法同时做到一致性和可用性。系统设计时只能选择一个目标。如果追求一致性，那么无法保证所有节点的可用性；如果追求所有节点的可用性，那就没法做到一致性。</p><blockquote><p><strong>读者问，在什么场合，可用性高于一致性？</strong></p><p>举例来说，发布一张网页到 CDN，多个服务器有这张网页的副本。后来发现一个错误，需要更新网页，这时只能每个服务器都更新一遍。</p><p>一般来说，网页的更新不是特别强调一致性。短时期内，一些用户拿到老版本，另一些用户拿到新版本，问题不会特别大。当然，所有人最终都会看到新版本。所以，这个场合就是可用性高于一致性。</p></blockquote><p>原文：<a href="http://www.ruanyifeng.com/blog/2018/07/cap.html">http://www.ruanyifeng.com/blog/2018/07/cap.html</a></p>]]></content>
    
    
    <summary type="html">分布式系统的CAP定理</summary>
    
    
    
    <category term="分布式" scheme="http://example.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="CAP" scheme="http://example.com/tags/CAP/"/>
    
    <category term="分布式" scheme="http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>01、基础架构：一条SQL查询语句是如何执行的</title>
    <link href="http://example.com/2021/04/04/MySQL/01/"/>
    <id>http://example.com/2021/04/04/MySQL/01/</id>
    <published>2021-04-04T14:13:56.000Z</published>
    <updated>2021-04-04T16:59:07.988Z</updated>
    
    <content type="html"><![CDATA[<p>有个最简单的表，表里只有一个ID字段，在执行下面这个查询语句时：</p><p><code>mysql&gt; select * from T where ID=10；</code></p><p> MySQL的基本架构示意图，可以清楚地看到SQL语句在MySQL的各个功能模块中的执行过程。</p><img src="image-20210127222256017.png" alt="image-20210127222256017"  /><p>MySQL可以分为 <strong>Server层</strong> 和 <strong>存储引擎层</strong> 两部分。</p><ol><li>Server层包括 <strong>连接器</strong>、<strong>查询缓存</strong>、<strong>分析器</strong>、<strong>优化器</strong>、<strong>执行器</strong>等，涵盖MySQL的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），<strong>所有跨存储引擎的功能都在这一层实现</strong>，比如存储过程、触发器、视图等。</li><li><strong>存储引擎层负责数据的存储和提取</strong>。其架构模式是插件式的，支持<code>InnoDB</code>、MyISAM、Memory等多个存储引擎。现在最常用的存储引擎是 InnoDB，它从MySQL 5.5.5版本开始成为了默认存储引擎。不同的存储引擎共用一个<strong>Server层</strong>，也就是从连接器到执行器的部分。</li></ol><h2 id="连接器"><a href="#连接器" class="headerlink" title="连接器"></a>连接器</h2><p>第一步，你会先连接到这个数据库上，这时候接待你的就是连接器。连接器负责跟客户端<strong>建立连接</strong>、<strong>获取权限</strong>、<strong>维持和管理连接</strong>。</p><p>连接命令一般是这么写的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql -h$ip -P$port -u$user -p</span><br></pre></td></tr></table></figure><p>输完命令之后，你就需要在交互对话里面输入密码。虽然密码也可以直接跟在-p后面写在命令行中，但这样可能会导致你的密码泄露。如果你连的是生产服务器，强烈建议你不要这么做。</p><p>连接命令中的mysql是客户端工具，用来跟服务端建立连接。在完成经典的TCP握手后，连接器就要开始认证你的身份，这个时候用的就是你输入的用户名和密码。</p><ul><li>如果用户名或密码不对，你就会收到一个”Access denied for user”的错误，然后客户端程序结束执行。</li><li>如果用户名密码认证通过，<strong>连接器会到权限表里面查出你拥有的权限</strong>。之后，这个连接里面的权限判断逻辑，都将依赖于此时读到的权限。</li></ul><p>这就意味着，一个用户成功建立连接后，即使你用管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限。修改完成后，<strong>只有再新建的连接才会使用新的权限设置</strong>。</p><p>连接完成后，如果你没有后续的动作，这个连接就处于空闲状态，你可以在 <code>show processlist</code> 命令中看到它。</p><p>文本中这个图是 <code>show pocesslist</code> 的结果，其中的<code>Command</code>列显示为“<strong>Sleep</strong>”的这一行，就表示现在系统里面有一个空闲连接。</p><img src="image-20210127222851964.png" alt="image-20210127222851964"  /><p>客户端如果太长时间没动静，连接器就会自动将它断开。这个时间是由参数 <strong>wait_timeout</strong> 控制的，默认值是8小时。</p><p>如果在连接被断开之后，客户端再次发送请求的话，就会收到一个错误提醒： <code>Lost connection to MySQL server during query</code>。这时候如果你要继续，就需要重连，然后再执行请求了。</p><p>数据库里面，<strong>长连接</strong>是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。<strong>短连接</strong>则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。建立连接的过程通常是比较复杂的，所以我建议你在使用中要尽量减少建立连接的动作，也就是<strong>尽量使用长连接</strong>。</p><p>但是全部使用长连接后，你可能会发现，有些时候MySQL占用内存涨得特别快，这是因为 <strong>MySQL在执行过程中临时使用的内存是管理在连接对象里面的</strong>。这些资源会在连接断开的时候才释放。所以如果长连接累积下来，可能导致内存占用太大，被系统强行杀掉（OOM），从现象看就是MySQL异常重启了。</p><p>  怎么解决这个问题呢？你可以考虑以下两种方案。</p><ol><li><strong>定期断开长连接</strong>。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。</li><li>如果你用的是MySQL 5.7或更新版本，可以在每次执行一个比较大的操作后，通过执行 <code>mysql_reset_connection</code>来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。</li></ol><h2 id="查询缓存"><a href="#查询缓存" class="headerlink" title="查询缓存"></a>查询缓存</h2><p>MySQL拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以key-value对的形式，被直接缓存在内存中。key是查询的语句，value是查询的结果。如果你的查询能够直接在这个缓存中找到key，那么这个value就会被直接返回给客户端。</p><p>如果语句不在查询缓存中，就会继续后面的执行阶段。执行完成后，执行结果会被存入查询缓存中。你可以看到，如果查询命中缓存，MySQL不需要执行后面的复杂操作，就可以直接返回结果，这个效率会很高。</p><p><strong>建议你不要使用查询缓存</strong>，为什么呢？<strong>因为查询缓存往往弊大于利。</strong>查询缓存的<strong>失效非常频繁</strong>，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。因此很可能你费劲地把结果存起来，还没使用呢，就被一个更新全清空了。        </p><p>对于更新压力大的数据库来说，查询缓存的命中率会非常低。除非你的业务就是有一张静态表，很长时间才会更新一次。比如，一个系统配置表，那这张表上的查询才适合使用查询缓存。</p><p>MySQL 8.0版本直接将查询缓存的整块功能删掉了，也就是说8.0开始彻底没有这个功能了。</p><h2 id="分析器"><a href="#分析器" class="headerlink" title="分析器"></a>分析器</h2><p> <strong>词法分析</strong> : 你输入的是由多个字符串和空格组成的一条SQL语句，MySQL需要识别出里面的字符串分别是什么，代表什么。MySQL从你输入的”select”这个关键字识别出来，这是一个查询语句。它也要把字符串“T”识别成“表名T”，把字符串“ID”识别成“列ID”。</p><p> <strong>语法分析</strong>： 根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个SQL语句是否满足MySQL语法。如果你的语句不对，就会收到 <code>You have an error in your SQL syntax</code> 的错误提醒，比如下面这个语句select少打了开头的字母“s”。一般语法错误会提示第一个出现错误的位置，所以你要关注的是紧接“use near”的内容。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; elect * from t where ID&#x3D;1;</span><br><span class="line"></span><br><span class="line">ERROR 1064 (42000): You have an error in your SQL syntax; </span><br><span class="line">check the manual that corresponds to your MySQL server version </span><br><span class="line">for the right syntax to use near &#39;elect * from t where ID&#x3D;1&#39; at line 1</span><br></pre></td></tr></table></figure><h2 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h2><p>经过了分析器，MySQL就知道你要做什么了。在开始执行之前，还要先经过优化器的处理。</p><p>优化器是在表里面有多个索引的时候，<strong>决定使用哪个索引</strong>；或者在一个语句有多表关联（join）的时候，<strong>决定各个表的连接顺序</strong>。</p><p>比如你执行下面这样的语句，这个语句是执行两个表的join：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t1 <span class="keyword">join</span> t2 <span class="keyword">using</span>(ID) <span class="keyword">where</span> t1.c<span class="operator">=</span><span class="number">10</span> <span class="keyword">and</span> t2.d<span class="operator">=</span><span class="number">20</span>;</span><br></pre></td></tr></table></figure><ul><li>既可以先从表t1里面取出c=10的记录的ID值，再根据ID值关联到表t2，再判断t2里面d的值是否等于20。</li><li>也可以先从表t2里面取出d=20的记录的ID值，再根据ID值关联到t1，再判断t1里面c的值是否等于10。</li></ul><p>这两种执行方法的逻辑结果是一样的，但是执行的效率会有不同，而优化器的作用就是决定选择使用哪一个方案。优化器阶段完成后，这个语句的执行方案就确定下来了，然后进入执行器阶段。</p><h2 id="执行器"><a href="#执行器" class="headerlink" title="执行器"></a>执行器</h2><p>开始执行的时候，要先判断一下你对这个表T有没有执行查询的<strong>权限</strong>，如果没有，就会返回没有权限的错误，如下所示</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> T <span class="keyword">where</span> ID<span class="operator">=</span><span class="number">10</span>; </span><br><span class="line">ERROR <span class="number">1142</span> (<span class="number">42000</span>): <span class="keyword">SELECT</span> command denied <span class="keyword">to</span> <span class="keyword">user</span> <span class="string">&#x27;b&#x27;</span>@<span class="string">&#x27;localhost&#x27;</span> <span class="keyword">for</span> <span class="keyword">table</span> <span class="string">&#x27;T&#x27;</span></span><br></pre></td></tr></table></figure><p>如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。</p><p>比如我们这个例子中的表T中，ID字段没有索引，那么执行器的执行流程是这样的：</p><ol><li>调用InnoDB引擎接口取这个表的第一行，判断ID值是不是10，如果不是则跳过，如果是则将这行存在结果集中；</li><li>调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。</li><li>执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。</li></ol><p>对于有索引的表，执行的逻辑也差不多。第一次调用的是“<strong>取满足条件的第一行</strong>”这个接口，之后循环取“<strong>满足条件的下一行</strong>”这个接口，这些接口都是引擎中已经定义好的。</p><p>你会在数据库的慢查询日志中看到一个 <code>rows_examined</code> 的字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此<strong>引擎扫描行数跟rows_examined并不是完全相同的。</strong></p><h2 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a>思考题</h2><p>如果表T中没有字段k，而你执行了这个语句 select * from T where k=1, 那肯定是会报“不存在这个列”的错误： “Unknown column ‘k’ in ‘where clause’”。</p><p>你觉得这个错误是在我们上面提到的哪个阶段报出来的呢？</p>]]></content>
    
    
    <summary type="html">MySQL</summary>
    
    
    
    <category term="MySQL实战" scheme="http://example.com/categories/MySQL%E5%AE%9E%E6%88%98/"/>
    
    
    <category term="MySQL" scheme="http://example.com/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>02、日志系统：一条SQL更新语句是如何执行的</title>
    <link href="http://example.com/2021/04/04/MySQL/02/"/>
    <id>http://example.com/2021/04/04/MySQL/02/</id>
    <published>2021-04-04T14:13:56.000Z</published>
    <updated>2021-04-04T16:59:32.789Z</updated>
    
    <content type="html"><![CDATA[<p>一个表有一个主键ID和一个整型字段c：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> T(ID <span class="type">int</span> <span class="keyword">primary</span> key, c <span class="type">int</span>);</span><br></pre></td></tr></table></figure><p>如果要将ID=2这一行的值加1，SQL语句就会这么写：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">update T <span class="keyword">set</span> c<span class="operator">=</span>c<span class="operator">+</span><span class="number">1</span> <span class="keyword">where</span> ID<span class="operator">=</span><span class="number">2</span>;</span><br></pre></td></tr></table></figure><ul><li><p>分析器会通过词法和语法解析知道这是一条更新语句。</p></li><li><p>优化器决定要使用ID这个索引。</p></li><li><p>执行器负责具体执行，找到这一行，然后更新。</p><p>与查询流程不一样的是，更新流程还涉及两个重要的日志模块，它们正是我们今天要讨论的主角：<code>redo log</code>（重做日志）和 <code>binlog</code>（归档日志）。</p></li></ul><h2 id="redo-log"><a href="#redo-log" class="headerlink" title="redo log"></a>redo log</h2><p>酒店掌柜有一个粉板，专门用来记录客人的赊账记录。如果赊账的人不多，那么他可以把顾客名和账目写在板上。但如果赊账的人多了，粉板总会有记不下的时候，这个时候掌柜一定还有一个专门记录赊账的账本。</p><p>  如果有人要赊账或者还账的话，掌柜一般有两种做法：</p><ul><li>一种做法是直接把账本翻出来，把这次赊的账加上去或者扣除掉；</li><li>另一种做法是先在粉板上记下这次的账，等打烊以后再把账本翻出来核算。</li></ul><p>在生意红火柜台很忙时，掌柜一定会选择后者，因为前者操作实在是太麻烦了。首先，你得找到这个人的赊账总额那条记录。你想想，密密麻麻几十页，掌柜要找到那个名字，可能还得带上老花镜慢慢找，找到之后再拿出算盘计算，最后再将结果写回到账本上。</p><p>这整个过程想想都麻烦。相比之下，还是先在粉板上记一下方便。你想想，如果掌柜没有粉板的帮助，每次记账都得翻账本，效率是不是低得让人难以忍受？</p><p>同样，在MySQL里也有这个问题，如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程IO成本、查找成本都很高。为了解决这个问题，MySQL的设计者就用了类似酒店掌柜粉板的思路来提升更新效率。</p><p>而粉板和账本配合的整个过程，其实就是MySQL里经常说到的WAL技术，WAL的全称是 <code>Write-Ahead Logging</code>，它的关键点就是先写日志，再写磁盘，也就是先写粉板，等不忙的时候再写账本。</p><p>具体来说，当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log（粉板）里面，并更新内存，这个时候更新就算完成了。同时，InnoDB引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做，这就像打烊以后掌柜做的事。</p><p>如果今天赊账的不多，掌柜可以等打烊后再整理。但如果某天赊账的特别多，粉板写满了，又怎么办呢？这个时候掌柜只好放下手中的活儿，把粉板中的一部分赊账记录更新到账本中，然后把这些记录从粉板上擦掉，为记新账腾出空间。</p><p>与此类似，InnoDB的 <strong>redo log是固定大小的</strong>，比如可以配置为一组4个文件，每个文件的大小是1GB，那么这块“粉板”总共就可以记录4GB的操作。从头开始写，写到末尾就又回到开头循环写，如下面这个图所示。</p><img src="image-20210127232029725.png" alt="image-20210127232029725" style="zoom:67%;" /><p><code>write pos</code> 是当前记录的位置，一边写一边后移，写到第3号文件末尾后就回到0号文件开头。</p><p><code>checkpoint </code>是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。</p><p> <code>write pos </code> 和 <code>checkpoint</code> 之间的是“粉板”上还空着的部分，可以用来记录新的操作。如果 <strong>write pos</strong>追上<strong>checkpoint</strong>，表示“粉板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把checkpoint推进一下。</p><p> 有了redo log，InnoDB就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为 <strong>crash-safe</strong>。要理解crash-safe这个概念，可以想想我们前面赊账记录的例子。只要赊账记录记在了粉板上或写在了账本上，之后即使掌柜忘记了，比如突然停业几天，恢复生意后依然可以通过账本和粉板上的数据明确赊账账目。</p><h2 id="binlog"><a href="#binlog" class="headerlink" title="binlog"></a>binlog</h2><p>前面我们讲过，MySQL整体来看，其实就有两块：</p><ul><li>  一块是Server层，它主要做的是MySQL功能层面的事情；</li><li>  一块是引擎层，负责存储相关的具体事宜。</li></ul><p>上面我们聊到的粉板 <code>redo log</code> 是 <code>InnoDB</code> 引擎特有的日志，而 <code>Server</code> 层也有自己的日志，称为<code>binlog</code>（<strong>归档日志</strong>）</p><blockquote><p>这两种日志有以下三点不同</p><ol><li>redo log 是 <strong>InnoDB 引擎</strong>特有的；binlog 是 MySQL 的 <strong>Server</strong> 层实现的，所有引擎都可以使用。</li><li>redo log 是<strong>物理日志</strong>，记录的是“在某个数据页上做了什么修改”；binlog 是<strong>逻辑日志</strong>，记录的是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1 ”。</li><li>redo log是<strong>循环</strong>写的，空间固定会用完；binlog是可以<strong>追加</strong>写入的。“追加写”是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。</li></ol></blockquote><h2 id="内部流程"><a href="#内部流程" class="headerlink" title="内部流程"></a>内部流程</h2><p> <strong>执行器</strong> 和 **InnoDB 引擎 **在执行 update 语句时的内部流程</p><ol><li>执行器先找引擎取ID=2这一行。ID是主键，引擎直接用 <strong>树搜索</strong> 找到这一行。如果ID=2这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。</li><li>执行器拿到引擎给的行数据，把这个值加上1，比如原来是N，现在就是N+1，得到新的一行数据，再调用引擎接口写入这行新数据。</li><li>引擎将这行新数据<strong>更新到内存</strong>中，同时将这个更新操作记录到 <strong>redo log</strong>里面，此时 redo log 处于 <code>prepare</code> 状态。然后告知执行器执行完成了，随时可以提交事务。</li><li>执行器生成这个操作的 binlog，并把 binlog 写入磁盘。</li><li>执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。</li></ol><p>  这里我给出这个update语句的执行流程图，图中浅色框表示是在InnoDB内部执行的，深色框表示是在执行器中执行的。</p><img src="image-20210130171513330.png" alt="image-20210130171513330" style="zoom:67%;" /><h2 id="两阶段提交"><a href="#两阶段提交" class="headerlink" title="两阶段提交"></a><strong>两阶段提交</strong></h2><blockquote><p><strong>两阶段提交，为了让两份日志之间的逻辑一致</strong></p></blockquote><p><strong>怎样让数据库恢复到半个月内任意一秒的状态？</strong></p><p>前面我们说过了，binlog会记录所有的逻辑操作，并且是采用“追加写”的形式。如果你的DBA承诺说半个月内可以恢复，那么备份系统中一定会保存最近半个月的所有 binlog，同时系统会定期做 <strong>整库备份</strong>。这里的“定期”取决于系统的重要性，可以是一天一备，也可以是一周一备。</p><blockquote><p>  当需要恢复到指定的某一秒时，比如某天下午两点发现中午十二点有一次误删表，需要找回数据，那你可以这么做：</p><ul><li>首先，找到最近的一次全量备份，如果你运气好，可能就是昨天晚上的一个备份，从这个备份恢复到临时库</li><li>然后，从备份的时间点开始，将备份的binlog依次取出来，重放到中午误删表之前的那个时刻。</li></ul><p> 这样你的临时库就跟误删之前的线上库一样了，然后你可以把表数据从临时库取出来，按需要恢复到线上库去。</p></blockquote><p><strong>为什么日志需要“两阶段提交”？</strong></p><p>用反证法来进行解释，由于redo log和binlog是两个独立的逻辑，如果不用两阶段提交，要么就是先写完redo log再写binlog，或者采用反过来的顺序。我们看看这两种方式会有什么问题。</p><p>仍然用前面的update语句来做例子。假设当前ID=2的行，字段c的值是0，再假设执行update语句过程中在写完第一个日志后，第二个日志还没有写完期间发生了crash，会出现什么情况呢？</p><ol><li><strong>先写redo log后写binlog</strong>。假设在redo log写完，binlog还没有写完的时候，MySQL进程异常重启。由于我们前面说过的，redo log写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行c的值是1。但是由于binlog没写完就crash了，这时候binlog里面就没有记录这个语句。因此，之后备份日志的时候，存起来的binlog里面就没有这条语句。然后你会发现，如果需要用这个binlog来恢复临时库的话，由于这个语句的binlog丢失，这个临时库就会少了这一次更新，恢复出来的这一行c的值就是0，与原库的值不同。</li><li><strong>先写binlog后写redo log</strong>。如果在binlog写完之后crash，由于redo log还没写，崩溃恢复以后这个事务无效，所以这一行c的值是0。但是binlog里面已经记录了“把c从0改成1”这个日志。所以，在之后用binlog来恢复的时候就多了一个事务出来，恢复出来的这一行c的值就是1，与原库的值不同。</li></ol><p>  可以看到，<strong>如果不使用“两阶段提交”，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致</strong>。</p><p>  这个概率是不是很低，平时也没有什么动不动就需要恢复临时库的场景呀？其实不是的，不只是误操作后需要用这个过程来恢复数据。当你需要扩容的时候，也就是需要再多搭建一些备库来增加系统的读能力的时候，现在常见的做法也是用全量备份加上应用binlog来实现的，这个“不一致”就会导致你的线上出现主从数据库不一致的情况。</p><p>  简单说，redo log和binlog都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。</p><h2 id="如何用两阶段提交保证两份日志的一致"><a href="#如何用两阶段提交保证两份日志的一致" class="headerlink" title="如何用两阶段提交保证两份日志的一致"></a>如何用两阶段提交保证两份日志的一致</h2><p>1 写入 redo log，prepare阶段 </p><p>2 写binlog </p><p>3 commit</p><p>当在2之前崩溃时，重启恢复：后发现没有commit，回滚。</p><p>当在3之前崩溃，重启恢复：虽没有commit，但满足prepare和binlog完整，所以重启后会自动commit。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><strong>小结</strong></h2><p><strong>redo log 用于保证 crash-safe 能力</strong></p><p><code>innodb_flush_log_at_trx_commit</code> 这个参数设置成<strong>1</strong>的时候，表示每次事务的redo log都直接持久化到磁盘。这个参数我建议你设置成1，这样可以保证MySQL异常重启之后数据不丢失。</p><p><code>sync_binlog</code> 这个参数设置成1的时候，表示每次事务的binlog都持久化到磁盘。这个参数我也建议你设置成1，这样可以保证MySQL异常重启之后binlog不丢失。</p><p><strong>两阶段提交是跨系统维持数据逻辑一致性时常用的一个方案</strong>，即使你不做数据库内核开发，日常开发中也有可能会用到。</p><h2 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a><strong>思考题</strong></h2><p>前面我说到定期全量备份的周期“取决于系统重要性，有的是一天一备，有的是一周一备”。那么在什么场景下，一天一备会比一周一备更有优势呢？或者说，它影响了这个数据库系统的哪个指标？</p><p>好处是“最长恢复时间”更短。</p><p>在一天一备的模式里，最坏情况下需要应用一天的binlog。比如，你每天0点做一次全量备份，而要恢复出一个到昨天晚上23点的备份。</p><p>一周一备最坏情况就要应用一周的binlog了。</p><p>系统的对应指标就是 RTO（恢复目标时间）</p><p>当然这个是有成本的，因为更频繁全量备份需要消耗更多存储空间，所以这个RTO是成本换来的，就需要你根据业务重要性来评估了。</p>]]></content>
    
    
    <summary type="html">MySQL</summary>
    
    
    
    <category term="MySQL实战" scheme="http://example.com/categories/MySQL%E5%AE%9E%E6%88%98/"/>
    
    
    <category term="MySQL" scheme="http://example.com/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>03、事务隔离：为什么你改了我还看不见</title>
    <link href="http://example.com/2021/04/04/MySQL/03/"/>
    <id>http://example.com/2021/04/04/MySQL/03/</id>
    <published>2021-04-04T14:13:56.000Z</published>
    <updated>2021-04-04T16:59:57.362Z</updated>
    
    <content type="html"><![CDATA[<p><strong>事务就是要保证一组数据库操作，要么全部成功，要么全部失败。</strong></p><p><strong>ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性）</strong></p><p>在MySQL中，**事务支持是在引擎层 **实现的。你现在知道，MySQL是一个支持多引擎的系统，但并不是所有的引擎都支持事务。比如MySQL原生的MyISAM引擎就不支持事务，这也是MyISAM被InnoDB取代的重要原因之一。</p><h2 id="隔离性与隔离级别"><a href="#隔离性与隔离级别" class="headerlink" title="隔离性与隔离级别"></a><strong>隔离性与隔离级别</strong></h2><p>当数据库上有多个事务同时执行的时候，就可能出现 <code>脏读（dirty read）</code>、<code>不可重复读（non-repeatable read）</code>、<code>幻读（phantom read）</code>的问题，为了解决这些问题，就有了“隔离级别”的概念。</p><p>在谈隔离级别之前，你首先要知道，你 <strong>隔离得越严实，效率就会越低</strong>，因此很多时候，我们都要在二者之间寻找一个 <strong>平衡点</strong>。</p><p>SQL标准的事务隔离级别包括：<code>读未提交（read uncommitted）</code>、<code>读提交（read committed）</code>、<code>可重复读（repeatable read）</code>和 <code>串行化（serializable ）</code></p><p>下面我逐一为你解释：</p><ul><li><strong>读未提交</strong>，一个事务还没提交时，它做的变更就能被别的事务看到。</li><li><strong>读提交</strong>，一个事务提交之后，它做的变更才会被其他事务看到。</li><li><strong>可重复读</strong>，一个事务执行过程中看到的数据，<strong>总是跟这个事务在启动时看到的数据是一致的</strong>。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。</li><li><strong>串行化</strong>，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。</li></ul><p>其中“读提交”和“可重复读”比较难理解，所以我用一个例子说明这几种隔离级别。</p><p>假设数据表T中只有一列，其中一行的值为1，下面是按照时间顺序执行两个事务的行为。</p><img src="clipboard-1611999674629.png" alt="img" style="zoom: 50%;" /><p>我们来看看在不同的隔离级别下，事务A会有哪些不同的返回结果，也就是图里面V1、V2、V3的返回值分别是什么。</p><ul><li>若隔离级别是“<strong>读未提交</strong>”， 则V1的值就是 <strong>2</strong>。这时候事务B虽然还没有提交，但是结果已经被A看到了。因此，V2、V3也都是2。</li><li>若隔离级别是“<strong>读提交</strong>”，则V1是 <strong>1</strong>，V2的值是 <strong>2</strong>。事务B的更新在提交后才能被A看到。所以， V3的值也是2。</li><li>若隔离级别是“<strong>可重复读</strong>”，则V1、V2是 <strong>1</strong>，V3是 <strong>2</strong>。之所以V2还是1，遵循的就是这个要求：事务在执行期间看到的数据前后必须是一致的。</li><li>若隔离级别是“<strong>串行化</strong>”，则在事务B执行“将1改成2”的时候，会被锁住。直到事务A提交后，事务B才可以继续执行。所以从A的角度看， V1、V2值是 <strong>1</strong>，V3的值是 <strong>2</strong>。</li></ul><p>在实现上，数据库里面会创建一个 <strong>视图</strong>，访问的时候以视图的逻辑结果为准。</p><ul><li>“<strong>读未提交</strong>”隔离级别下直接返回记录上的最新值，<strong>没有视图概念</strong></li><li>“<strong>读提交</strong>”隔离级别下，<strong>视图是在每个SQL语句开始执行的时候创建的</strong>。</li><li>“<strong>可重复读</strong>”隔离级别下，视图是在<strong>事务启动时创建的</strong>，整个事务存在期间都用这个视图。</li><li>“<strong>串行化</strong>”隔离级别下直接用<strong>加锁</strong>的方式来避免并行访问。</li></ul><p>Oracle数据库的默认隔离级别其实就是“<strong>读提交</strong>”，因此对于一些从Oracle迁移到MySQL的应用，为保证数据库隔离级别的一致，你一定要记得将MySQL的隔离级别设置为“读提交”。配置的方式是，将启动参数 <code>transaction-isolation</code> 的值设置成 <code>READ-COMMITTED</code></p><p>你可以用 <code>show variables</code> 来查看当前的值。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show variables like &#39;transaction_isolation&#39;;</span><br><span class="line">+-----------------------+----------------+</span><br><span class="line">| Variable_name         | Value          |</span><br><span class="line">+-----------------------+----------------+</span><br><span class="line">| transaction_isolation | READ-COMMITTED |</span><br><span class="line">+--</span><br></pre></td></tr></table></figure><p>总结来说，存在即合理，哪个隔离级别都有它自己的 <strong>使用场景</strong>，你要根据自己的 <strong>业务情况</strong> 来定。</p><p><strong>什么时候需要“可重复读”的场景呢？</strong></p><p>数据校对逻辑的案例。假设你在管理一个个人银行账户表。一个表存了每个月月底的余额，一个表存了账单明细。这时候你要做数据校对，也就是判断上个月的余额和当前余额的差额，是否与本月的账单明细一致。你一定希望在校对过程中，即使有用户发生了一笔新的交易，也不影响你的校对结果。这时候使用“可重复读”隔离级别就很方便。事务启动时的视图可以认为是静态的，不受其他事务更新的影响。</p><h2 id="事务隔离的实现"><a href="#事务隔离的实现" class="headerlink" title="事务隔离的实现"></a><strong>事务隔离的实现</strong></h2><p>理解了事务的隔离级别，我们再来看看事务隔离具体是怎么实现的。这里我们展开说明“可重复读”。</p><p>在MySQL中，实际上每条记录在更新的时候都会同时记录一条<strong>回滚操作</strong>。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。</p><p>假设一个值从1被按顺序改成了2、3、4，在回滚日志里面就会有类似下面的记录。</p><img src="image-20210130181158732.png" alt="image-20210130181158732" style="zoom:50%;" /><p>当前值是4，但是在查询这条记录的时候，不同时刻启动的事务会有不同的 <code>read-view</code>。</p><p>如图中看到的，在视图A、B、C里面，这一个记录的值分别是1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的<strong>多版本并发控制（MVCC）</strong>。</p><p>对于 <code>read-view A</code>，要得到1，就必须将当前值依次执行图中所有的回滚操作得到。同时你会发现，即使现在有另外一个事务正在将4改成5，这个事务跟read-view A、B、C对应的事务是不会冲突的。</p><p><strong>你一定会问，回滚日志总不能一直保留吧，什么时候删除呢？</strong></p><p>答案是，在不需要的时候才删除。也就是说，系统会判断，当没有事务再需要用到这些回滚日志时，回滚日志会被删除。</p><p><strong>什么时候才不需要了呢？</strong></p><p>就是当系统里没有比这个回滚日志更早的read-view的时候。</p><p> <strong>为什么建议你尽量不要使用长事务?</strong></p><p>长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。</p><p>在MySQL 5.5及以前的版本，回滚日志是跟数据字典一起放在ibdata文件里的，即使长事务最终提交，回滚段被清理，文件也不会变小。我见过数据只有20GB，而回滚段有200GB的库。最终只好为了清理回滚段，重建整个库。</p><p>除了对回滚段的影响，长事务还占用锁资源，也可能拖垮整个库，这个我们会在后面讲锁的时候展开。</p><h2 id="事务的启动方式"><a href="#事务的启动方式" class="headerlink" title="事务的启动方式"></a><strong>事务的启动方式</strong></h2><p>长事务有这些潜在风险，我当然是建议你尽量避免。其实很多时候业务开发同学并不是有意使用长事务，通常是由于误用所致。</p><blockquote><p>MySQL的事务启动方式有以下几种：</p><ol><li>显式启动事务语句， <code>begin</code> 或 <code>start transaction</code>。配套的提交语句是 <code>commit</code>，回滚语句是 <code>rollback</code>。</li><li><code>set autocommit=0</code>，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个select语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行commit 或 rollback 语句，或者断开连接。</li></ol></blockquote><p>有些客户端连接框架会默认连接成功后先执行一个 <code>set autocommit=0</code> 的命令。这就导致接下来的查询都在事务中，如果是长连接，就导致了意外的长事务。因此，我会建议你总是使用 <code>set autocommit=1</code> , 通过显式语句的方式来启动事务。</p><p>但是有的开发同学会纠结“多一次交互”的问题。对于一个需要频繁使用事务的业务，第二种方式每个事务在开始时都不需要主动执行一次 “begin”，减少了语句的交互次数。如果你也有这个顾虑，我建议你使用 <code>commit work and chain</code> 语法。</p><p>在autocommit为1的情况下，用begin显式启动的事务，如果执行commit则提交事务。如果执行 <code>commit work and chain</code>，则是提交事务并<strong>自动启动下一个事务</strong>，这样也省去了再次执行begin语句的开销。同时带来的好处是从程序开发的角度明确地知道每个语句是否处于事务中。</p><p>你可以在 <code>information_schema</code> 库的 <code>innodb_trx</code> 这个表中查询长事务，比如下面这个语句，用于查找持续时间超过60s的事务。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> information_schema.innodb_trx <span class="keyword">where</span> TIME_TO_SEC(timediff(now(),trx_started))<span class="operator">&gt;</span><span class="number">60</span> </span><br></pre></td></tr></table></figure><h2 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a><strong>思考题</strong></h2><p>你现在知道了系统里面应该避免长事务，如果你是业务开发负责人同时也是数据库负责人，你会有什么方案来避免出现或者处理这种情况呢？</p><p><strong>首先，从应用开发端来看：</strong></p><ol><li>确认是否使用了 <code>set autocommit=0</code>。这个确认工作可以在测试环境中开展，把MySQL的general_log开起来，然后随便跑一个业务逻辑，通过general_log的日志来确认。一般框架如果会设置这个值，也就会提供参数来控制行为，你的目标就是把它改成1。</li><li>确认是否有不必要的只读事务。有些框架会习惯不管什么语句先用begin/commit框起来。我见过有些是业务并没有这个需要，但是也把好几个select语句放到了事务中。这种只读事务可以去掉。</li><li>业务连接数据库的时候，根据业务本身的预估，通过 <code>SET MAX_EXECUTION_TIME</code> 命令，来控制每个语句执行的最长时间，避免单个语句意外执行太长时间。（为什么会意外？在后续的文章中会提到这类案例）</li></ol><p><strong>其次，从数据库端来看：</strong></p><ol><li>监控 <code>information_schema.Innodb_trx</code> 表，设置长事务阈值，超过就报警/或者kill；</li><li><code>Percona</code> 的 <code>pt-kill</code> 这个工具不错，推荐使用；</li><li>在业务功能测试阶段要求输出所有的 <code>general_log</code>，分析日志行为提前发现问题；</li><li>如果使用的是MySQL 5.6或者更新版本，把 <code>innodb_undo_tablespaces</code> 设置成2（或更大的值）。如果真的出现大事务导致回滚段过大，这样设置后清理起来更方便。</li></ol>]]></content>
    
    
    <summary type="html">MySQL</summary>
    
    
    
    <category term="MySQL实战" scheme="http://example.com/categories/MySQL%E5%AE%9E%E6%88%98/"/>
    
    
    <category term="MySQL" scheme="http://example.com/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>04、深入浅出索引（上）</title>
    <link href="http://example.com/2021/04/04/MySQL/04/"/>
    <id>http://example.com/2021/04/04/MySQL/04/</id>
    <published>2021-04-04T14:13:56.000Z</published>
    <updated>2021-04-04T17:00:03.479Z</updated>
    
    <content type="html"><![CDATA[<p><strong>索引的出现其实就是为了提高数据查询的效率，就像书的目录一样。</strong></p><h2 id="索引的常见模型"><a href="#索引的常见模型" class="headerlink" title="索引的常见模型"></a><strong>索引的常见模型</strong></h2><p>索引常用的数据结构，分别是哈希表、有序数组和搜索树。</p><p><strong>哈希表这种结构适用于只有等值查询的场景，做区间查询的速度是很慢的</strong></p><p><strong>有序数组在等值查询和范围查询场景中的性能就都非常优秀，但只适用于静态存储引擎</strong></p><p><strong>二叉树 <strong>是搜索效率最高的，但是实际上大多数的数据库存储却并不使用二叉树。其原因是，</strong>索引不止存在内存中，还要写到磁盘上</strong>。</p><blockquote><p>为什么不用二叉树要用N叉树？</p><p>一棵100万节点的平衡二叉树，树高20。一次查询可能需要访问20个数据块。在机械硬盘时代，从磁盘随机读一个数据块需要10 ms左右的寻址时间。也就是说，对于一个100万行的表，如果使用二叉树来存储，单独访问一个行可能需要20个10 ms的时间。</p><p>为了让一个查询<strong>尽量少地读磁盘</strong>，就必须让查询过程访问尽量少的数据块。那么，我们就不应该使用二叉树，而是要使用“N叉”树。这里，“N叉”树中的“N”取决于数据块的大小。</p></blockquote><p>以InnoDB的一个整数字段索引为例，这个N差不多是<strong>1200</strong>。这棵树高是4的时候，就可以存1200的3次方个值，这已经17亿了。考虑到<strong>树根的数据块总是在内存中</strong>的，一个10亿行的表上一个整数字段的索引，查找一个值最多只需要访问3次磁盘。其实，树的第二层也有很大概率在内存中，那么访问磁盘的平均次数就更少了。</p><p>N叉树由于在读写上的性能优点，以及适配磁盘的访问模式，已经被广泛应用在数据库引擎中了。不管是哈希还是有序数组，或者N叉树，它们都是不断迭代、不断优化的产物或者解决方案。数据库技术发展到今天，跳表、LSM树等数据结构也被用于引擎设计中</p><h2 id="InnoDB-的索引模型"><a href="#InnoDB-的索引模型" class="headerlink" title="InnoDB 的索引模型"></a><strong>InnoDB 的索引模型</strong></h2><p>在InnoDB中，表都是<strong>根据主键顺序以索引的形式存放的</strong>，这种存储方式的表称为<strong>索引组织表</strong>。</p><p>InnoDB 使用了 B+树索引模型，所以数据都是存储在B+树中的。每一个索引在InnoDB里面对应一棵B+树。</p><p>假设，我们有一个主键列为ID的表，表中有字段k，并且在k上有索引。</p><p>这个表的建表语句是：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> T(id <span class="type">int</span> <span class="keyword">primary</span> key,k <span class="type">int</span> <span class="keyword">not</span> <span class="keyword">null</span>,name <span class="type">varchar</span>(<span class="number">16</span>),index (k)) engine<span class="operator">=</span>InnoDB;</span><br></pre></td></tr></table></figure><p>表中 R1~R5 的(ID,k)值分别为(100,1)、(200,2)、(300,3)、(500,5)和(600,6)，两棵树的示例示意图如下。</p><img src="image-20210131205410176.png" alt="image-20210131205410176" style="zoom:67%;" /><p>根据叶子节点的内容，索引类型分为 <strong>主键索引</strong> 和 <strong>非主键索引</strong> </p><p><strong>主键索引的叶子节点存的是整行数据</strong>。在InnoDB里，主键索引也被称为<strong>聚簇索引（clustered index）</strong></p><p><strong>非主键索引的叶子节点内容是主键的值</strong>。在InnoDB里，非主键索引也被称为<strong>二级索引（secondary index）</strong></p><blockquote><p><strong>基于主键索引和普通索引的查询有什么区别？</strong></p><ul><li><p>如果语句是 <code>select * from T where ID=500</code>，即主键查询方式，则只需要搜索ID这棵B+树；</p></li><li><p>如果语句是 <code>select * from T where k=5</code>，即普通索引查询方式，则需要先搜索k索引树，得到ID的值为500，再到ID索引树搜索一次。这个过程称为 <strong>回表</strong></p></li></ul></blockquote><p>也就是说，基于非主键索引的查询需要多扫描一棵索引树。因此，我们在<strong>应用中应该尽量使用主键查询</strong>。</p><h2 id="索引维护"><a href="#索引维护" class="headerlink" title="索引维护"></a><strong>索引维护</strong></h2><p>B+树为了维护索引有序性，在插入新值的时候需要做必要的 <strong>维护</strong>。以上面这个图为例，如果插入新的行ID值为700，则只需要在R5的记录后面插入一个新记录。如果新插入的ID值为400，就相对麻烦了，需要逻辑上挪动后面的数据，空出位置。</p><p>而更糟的情况是，如果R5所在的<strong>数据页已经满了</strong>，根据B+树的算法，这时候需要<strong>申请一个新的数据页</strong>，然后挪动部分数据过去。这个过程称为 <strong>页分裂</strong>。在这种情况下，性能自然会受影响。除了性能外，页分裂操作还影响数据页的利用率。原本放在一个页的数据，现在分到两个页中，整体空间利用率降低大约50%。当然有分裂就有合并。当相邻两个页由于删除了数据，利用率很低之后，会将数据页做合并。合并的过程，可以认为是分裂过程的逆过程。</p><p>你可能在一些建表规范里面见到过类似的描述，要求建表语句里一定要有自增主键。当然事无绝对，我们来分析一下<strong>哪些场景下应该使用自增主键，而哪些场景下不应该?</strong></p><p>自增主键是指自增列上定义的主键，在建表语句中一般是这么定义的： <code>NOT NULL PRIMARY KEY AUTO_INCREMENT</code>。</p><p>插入新记录的时候可以不指定ID的值，系统会获取当前ID最大值加1作为下一条记录的ID值。也就是说，自增主键的插入数据模式，正符合了我们前面提到的递增插入的场景。每次插入一条新记录，都是追加操作，<strong>都不涉及到挪动其他记录，也不会触发叶子节点的分裂</strong>。而有业务逻辑的字段做主键，则往往不容易保证有序插入，这样写数据成本相对较高。</p><p>除了考虑性能外，我们还可以从存储空间的角度来看。假设你的表中确实有一个唯一字段，比如字符串类型的身份证号，那应该用身份证号做主键，还是用自增字段做主键呢？</p><p>由于每个非主键索引的叶子节点上都是主键的值。如果用身份证号做主键，那么每个二级索引的叶子节点占用约20个字节，而如果用整型做主键，则只要4个字节，如果是长整型（bigint）则是8个字节。</p><p><strong>显然，主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。</strong>所以，从性能和存储空间方面考量，<strong>自增主键往往是更合理的选择</strong>。</p><blockquote><p>什么场景适合用业务字段直接做主键的呢？</p><p>比如，有些业务的场景需求是这样的：</p><ol><li>只有一个索引；</li><li>该索引必须是唯一索引。</li></ol><p>这就是典型的KV场景。由于没有其他索引，所以也就不用考虑其他索引的叶子节点大小的问题。这时候我们就要优先考虑上一段提到的“尽量使用主键查询”原则，直接将这个索引设置为主键，可以避免每次查询需要搜索两棵树。</p></blockquote>]]></content>
    
    
    <summary type="html">MySQL</summary>
    
    
    
    <category term="MySQL实战" scheme="http://example.com/categories/MySQL%E5%AE%9E%E6%88%98/"/>
    
    
    <category term="MySQL" scheme="http://example.com/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>05、深入浅出索引（下）</title>
    <link href="http://example.com/2021/04/04/MySQL/05/"/>
    <id>http://example.com/2021/04/04/MySQL/05/</id>
    <published>2021-04-04T14:13:56.000Z</published>
    <updated>2021-04-04T17:00:34.468Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">create</span> <span class="keyword">table</span> T (</span><br><span class="line">    ID <span class="type">int</span> <span class="keyword">primary</span> key,</span><br><span class="line">    k <span class="type">int</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="number">0</span>, </span><br><span class="line">    s <span class="type">varchar</span>(<span class="number">16</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">DEFAULT</span> <span class="string">&#x27;&#x27;</span>,</span><br><span class="line">    index k(k))</span><br><span class="line">    engine<span class="operator">=</span>InnoDB;</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> T <span class="keyword">values</span>(<span class="number">100</span>,<span class="number">1</span>, <span class="string">&#x27;aa&#x27;</span>),</span><br><span class="line">         (<span class="number">200</span>,<span class="number">2</span>,<span class="string">&#x27;bb&#x27;</span>),</span><br><span class="line">        (<span class="number">300</span>,<span class="number">3</span>,<span class="string">&#x27;cc&#x27;</span>),</span><br><span class="line">        (<span class="number">500</span>,<span class="number">5</span>,<span class="string">&#x27;ee&#x27;</span>),</span><br><span class="line">        (<span class="number">600</span>,<span class="number">6</span>,<span class="string">&#x27;ff&#x27;</span>),</span><br><span class="line">        (<span class="number">700</span>,<span class="number">7</span>,<span class="string">&#x27;gg&#x27;</span>);</span><br></pre></td></tr></table></figure><img src="image-20210131225745498.png" alt="image-20210131225745498" style="zoom:60%;" /><p>上面这个表T中，如果我执行 <code>select * from T where k between 3 and 5</code>，需要执行几次树的搜索操作，会扫描多少行？</p><p> 这条SQL查询语句的执行流程：</p><ol><li>在k索引树上找到k=3的记录，取得 ID = 300；</li><li>再到ID索引树查到ID=300对应的R3；</li><li>在k索引树取下一个值k=5，取得ID=500；</li><li>再回到ID索引树查到ID=500对应的R4；</li><li>在k索引树取下一个值k=6，不满足条件，循环结束。</li></ol><p>在这个过程中，<strong>回到主键索引树搜索的过程，我们称为回表</strong>。可以看到，这个查询过程读了k索引树的3条记录（步骤1、3和5），回表了两次（步骤2和4）。</p><p>在这个例子中，由于查询结果所需要的数据只在主键索引上有，所以不得不回表。那么，有没有可能经过索引优化，避免回表过程呢？</p><h2 id="覆盖索引"><a href="#覆盖索引" class="headerlink" title="覆盖索引"></a><strong>覆盖索引</strong></h2><p>如果执行的语句是 <code>select ID from T where k between 3 and 5</code>，这时只需要查ID的值，而ID的值已经在k索引树上了，因此可以直接提供查询结果，不需要回表。也就是说，在这个查询里面，索引k已经“覆盖了”我们的查询需求，我们称为<strong>覆盖索引</strong>。</p><p><strong>由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。</strong></p><p>需要注意的是，在引擎内部使用覆盖索引在索引k上其实读了三个记录，R3~R5（对应的索引k上的记录项），但是对于MySQL的Server层来说，它就是找引擎拿到了两条记录，因此MySQL认为扫描行数是2。</p><p>基于上面覆盖索引的说明，我们来讨论一个问题：<strong>在一个市民信息表上，是否有必要将身份证号和名字建立联合索引？</strong></p><p>假设这个市民表的定义是这样的：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `tuser` (</span><br><span class="line">  `id` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `id_card` <span class="type">varchar</span>(<span class="number">32</span>) <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `name` <span class="type">varchar</span>(<span class="number">32</span>) <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `age` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `ismale` tinyint(<span class="number">1</span>) <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  <span class="keyword">PRIMARY</span> KEY (`id`),</span><br><span class="line">  KEY `id_card` (`id_card`),</span><br><span class="line">  KEY `name_id_card` (`name`,`id_card`)</span><br><span class="line">) ENGINE<span class="operator">=</span>InnoDB</span><br></pre></td></tr></table></figure><p>身份证号是市民的唯一标识。 如果有根据身份证号查询市民信息的需求，我们只要在身份证号字段上建立索引就够了。而再建立一个（身份证号、姓名）的联合索引，是不是浪费空间？</p><p>如果现在有一个高频请求，要根据市民的身份证号查询他的姓名，这个联合索引就有意义了。它可以在这个高频请求上用到覆盖索引，不再需要回表查整行记录，减少语句的执行时间。</p><p>当然，索引字段的维护总是有代价的。因此，在建立冗余索引来支持覆盖索引时就需要权衡考虑了。这正是业务DBA，或者称为业务数据架构师的工作。</p><h2 id="最左前缀原则"><a href="#最左前缀原则" class="headerlink" title="最左前缀原则"></a><strong>最左前缀原则</strong></h2><p>看到这里你一定有一个疑问，如果为每一种查询都设计一个索引，索引是不是太多了?</p><p>如果我现在要按照市民的身份证号去查他的家庭地址呢？虽然这个查询需求在业务中出现的概率不高，但总不能让它走全表扫描吧？反过来说，单独为一个不频繁的请求创建一个（身份证号，地址）的索引又感觉有点浪费。应该怎么做呢？这里，我先和你说结论吧。</p><p><strong>B+树这种索引结构，可以利用索引的“最左前缀”，来定位记录。</strong></p><p>为了直观地说明这个概念，我们用（name，age）这个联合索引来分析。</p><img src="clipboard-1612365696672.png" alt="img" style="zoom:37%;" /><p>可以看到，<strong>索引项是按照索引定义里面出现的字段顺序排序的</strong>。当你的逻辑需求是查到所有名字是“张三”的人时，可以快速定位到ID4，然后向后遍历得到所有需要的结果。</p><p>如果你要查的是所有名字第一个字是“张”的人，你的SQL语句的条件是”where name like ‘张%’”。这时，你也能够用上这个索引，查找到第一个符合条件的记录是ID3，然后向后遍历，直到不满足条件为止。</p><p>可以看到，不只是索引的全部定义，<strong>只要满足最左前缀，就可以利用索引来加速检索</strong>。这个最左前缀可以是联合索引的最左N个字段，也可以是字符串索引的最左M个字符。</p><p>基于上面对最左前缀索引的说明，我们来讨论一个问题：</p><p><strong>在建立联合索引的时候，如何安排索引内的字段顺序。</strong></p><p>这里我们的评估标准是，<strong>索引的复用能力</strong>。因为可以支持最左前缀，所以当已经有了(a,b)这个联合索引后，一般就不需要单独在a上建立索引了。因此，<strong>第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的</strong></p><p>所以现在你知道了，这段开头的问题里，我们要为高频请求创建(身份证号，姓名）这个联合索引，并用这个索引支持“根据身份证号查询地址”的需求。</p><p>那么，如果既有联合查询，又有基于a、b各自的查询呢？查询条件里面只有b的语句，是无法使用(a,b)这个联合索引的，这时候你不得不维护另外一个索引，也就是说你需要同时维护(a,b)、(b) 这两个索引。</p><p>这时候，我们要<strong>考虑的原则就是空间</strong>了。比如上面这个市民表的情况，name字段是比age字段大的 ，那我就建议你创建一个（name,age)的联合索引和一个(age)的单字段索引。</p><h2 id="索引下推"><a href="#索引下推" class="headerlink" title="索引下推"></a><strong>索引下推</strong></h2><p><strong>不符合最左前缀的部分，会怎么样呢？</strong></p><p>以市民表的联合索引（name, age）为例。如果现在有一个需求：检索出表中“<strong>名字第一个字是张，而且年龄是10岁的所有男孩</strong>。</p><p>那么，SQL语句是这么写的：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> tuser <span class="keyword">where</span> name <span class="keyword">like</span> <span class="string">&#x27;张%&#x27;</span> <span class="keyword">and</span> age<span class="operator">=</span><span class="number">10</span> <span class="keyword">and</span> ismale<span class="operator">=</span><span class="number">1</span>;</span><br></pre></td></tr></table></figure><p>你已经知道了前缀索引规则，所以这个语句在搜索索引树的时候，只能用 “张”，找到第一个满足条件的记录ID3。当然，这还不错，总比全表扫描要好。然后呢？当然是判断其他条件是否满足。</p><p>在MySQL 5.6之前，只能从ID3开始一个个回表。到主键索引上找出数据行，再对比字段值。而MySQL 5.6 引入的<strong>索引下推优化</strong>（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。</p><img src="clipboard-1612712459436.png" alt="img" style="zoom:60%;" /><img src="clipboard-1612712469894.png" alt="img" style="zoom:60%;" /><p>这两个图里面，<strong>每一个虚线箭头表示回表一次</strong>。</p><p>图一中，在(name,age)索引里面我特意去掉了age的值，这个过程InnoDB并不会去看age的值，只是按顺序把“name第一个字是’张’”的记录一条条取出来回表。因此，需要 <strong>回表4次</strong>。</p><p>两个图区别是，InnoDB在(name,age)<strong>索引内部就判断了age是否等于10</strong>，对于不等于10的记录，直接判断并跳过。在我们的这个例子中，只需要对ID4、ID5这两条记录回表取数据判断，就只需要 <strong>回表2次</strong>。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><strong>小结</strong></h2><p>今天这篇文章，我和你继续讨论了数据库索引的概念，包括了<strong>覆盖索引</strong>、<strong>前缀索引</strong>、<strong>索引下推</strong>。你可以看到，在满足语句需求的情况下， <strong>尽量少地访问资源是数据库设计的重要原则之一</strong>。我们在使用数据库的时候，尤其是在设计表结构时，也要以减少资源消耗作为目标。</p><h2 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a><strong>思考题</strong></h2><p>实际上主键索引也是可以使用多个字段的。DBA小吕在入职新公司的时候，就发现自己接手维护的库里面，有这么一个表，表结构定义类似这样的：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `geek` (</span><br><span class="line">  `a` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `b` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `c` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `d` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  <span class="keyword">PRIMARY</span> KEY (`a`,`b`),</span><br><span class="line">  KEY `c` (`c`),</span><br><span class="line">  KEY `ca` (`c`,`a`),</span><br><span class="line">  KEY `cb` (`c`,`b`)</span><br><span class="line">) ENGINE<span class="operator">=</span>InnoDB;</span><br></pre></td></tr></table></figure><p>公司的同事告诉他说，由于历史原因，这个表需要a、b做联合主键，这个小吕理解了。</p><p>但是，学过本章内容的小吕又纳闷了，既然主键包含了a、b这两个字段，那意味着单独在字段c上创建一个索引，就已经包含了三个字段了呀，为什么要创建“ca”“cb”这两个索引？</p><p>同事告诉他，是因为他们的业务里面有这样的两种语句：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> geek <span class="keyword">where</span> c<span class="operator">=</span>N <span class="keyword">order</span> <span class="keyword">by</span> a limit <span class="number">1</span>;</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> geek <span class="keyword">where</span> c<span class="operator">=</span>N <span class="keyword">order</span> <span class="keyword">by</span> b limit <span class="number">1</span>;</span><br></pre></td></tr></table></figure><p>我给你的问题是，这位同事的解释对吗，为了这两个查询模式，这两个索引是否都是必须的？为什么呢？</p><p>答：</p><p>主键 a，b的聚簇索引组织顺序相当于 order by a,b ，也就是先按a排序，再按b排序，c无序。</p><p>索引 ca 的组织是先按c排序，再按a排序，同时记录主键，这个跟索引c的数据是一模一样的。</p><p>索引 cb 的组织是先按c排序，在按b排序，同时记录主键</p><p>所以，结论是ca可以去掉，cb需要保留。</p>]]></content>
    
    
    <summary type="html">MySQL</summary>
    
    
    
    <category term="MySQL实战" scheme="http://example.com/categories/MySQL%E5%AE%9E%E6%88%98/"/>
    
    
    <category term="MySQL" scheme="http://example.com/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>06、全局锁和表锁：给表加个字段怎么有这么多阻碍</title>
    <link href="http://example.com/2021/04/04/MySQL/06/"/>
    <id>http://example.com/2021/04/04/MySQL/06/</id>
    <published>2021-04-04T14:13:56.000Z</published>
    <updated>2021-04-04T17:06:27.548Z</updated>
    
    <content type="html"><![CDATA[<p>数据库锁设计的初衷是<strong>处理并发问题</strong></p><p><strong>根据加锁的范围，MySQL里面的锁大致可以分成全局锁、表级锁和行锁三类</strong>。</p><h2 id="全局锁"><a href="#全局锁" class="headerlink" title="全局锁"></a><strong>全局锁</strong></h2><p>顾名思义，全局锁就是对<strong>整个数据库实例加锁</strong></p><p>MySQL 提供了一个加<strong>全局读锁</strong>的方法，命令是 <code>Flush tables with read lock</code> (FTWRL)。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：<strong>数据更新语句</strong>（数据的增删改）、<strong>数据定义语句</strong>（包括建表、修改表结构等）和<strong>更新类事务的提交语句</strong>。</p><p><strong>全局锁的典型使用场景是，做全库逻辑备份。</strong>也就是把整库每个表都select出来存成文本。</p><p>以前有一种做法，是通过FTWRL确保不会有其他线程对数据库做更新，然后对整个库做备份。注意，在备份过程中整个库完全处于只读状态。</p><p>但是让整库都只读，听上去就很危险：</p><ul><li>如果你在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆；</li><li>如果你在从库上备份，那么备份期间从库不能执行主库同步过来的binlog，会导致主从延迟。</li></ul><p>看来加全局锁不太好。但是细想一下，<strong>备份为什么要加锁呢？</strong></p><p>我们来看一下不加锁会有什么问题。假设你现在要维护“极客时间”的购买系统，关注的是用户账户余额表和用户课程表。</p><p>现在发起一个逻辑备份。假设备份期间，有一个用户，他购买了一门课程，业务逻辑里就要扣掉他的余额，然后往已购课程里面加上一门课。</p><p>如果时间顺序上是先备份账户余额表(u_account)，然后用户购买，然后备份用户课程表(u_course)，会怎么样呢？你可以看一下这个图：</p><img src="bcea4e49b0cd.png" alt="img" style="zoom: 50%;" /><p>可以看到，这个备份结果里，用户A的数据状态是“账户余额没扣，但是用户课程表里面已经多了一门课”。如果后面用这个备份来恢复数据的话，用户A就发现，自己赚了。 如果备份表的顺序反过来，先备份用户课程表再备份账户余额表，又可能会出现什么结果？</p><p><strong>不加锁的话，备份系统备份的得到的库不是一个逻辑时间点，这个视图是逻辑不一致的。</strong></p><p>前面讲事务隔离的时候，其实是有一个方法能够拿到一致性视图的，就是在可重复读隔离级别下开启一个事务。</p><p>官方自带的逻辑备份工具是<code>mysqldump</code>。当<code>mysqldump</code>使用参数<code>–single-transaction</code>的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于MVCC的支持，这个过程中数据是可以正常更新的。</p><p>你一定在疑惑，有了这个功能，为什么还需要FTWRL呢？<strong>一致性读是好，但前提是引擎要支持这个隔离级别。</strong>比如，对于MyISAM这种不支持事务的引擎，如果备份过程中有更新，总是只能取到最新的数据，那么就破坏了备份的一致性。这时，我们就需要使用FTWRL命令了。所以，<strong>single-transaction方法只适用于所有的表使用事务引擎的库。</strong>如果有的表使用了不支持事务的引擎，那么备份就只能通过FTWRL方法。这往往是DBA要求业务开发人员使用InnoDB替代MyISAM的原因之一。</p><p><strong>既然要全库只读，为什么不使用set global readonly=true的方式呢</strong>？</p><p>确实readonly方式也可以让全库进入只读状态，但我还是会建议你用FTWRL方式，主要有两个原因：</p><ul><li>一是，在有些系统中，readonly的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。因此，修改global变量的方式影响面更大，我不建议你使用。</li><li>二是，在异常处理机制上有差异。如果执行FTWRL命令之后由于客户端发生异常断开，那么MySQL会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为readonly之后，如果客户端发生异常，则数据库就会一直保持readonly状态，这样会导致整个库长时间处于不可写状态，风险较高。</li></ul><p>业务的更新不只是增删改数据（DML)，还有可能是加字段等修改表结构的操作（DDL）。不论是哪种方法，一个库被全局锁上以后，你要对里面任何一个表做加字段操作，都是会被锁住的。但是，即使没有被全局锁住，加字段也不是就能一帆风顺的，因为你还会碰到接下来我们要介绍的表级锁。</p><h2 id="表级锁"><a href="#表级锁" class="headerlink" title="表级锁"></a><strong>表级锁</strong></h2><p>MySQL里面表级别的锁有两种：一种是 <strong>表锁</strong>，一种是 <strong>元数据锁</strong>（meta data lock，MDL)。</p><p><strong>表锁的语法是 <code>lock tables … read/write</code></strong></p><p>与FTWRL类似，可以用 <code>unlock tables</code> 主动释放锁，也可以在客户端断开的时候自动释放。需要注意，lock tables语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。</p><p>举个例子, 如果在某个线程A中执行 <code>lock tables t1 read, t2 write;</code> 这个语句，则其他线程写t1、读写t2的语句都会被阻塞。同时，线程A在执行<code>unlock tables</code>之前，也只能执行读t1、读写t2的操作。连写t1都不允许，自然也不能访问其他表。</p><p>在还没有出现更细粒度的锁的时候，表锁是最常用的处理并发的方式。而对于InnoDB这种支持行锁的引擎，一般不使用lock tables命令来控制并发，毕竟锁住整个表的影响面还是太大。</p><p><strong>另一类表级的锁是MDL（metadata lock)。</strong>MDL不需要显式使用，在访问一个表的时候会被自动加上。MDL的作用是，<strong>保证读写的正确性</strong>。你可以想象一下，如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上，肯定是不行的。</p><p>因此，在MySQL 5.5版本中引入了MDL，<strong>当对一个表做增删改查操作的时候，加MDL读锁；当要对表做结构变更操作的时候，加MDL写锁。</strong></p><ul><li>读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。</li><li>读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。</li></ul><p>因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。虽然MDL锁是系统默认会加的，但却是你不能忽略的一个机制。</p><p>比如下面这个例子，我经常看到有人掉到这个坑里：给一个小表加个字段，导致整个库挂了。你肯定知道，给一个表加字段，或者修改字段，或者加索引，需要扫描全表的数据。在对大表操作的时候，你肯定会特别小心，以免对线上服务造成影响。而实际上，即使是小表，操作不慎也会出问题。我们来看一下下面的操作序列，假设表t是一个小表。</p><p>备注：这里的实验环境是MySQL 5.6。</p><img src="6ececdfb0ce.jpeg" alt="img" style="zoom:50%;" /><p>session A 先启动，这时候会对表t加一个MDL读锁。</p><p>session B 需要的也是MDL读锁，因此可以正常执行。</p><p>session C会被blocked，是因为session A的MDL读锁还没有释放，而session C需要MDL写锁，因此只能被阻塞。</p><p>如果只有session C自己被阻塞还没什么关系，但是之后所有要在表t上新申请MDL读锁的请求也会被session C阻塞。前面我们说了，所有对表的增删改查操作都需要先申请MDL读锁，就都被锁住，等于这个表现在完全不可读写了。</p><p>如果某个表上的查询语句频繁，而且客户端有重试机制，也就是说超时后会再起一个新session再请求的话，这个库的线程很快就会爆满。</p><p>你现在应该知道了，<strong>事务中的MDL锁，在语句执行开始时申请，但是语句结束后并不会马上释放，而会等到整个事务提交后再释放</strong>。</p><blockquote><p><strong>如何安全地给小表加字段？</strong></p><p>首先我们要解决长事务，事务不提交，就会一直占着MDL锁。在MySQL的<code>information_schema</code> 库的 <code>innodb_trx</code> 表中，你可以查到当前执行中的事务。如果你要做DDL变更的表刚好有长事务在执行，要考虑先暂停DDL，或者kill掉这个长事务。</p><p>如果你要变更的表是一个热点表，虽然数据量不大，但是上面的请求很频繁，而你不得不加个字段，你该怎么做呢？这时候kill可能未必管用，因为新的请求马上就来了。比较理想的机制是，在<code>alter table</code>语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到MDL写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者DBA再通过重试命令重复这个过程。 </p><p>MariaDB已经合并了AliSQL的这个功能，所以这两个开源分支目前都支持DDL NOWAIT/WAIT n这个语法。</p><p><code>ALTER TABLE tbl_name NOWAIT add column ...</code> </p><p><code>ALTER TABLE tbl_name WAIT N add column ...</code> </p></blockquote><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><strong>小结</strong></h2><p>全局锁主要用在逻辑备份过程中。对于全部是InnoDB引擎的库，我建议你选择使用 <code>–single-transaction</code> 参数，对应用会更友好。</p><p>表锁一般是在数据库引擎不支持行锁的时候才会被用到的。如果你发现你的应用程序里有lock tables这样的语句，你需要追查一下，比较可能的情况是：</p><ul><li>要么是你的系统现在还在用MyISAM这类不支持事务的引擎，那要安排升级换引擎；</li><li>要么是你的引擎升级了，但是代码还没升级。我见过这样的情况，最后业务开发就是把lock tables 和 unlock tables 改成 begin 和 commit，问题就解决了。</li></ul><p>MDL会直到事务提交才释放，在做表结构变更的时候，你一定要小心不要导致锁住线上查询和更新。</p><h2 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a><strong>思考题</strong></h2><p>备份一般都会在备库上执行，你在用 <code>–single-transaction</code> 方法做逻辑备份的过程中，如果主库上的一个小表做了一个DDL，比如给一个表上加了一列。这时候，从备库上会看到什么现象呢？</p><p>假设这个DDL是针对表t1的， 这里我把备份过程中几个关键的语句列出来：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Q1:<span class="keyword">SET</span> SESSION TRANSACTION ISOLATION LEVEL REPEATABLE READ;</span><br><span class="line">Q2:<span class="keyword">START</span> TRANSACTION  <span class="keyword">WITH</span> CONSISTENT SNAPSHOT；</span><br><span class="line"><span class="comment">/* other tables */</span></span><br><span class="line">Q3:<span class="keyword">SAVEPOINT</span> sp;</span><br><span class="line"><span class="comment">/* 时刻 1 */</span></span><br><span class="line">Q4:<span class="keyword">show</span> <span class="keyword">create</span> <span class="keyword">table</span> `t1`;</span><br><span class="line"><span class="comment">/* 时刻 2 */</span></span><br><span class="line">Q5:<span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> `t1`;</span><br><span class="line"><span class="comment">/* 时刻 3 */</span></span><br><span class="line">Q6:<span class="keyword">ROLLBACK</span> <span class="keyword">TO</span> <span class="keyword">SAVEPOINT</span> sp;</span><br><span class="line"><span class="comment">/* 时刻 4 */</span></span><br><span class="line"><span class="comment">/* other tables */</span></span><br></pre></td></tr></table></figure><p>在备份开始的时候，为了确保RR（可重复读）隔离级别，再设置一次RR隔离级别(Q1);</p><p>启动事务，这里用 WITH CONSISTENT SNAPSHOT确保这个语句执行完就可以得到一个一致性视图（Q2)；</p><p>设置一个保存点，这个很重要（Q3）；</p><p>show create 是为了拿到表结构(Q4)，然后正式导数据 （Q5），回滚到SAVEPOINT sp，在这里的作用是释放 t1的MDL锁 （Q6。当然这部分属于“超纲”，上文正文里面都没提到。</p><p>DDL从主库传过来的时间按照效果不同，我打了四个时刻。题目设定为小表，我们假定到达后，如果开始执行，则很快能够执行完成。</p><p>参考答案如下：</p><ol><li>如果在Q4语句执行之前到达，现象：没有影响，备份拿到的是DDL后的表结构。</li><li>如果在“时刻 2”到达，则表结构被改过，Q5执行的时候，报 Table definition has changed, please retry transaction，现象：mysqldump终止；</li><li>如果在“时刻3”到达，mysqldump占着t1的MDL读锁，binlog被阻塞，现象：主从延迟，直到Q6执行完成。</li><li>从“时刻4”开始，mysqldump释放了MDL读锁，现象：没有影响，备份拿到的是DDL前的表结构。</li></ol>]]></content>
    
    
    <summary type="html">MySQL</summary>
    
    
    
    <category term="MySQL实战" scheme="http://example.com/categories/MySQL%E5%AE%9E%E6%88%98/"/>
    
    
    <category term="MySQL" scheme="http://example.com/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>07、行锁功过：怎么减少行锁对性能的影响</title>
    <link href="http://example.com/2021/04/04/MySQL/07/"/>
    <id>http://example.com/2021/04/04/MySQL/07/</id>
    <published>2021-04-04T14:13:56.000Z</published>
    <updated>2021-04-04T17:01:03.132Z</updated>
    
    <content type="html"><![CDATA[<p>MySQL的行锁是在引擎层由各个引擎自己实现的。但并不是所有的引擎都支持行锁，比如MyISAM引擎就不支持行锁。不支持行锁意味着并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。<strong>InnoDB是支持行锁的，这也是MyISAM被InnoDB替代的重要原因之一。</strong></p><p><strong>InnoDB的行锁如何通过减少锁冲突来提升业务并发度？</strong></p><p>行锁就是针对数据表中行记录的锁。比如事务A更新了一行，而这时候事务B也要更新同一行，则必须等事务A的操作完成后才能进行更新。</p><p>当然，数据库中还有一些没那么一目了然的概念和设计，这些概念如果理解和使用不当，容易导致程序出现非预期行为，比如两阶段锁。</p><h2 id="两阶段锁"><a href="#两阶段锁" class="headerlink" title="两阶段锁"></a><strong>两阶段锁</strong></h2><p>在下面的操作序列中，事务B的update语句执行时会是什么现象呢？</p><p>假设字段id是表t的主键。</p><img src="clipboard-1612946256102.png" alt="img" style="zoom: 50%;" /><p>实际上事务B的update语句会被阻塞，直到事务A执行commit之后，事务B才能继续执行。<strong>事务A持有的两个记录的行锁，都是在commit的时候才释放的。</strong></p><p>在InnoDB事务中，<strong>行锁是在需要的时候才加上的</strong>，但并不是不需要了就立刻释放，而是要<strong>等到事务结束时才释放</strong>。这个就是两阶段锁协议。</p><p>如果你的事务中需要锁多个行，要把最可能造成锁冲突、<strong>最可能影响并发度的锁尽量往后放</strong>。</p><blockquote><p>假设你负责实现一个电影票在线交易业务，顾客A要在影院B购买电影票。</p><p>这个业务需要涉及到以下操作：</p><ol><li>从顾客A账户余额中扣除电影票价；</li><li>给影院B的账户余额增加这张电影票价；</li><li>记录一条交易日志。</li></ol><p>要完成这个交易，我们需要update两条记录，并insert一条记录。当然，为了保证交易的原子性，我们要把这三个操作放在一个事务中。那么，你会怎样安排这三个语句在事务中的顺序呢？</p><p>根据两阶段锁协议，不论你怎样安排语句顺序，所有的操作需要的行锁都是在事务提交的时候才释放的。所以，如果你把语句2安排在最后，比如按照3、1、2这样的顺序，那么影院账户余额这一行的锁时间就最少。这就最大程度地减少了事务之间的锁等待，提升了并发度。</p><p>如果这个影院做活动，可以低价预售一年内所有的电影票，而且这个活动只做一天。于是在活动时间开始的时候，你的MySQL就挂了。你登上服务器一看，CPU消耗接近100%，但整个数据库每秒就执行不到100个事务。这是什么原因呢？要说到死锁和死锁检测</p></blockquote><h2 id="死锁和死锁检测"><a href="#死锁和死锁检测" class="headerlink" title="死锁和死锁检测"></a><strong>死锁和死锁检测</strong></h2><p>当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。</p><p>这里我用数据库中的行锁举个例子。</p><img src="clipboard-1612946827069.png" alt="img" style="zoom: 50%;" /><p>这时候，事务A在等待事务B释放id=2的行锁，而事务B在等待事务A释放id=1的行锁。 事务A和事务B在互相等待对方的资源释放，就是进入了死锁状态。当出现死锁以后，有两种策略：</p><ul><li>一种策略是，直接进入等待，直到<strong>超时</strong>。这个超时时间可以通过参数<code>innodb_lock_wait_timeout</code> 来设置。</li><li>另一种策略是，发起<strong>死锁检测</strong>，发现死锁后，<strong>主动回滚死锁链条中的某一个事务</strong>，让其他事务得以继续执行。将参数<code>innodb_deadlock_detect</code>设置为on，表示开启这个逻辑。</li></ul><p>在InnoDB中，<code>innodb_lock_wait_timeout</code> 的默认值是50s，意味着如果采用第一个策略，当出现死锁以后，第一个被锁住的线程要过50s才会超时退出，然后其他线程才有可能继续执行。对于在线服务来说，这个等待时间往往是无法接受的。但是，我们又不可能直接把这个时间设置成一个很小的值，比如1s。这样当出现死锁的时候，确实很快就可以解开，但如果不是死锁，而是简单的锁等待呢？所以，超时时间设置太短的话，会出现很多<strong>误伤</strong>。</p><p>所以，正常情况下我们还是要采用第二种策略，即：主动死锁检测，而且 <code>innodb_deadlock_detect</code> 的默认值本身就是on。主动死锁检测在发生死锁的时候，是能够快速发现并进行处理的，但是它也是有额外负担的。</p><p>你可以想象一下这个过程：每当一个事务被锁的时候，就要看看它所依赖的线程有没有被别人锁住，如此循环，最后判断是否出现了循环等待，也就是死锁。那如果是我们上面说到的所有事务都要更新同一行的场景呢？</p><p>每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是O(n^2)的操作。假设有1000个并发线程要同时更新同一行，那么死锁检测操作就是100万这个量级的。虽然最终检测的结果是没有死锁，但是这期间要消耗大量的CPU资源。因此，你就会看到CPU利用率很高，但是每秒却执行不了几个事务。</p><p><strong>怎么解决由这种热点行更新导致的性能问题呢？</strong></p><p>问题的症结在于，死锁检测要耗费大量的CPU资源。</p><p>一种头痛医头的方法，就是如果你能确保这个业务一定不会出现死锁，<strong>可以临时把死锁检测关掉</strong>。但是这种操作本身带有一定的风险，因为业务设计的时候一般不会把死锁当做一个严重错误，毕竟出现死锁了，就回滚，然后通过业务重试一般就没问题了，这是业务无损的。而关掉死锁检测意味着可能会出现大量的超时，这是业务有损的。</p><p>另一个思路是 <strong>控制并发度</strong>。根据上面的分析，你会发现如果并发能够控制住，比如同一行同时最多只有10个线程在更新，那么死锁检测的成本很低，就不会出现这个问题。一个直接的想法就是，在客户端做并发控制。但是，你会很快发现这个方法不太可行，因为客户端很多。我见过一个应用，有600个客户端，这样即使每个客户端控制到只有5个并发线程，汇总到数据库服务端以后，峰值并发数也可能要达到3000。</p><p>因此，这个并发控制要做在数据库服务端。如果你有中间件，可以考虑在<strong>中间件</strong>实现；如果你的团队有能修改MySQL源码的人，也可以做在MySQL里面。基本思路就是，对于相同行的更新，在进入引擎之前排队。这样在InnoDB内部就不会有大量的死锁检测工作了。</p><p>可能你会问，<strong>如果团队里暂时没有数据库方面的专家，不能实现这样的方案，能不能从设计上优化这个问题呢？</strong></p><p>你可以考虑通过将一行改成逻辑上的多行来减少锁冲突。还是以影院账户为例，可以考虑放在多条记录上，比如10个记录，影院的账户总额等于这10个记录的值的总和。这样每次要给影院账户加金额的时候，随机选其中一条记录来加。这样每次冲突概率变成原来的1/10，可以减少锁等待个数，也就减少了死锁检测的CPU消耗。</p><p>这个方案看上去是无损的，但其实这类方案需要<strong>根据业务逻辑做详细设计</strong>。如果账户余额可能会减少，比如退票逻辑，那么这时候就需要考虑当一部分行记录变成0的时候，代码要有特殊处理。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><strong>小结</strong></h2><p>今天，我和你介绍了MySQL的行锁，涉及了两阶段锁协议、死锁和死锁检测这两大部分内容。</p><p>其中，我以两阶段协议为起点，和你一起讨论了在开发的时候如何安排正确的事务语句。这里的原则/我给你的建议是：<strong>如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁的申请时机尽量往后放。</strong></p><p>但是，调整语句顺序并不能完全避免死锁。所以我们引入了死锁和死锁检测的概念，以及提供了三个方案，来减少死锁对数据库的影响。<strong>减少死锁的主要方向，就是控制访问相同资源的并发事务量</strong>。</p><h2 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a><strong>思考题</strong></h2><p>如果你要删除一个表里面的前10000行数据，有以下三种方法可以做到：</p><ul><li>第一种，直接执行delete from T limit 10000;</li><li>第二种，在一个连接中循环执行20次 delete from T limit 500;</li><li>第三种，在20个连接中同时执行delete from T limit 500。</li></ul><p>你会选择哪一种方法呢？为什么呢？</p><p>第一种方式（即：直接执行delete from T limit 10000）里面，单个语句占用时间长，锁的时间也比较长；而且大事务还会导致主从延迟。</p><p>第二种方式是相对较好的。</p><p>第三种方式（即：在20个连接中同时执行delete from T limit 500），会人为造成锁冲突。</p>]]></content>
    
    
    <summary type="html">MySQL</summary>
    
    
    
    <category term="MySQL实战" scheme="http://example.com/categories/MySQL%E5%AE%9E%E6%88%98/"/>
    
    
    <category term="MySQL" scheme="http://example.com/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>08、事务到底是隔离的还是不隔离的</title>
    <link href="http://example.com/2021/04/04/MySQL/08/"/>
    <id>http://example.com/2021/04/04/MySQL/08/</id>
    <published>2021-04-04T14:13:56.000Z</published>
    <updated>2021-04-04T17:05:01.270Z</updated>
    
    <content type="html"><![CDATA[<p>如果是可重复读隔离级别，事务T启动的时候会创建一个视图read-view，之后事务T执行期间，即使有其他事务修改了数据，事务T看到的仍然跟在启动时看到的一样。也就是说，一个在可重复读隔离级别下执行的事务，好像与世无争，不受外界影响。</p><p>但是，我在上一篇文章中，和你分享行锁的时候又提到，一个事务要更新一行，如果刚好有另外一个事务拥有这一行的行锁，它又不能这么超然了，会被锁住，进入等待状态。问题是，既然进入了等待状态，那么等到这个事务自己获取到行锁要更新数据的时候，它读到的值又是什么呢？</p><p>我给你举一个例子吧。下面是一个只有两行的表的初始化语句。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `t` (</span><br><span class="line">  `id` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `k` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  <span class="keyword">PRIMARY</span> KEY (`id`)</span><br><span class="line">) ENGINE<span class="operator">=</span>InnoDB;</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t(id, k) <span class="keyword">values</span>(<span class="number">1</span>,<span class="number">1</span>),(<span class="number">2</span>,<span class="number">2</span>);</span><br></pre></td></tr></table></figure><img src="clipboard-1613230212124.png" alt="img" style="zoom:67%;" /><p><code>begin/start transaction</code> 命令并不是一个事务的起点，在执行到它们之后的第一个操作InnoDB表的语句（第一个快照读语句），事务才真正启动。如果你想要马上启动一个事务，可以使用 <code>start transaction with consistent snapshot</code> 这个命令。如果没有特别说明，都是默认autocommit=1。</p><p>在这个例子中，事务C没有显式地使用 begin/commit，表示这个update语句本身就是一个事务，语句完成的时候会自动提交。事务B在更新了行之后查询; 事务A在一个只读事务中查询，并且时间顺序上是在事务B的查询之后。</p><p><strong>事务B查到的k的值是 3</strong></p><p><strong>事务A查到的k的值是 1</strong></p><p>在MySQL里，有两个“<strong>视图</strong>”的概念：</p><ul><li>一个是view。是一个用查询语句定义的<strong>虚拟表</strong>，在调用的时候执行查询语句并生成结果。创建视图的语法是 create view … ，而它的查询方法与表一样。</li><li>另一个是InnoDB在实现MVCC时用到的<strong>一致性读视图</strong>，即 <strong>consistent read view</strong>，用于支持 RC（Read Committed，读提交）和RR（Repeatable Read，可重复读）隔离级别的实现。它没有物理结构，<strong>作用是事务执行期间用来定义“我能看到什么数据”</strong>。</li></ul><h2 id="快照”在MVCC里是怎么工作的？"><a href="#快照”在MVCC里是怎么工作的？" class="headerlink" title="快照”在MVCC里是怎么工作的？"></a><strong>快照”在MVCC里是怎么工作的？</strong></h2><p>在可重复读隔离级别下，事务在启动的时候就“拍了个快照”。<strong>注意，这个快照是基于整库的。</strong></p><p>这时，你会说这看上去不太现实啊。如果一个库有100G，那么我启动一个事务，MySQL就要拷贝100G的数据出来，这个过程得多慢啊。可是，我平时的事务执行起来很快啊。实际上，我们并不需要拷贝出这100G的数据。</p><p><strong>这个快照是怎么实现的？</strong></p><p>InnoDB 里面每个事务有一个唯一的事务ID，叫作 <code>transaction id</code>。它是在<strong>事务开始</strong>的时候向InnoDB的事务系统申请的，是<strong>按申请顺序严格递增</strong>的。</p><p>每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本，并且把 <code>transaction id</code> 赋值给这个数据版本的事务ID，记为 <code>row trx_id</code>。同时，旧的数据版本要保留，并且在新的数据版本中，能够有信息可以直接拿到它。也就是说，数据表中的一行记录，其实可能有多个版本(row)，每个版本有自己的row trx_id。</p><p>如图2所示，就是一个记录被多个事务连续更新后的状态。</p><img src="clipboard-1613230781527.png" alt="img" style="zoom:60%;" /><p>语句更新会生成 <code>undo log</code>（回滚日志）吗？</p><p>那么，<strong>undo log在哪呢？</strong></p><p>实际上，图2中的三个虚线箭头，就是undo log；而V1、V2、V3并不是物理上真实存在的，而是每次需要的时候<strong>根据当前版本和undo log计算出来的</strong>。比如，需要V2的时候，就是通过V4依次执行U3、U2算出来。</p><p><strong>InnoDB是怎么定义那个“100G”的快照的？</strong></p><p>按照可重复读的定义，一个事务启动的时候，能够看到所有已经提交的事务结果。但是之后，这个事务执行期间，其他事务的更新对它不可见。</p><p>因此，一个事务只需要在启动的时候声明说，“以我启动的时刻为准，如果一个数据版本是在我启动之前生成的，就认；如果是我启动以后才生成的，我就不认，我必须要找到它的上一个版本”。当然，如果“上一个版本”也不可见，那就得继续往前找。还有，如果是这个事务自己更新的数据，它自己还是要认的。</p><p>在实现上， InnoDB为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正在“活跃”的所有事务ID。“活跃”指的就是，启动了但还没提交。</p><p>数组里面事务ID的最小值记为低水位，当前系统里面已经创建过的事务ID的最大值加1记为高水位。这个视图数组和高水位，就组成了当前事务的一致性视图（read-view）。而数据版本的可见性规则，就是基于数据的row trx_id和这个一致性视图的对比结果得到的。</p><p>这个视图数组把所有的row trx_id 分成了几种不同的情况。</p><img src="clipboard-1613231189515.png" alt="img" style="zoom:50%;" /><p>这样，对于当前事务的启动瞬间来说，一个数据版本的 <code>row trx_id</code>，有以下几种可能：</p><ol><li><p>如果落在绿色部分，表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的；</p></li><li><p>如果落在红色部分，表示这个版本是由将来启动的事务生成的，是肯定不可见的；</p></li><li><p>如果落在黄色部分，那就包括两种情况</p></li><li><ol><li>若 <code>row trx_id</code>在数组中，表示这个版本是由还没提交的事务生成的，不可见；</li><li>若 <code>row trx_id</code>不在数组中，表示这个版本是已经提交了的事务生成的，可见。</li></ol></li></ol><p>比如，对于图2中的数据来说，如果有一个事务，它的低水位是18，那么当它访问这一行数据时，就会从V4通过U3计算出V3，所以在它看来，这一行的值是11。</p><p>你看，有了这个声明后，系统里面随后发生的更新，是不是就跟这个事务看到的内容无关了呢？因为之后的更新，生成的版本一定属于上面的2或者3(1)的情况，而对它来说，这些新的数据版本是不存在的，所以这个事务的快照，就是“静态”的了。</p><p>所以你现在知道了，<strong>InnoDB利用了“所有数据都有多个版本”的这个特性，实现了“秒级创建快照”的能力。</strong></p><blockquote><p>事务A的语句返回的结果，为什么是k=1。不妨做如下假设：</p><ol><li>事务A开始前，系统里面只有一个活跃事务ID是99；</li><li>事务A、B、C的版本号分别是100、101、102，且当前系统里只有这四个事务；</li><li>三个事务开始前，(1,1）这一行数据的row trx_id是90。</li></ol><p>这样，事务A的视图数组就是[99,100], 事务B的视图数组是[99,100,101], 事务C的视图数组是[99,100,101,102]。</p><p>为了简化分析，我先把其他干扰语句去掉，只画出跟事务A查询逻辑有关的操作：</p><img src="clipboard-1613231581098.png" alt="img" style="zoom:40%;" /><p>第一个有效更新是事务C，把数据从(1,1)改成了(1,2)。这时候，这个数据的最新版本的<code>row trx_id</code>是102，而90这个版本已经成为了历史版本。</p><p>第二个有效更新是事务B，把数据从(1,2)改成了(1,3)。这时候，这个数据的最新版本的<code>row trx_id</code>是101，而102又成为了历史版本。</p><p>在事务A查询的时候，其实事务B还没有提交，但是它生成的(1,3)这个版本已经变成当前版本了。但这个版本对事务A必须是不可见的，否则就变成脏读了。事务A要来读数据了，它的视图数组是[99,100]。当然了，读数据都是从当前版本读起的。所以，事务A查询语句的读数据流程是这样的：</p><ul><li>找到(1,3)的时候，判断出row trx_id=101，比高水位大，处于红色区域，不可见；</li><li>接着，找到上一个历史版本，一看row trx_id=102，比高水位大，处于红色区域，不可见；</li><li>再往前找，终于找到了（1,1)，它的row trx_id=90，比低水位小，处于绿色区域，可见。</li></ul><p>这样执行下来，虽然期间这一行数据被修改过，但是事务A不论在什么时候查询，看到这行数据的结果都是一致的，所以我们称之为一致性读。</p></blockquote><p>一个数据版本，对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况：</p><ol><li>版本未提交，不可见；</li><li>版本已提交，但是是在视图创建后提交的，不可见；</li><li>版本已提交，而且是在视图创建前提交的，可见。</li></ol><p>事务A的查询语句的视图数组是在事务A启动的时候生成的，这时候：</p><ul><li>(1,3)还没提交，属于情况1，不可见；</li><li>(1,2)虽然提交了，但是是在视图数组创建之后提交的，属于情况2，不可见；</li><li>(1,1)是在视图数组创建之前提交的，可见。</li></ul><p>你看，去掉数字对比后，只用时间先后顺序来判断，分析起来是不是轻松多了。所以，后面我们就都用这个规则来分析。</p><h2 id="更新逻辑"><a href="#更新逻辑" class="headerlink" title="更新逻辑"></a><strong>更新逻辑</strong></h2><blockquote><p> <strong>事务B的update语句，如果按照一致性读，好像结果不对哦？</strong></p><p>事务B的视图数组是先生成的，之后事务C才提交，不是应该看不见(1,2)吗，怎么能算出(1,3)来？</p></blockquote><img src="clipboard-1613282827446.png" alt="img" style="zoom:36%;" /><p>如果事务B在更新之前查询一次数据，这个查询返回的k的值确实是1。</p><p>但是，当它要去更新数据的时候，就不能再在历史版本上更新了，否则事务C的更新就丢失了。因此，事务B此时的set k=k+1是在（1,2）的基础上进行的操作。所以，这里就用到了这样一条规则：<strong>更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）。</strong></p><p>因此，在更新的时候，当前读拿到的数据是(1,2)，更新后生成了新版本的数据(1,3)，这个新版本的row trx_id是101。所以，在执行事务B查询语句的时候，一看自己的版本号是101，最新数据的版本号也是101，是自己的更新，可以直接使用，所以查询得到的k的值是3。</p><p>这里我们提到了一个概念，叫作 <strong>当前读</strong>。其实，除了update语句外，select语句如果加锁，也是当前读。</p><p>如果把事务A的查询语句 <code>select * from t where id=1</code> 修改一下，加上 <code>lock in share mode</code> 或 <code>for update</code>，也都可以读到版本号是101的数据，返回的k的值是3。</p><p>下面这两个select语句，就是分别加了 <strong>读锁（S锁，共享锁）</strong>和 <strong>写锁（X锁，排他锁）</strong></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">select</span> k <span class="keyword">from</span> t <span class="keyword">where</span> id<span class="operator">=</span><span class="number">1</span> lock <span class="keyword">in</span> share mode; </span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">select</span> k <span class="keyword">from</span> t <span class="keyword">where</span> id<span class="operator">=</span><span class="number">1</span> <span class="keyword">for</span> update;</span><br></pre></td></tr></table></figure><p>再往前一步，假设事务C不是马上提交的，而是变成了下面的事务C’，会怎么样呢？</p><img src="clipboard-1613283261641.png" alt="img" style="zoom:60%;" /><p>事务C’的不同是，更新后并没有马上提交，在它提交前，事务B的更新语句先发起了。前面说过了，虽然事务C’还没提交，但是(1,2)这个版本也已经生成了，并且是当前的最新版本。那么，事务B的更新语句会怎么处理呢？</p><p><strong>“两阶段锁协议”就要上场了。事务C’没提交，也就是说(1,2)这个版本上的写锁还没释放。而事务B是当前读，必须要读最新版本，而且必须加锁，因此就被锁住了，必须等到事务C’释放这个锁，才能继续它的当前读。</strong></p><p>到这里，我们把一致性读、当前读和行锁就串起来了。</p><p><strong>事务的可重复读的能力是怎么实现的？</strong></p><p>可重复读的核心就是<strong>一致性读（consistent read）</strong> ，而事务更新数据的时候，只能用当前读。如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。</p><p>而读提交的逻辑和可重复读的逻辑类似，它们最主要的区别是：</p><ul><li>在可重复读隔离级别下，只需要在事务开始的时候创建一致性视图，之后事务里的其他查询都共用这个一致性视图；</li><li>在读提交隔离级别下，每一个语句执行前都会重新算出一个新的视图。</li></ul><p><strong>在读提交隔离级别下，事务A和事务B的查询语句查到的k，分别应该是多少呢？</strong></p><p>这里需要说明一下，“start transaction with consistent snapshot; ”的意思是从这个语句开始，创建一个持续整个事务的一致性快照。所以，在读提交隔离级别下，这个用法就没意义了，等效于普通的start transaction。</p><p>下面是读提交时的状态图，可以看到这两个查询语句的创建视图数组的时机发生了变化，就是图中的read view框。（注意：这里，我们用的还是事务C的逻辑直接提交，而不是事务C’）</p><img src="clipboard-1613283405265.png" alt="img" style="zoom:47%;" /><p>事务A的查询语句的视图数组是在执行这个语句的时候创建的，时序上(1,2)、(1,3)的生成时间都在创建这个视图数组的时刻之前。但是，在这个时刻：</p><ul><li>(1,3)还没提交，属于情况1，不可见；</li><li>(1,2)提交了，属于情况3，可见。</li></ul><p>所以，这时候事务A查询语句返回的是k=2。显然地，事务B查询结果k=3。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><strong>小结</strong></h2><p>InnoDB的行数据有多个版本，每个数据版本有自己的 <code>row trx_id</code>，每个事务或者语句有自己的一致性视图。</p><p><strong>普通查询语句是一致性读，一致性读会根据row trx_id和一致性视图确定数据版本的可见性。</strong></p><ul><li><strong>对于可重复读，查询只承认在事务启动前就已经提交完成的数据</strong>；</li><li><strong>对于读提交，查询只承认在语句启动前就已经提交完成的数据</strong>；</li></ul><p><strong>而当前读，总是读取已经提交完成的最新版本。</strong></p><p>你也可以想一下，为什么表结构不支持“可重复读”？</p><p>这是因为表结构没有对应的行数据，也没有row trx_id，因此只能遵循当前读的逻辑。</p><p>当然，MySQL 8.0已经可以把表结构放在InnoDB字典里了，也许以后会支持表结构的可重复读。</p><h2 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a><strong>思考题</strong></h2><p>用下面的表结构和初始化语句作为试验环境，事务隔离级别是可重复读。</p><p>现在，我要把所有“字段c和id值相等的行”的c值清零，但是却发现了一个“诡异”的、改不掉的情况。请你构造出这种情况，并说明其原理。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `t` (</span><br><span class="line">  `id` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `c` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  <span class="keyword">PRIMARY</span> KEY (`id`)</span><br><span class="line">) ENGINE<span class="operator">=</span>InnoDB;</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t(id, c) <span class="keyword">values</span>(<span class="number">1</span>,<span class="number">1</span>),(<span class="number">2</span>,<span class="number">2</span>),(<span class="number">3</span>,<span class="number">3</span>),(<span class="number">4</span>,<span class="number">4</span>);</span><br></pre></td></tr></table></figure><img src="/2021/04/04/MySQL/08/e93e36c3060b.png" class="" title="img"><p>复现出来以后，请你再思考一下，在实际的业务开发中有没有可能碰到这种情况？</p><p>你的应用代码会不会掉进这个“坑”里，你又是怎么解决的呢？</p><p>答案：</p><img src="截图.png" alt="img" style="zoom:50%;" /><p>这样，session A看到的就是我截图的效果了。</p><p>其实，还有另外一种场景</p><img src="截图-1613283448186.png" alt="img" style="zoom:67%;" /><p>这个操作序列跑出来，session A看的内容也是能够复现我截图的效果的。这个session B’启动的事务比A要早，其实是上期我们描述事务版本的可见性规则时留的彩蛋，因为规则里还有一个“活跃事务的判断”，我是准备留到这里再补充的。</p><p>用新的方式来分析session B’的更新为什么对session A不可见就是：在session A视图数组创建的瞬间，session B’是活跃的，属于“版本未提交，不可见”这种情况。</p>]]></content>
    
    
    <summary type="html">MySQL</summary>
    
    
    
    <category term="MySQL实战" scheme="http://example.com/categories/MySQL%E5%AE%9E%E6%88%98/"/>
    
    
    <category term="MySQL" scheme="http://example.com/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>09、普通索引和唯一索引，应该怎么选择</title>
    <link href="http://example.com/2021/04/04/MySQL/09/"/>
    <id>http://example.com/2021/04/04/MySQL/09/</id>
    <published>2021-04-04T14:13:56.000Z</published>
    <updated>2021-04-04T17:02:00.374Z</updated>
    
    <content type="html"><![CDATA[<p>假设你在维护一个市民系统，每个人都有一个唯一的身份证号，而且业务代码已经保证了不会写入两个重复的身份证号。</p><p>如果市民系统需要按照身份证号查姓名，就会执行类似这样的SQL语句：</p><p><code>select name from CUser where id_card = &#39;xxxxxxxyyyyyyzzzzz&#39;;</code></p><p>所以，你一定会考虑在id_card字段上建索引。</p><p>由于身份证号字段比较大，我不建议你把身份证号当做主键，那么现在你有两个选择，要么给id_card字段创建唯一索引，要么创建一个普通索引。如果业务代码已经保证了不会写入重复的身份证号，那么这两个选择逻辑上都是正确的。</p><p> <strong>从性能的角度考虑，你选择唯一索引还是普通索引呢？选择的依据是什么呢？</strong></p><p><strong>答：普通索引, changeBuffer</strong></p><hr><img src="1ed9536031d6698570ea175a7b7f9a46.png" alt="img" style="zoom:30%;" /><p>假设字段 k 上的值都不重复，从这两种索引对查询语句和更新语句的性能影响来进行分析。</p><h2 id="查询过程"><a href="#查询过程" class="headerlink" title="查询过程"></a><strong>查询过程</strong></h2><p>假设，执行查询的语句是 <code>select id from T where k=5</code>。这个查询语句在索引树上查找的过程，先是通过B+树从树根开始，按层搜索到叶子节点，也就是图中右下角的这个数据页，然后可以认为数据页内部通过二分法来定位记录。</p><ul><li>对于普通索引来说，查找到满足条件的第一个记录(5,500)后，需要查找下一个记录，直到碰到第一个不满足k=5条件的记录。</li><li>对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。</li></ul><p>那么，这个不同带来的性能差距会有多少呢？答案是，微乎其微。</p><p>你知道的，<strong>InnoDB的数据是按数据页为单位来读写的</strong>。也就是说，当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。在InnoDB中，每个数据页的大小默认是16KB。</p><p>因为引擎是按页读写的，所以说，当找到k=5的记录的时候，它所在的数据页就都在内存里了。那么，对于普通索引来说，要多做的那一次“查找和判断下一条记录”的操作，就只需要一次指针寻找和一次计算。当然，如果k=5这个记录刚好是这个数据页的最后一个记录，那么要取下一个记录，必须读取下一个数据页，这个操作会稍微复杂一些。但是，我们之前计算过，对于整型字段，一个数据页可以放近千个key，因此出现这种情况的概率会很低。所以，我们计算平均性能差异时，仍可以认为这个操作成本对于现在的CPU来说可以忽略不计。</p><h2 id="更新过程"><a href="#更新过程" class="headerlink" title="更新过程"></a><strong>更新过程</strong></h2><p>为了说明普通索引和唯一索引对更新语句性能的影响这个问题，我需要先跟你介绍一下 <code>change buffer</code>。</p><p>当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InooDB会将这些<strong>更新操作缓存在 change buffer 中</strong>，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后<strong>执行change buffer中与这个页有关的操作</strong>。通过这种方式就能保证这个数据逻辑的正确性。</p><p>需要说明的是，虽然名字叫作 change buffer，实际上它是可以<strong>持久化的数据</strong>。也就是说，change buffer 在内存中有拷贝，也会被写入到磁盘上。</p><p>将<code>change buffer</code>中的操作应用到原数据页，得到最新结果的过程称为<code>merge</code>。除了访问这个数据页会触发<code>merge</code>外，系统有后台线程会定期 <code>merge</code>。在数据库正常关闭（shutdown）的过程中，也会执行merge操作。</p><p>显然，如果能够将更新操作先记录在 change buffer，减少读磁盘，语句的执行速度会得到明显的提升。而且，数据读入内存是需要占用buffer pool 的，所以这种方式还能够避免占用内存，提高内存利用率。</p><h2 id="什么条件下可以使用change-buffer呢？"><a href="#什么条件下可以使用change-buffer呢？" class="headerlink" title="什么条件下可以使用change buffer呢？"></a><strong>什么条件下可以使用change buffer呢？</strong></h2><p><strong>对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束</strong>。比如，要插入(4,400)这个记录，就要先判断现在表中是否已经存在k=4的记录，而这<strong>必须要将数据页读入内存才能判断</strong>。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用<code>change buffer</code>了。因此，唯一索引的更新就不能使用 <code>change buffer</code>，实际上也<strong>只有普通索引可以使用</strong>。</p><p><code>change buffer</code> 用的是 <code>buffer pool</code> 里的内存，因此不能无限增大。<code>change buffer</code> 的大小，可以通过参数<code>innodb_change_buffer_max_size</code> 来动态设置。这个参数设置为50的时候，表示<code>change buffer</code>的大小最多只能占用 <code>buffer pool</code> 的50%。</p><p><strong>如果要在这张表中插入一个新记录(4,400)的话，InnoDB的处理流程是怎样的？</strong></p><p>第一种情况是，<strong>这个记录要更新的目标页在内存中</strong>。这时，InnoDB的处理流程如下：</p><ul><li>对于唯一索引来说，找到3和5之间的位置，判断到没有冲突，插入这个值，语句执行结束；</li><li>对于普通索引来说，找到3和5之间的位置，插入这个值，语句执行结束。</li></ul><p>这样看来，普通索引和唯一索引对更新语句性能影响的差别，只是一个判断，只会耗费微小的CPU时间。但，这不是我们关注的重点。</p><p>第二种情况是，<strong>这个记录要更新的目标页不在内存中</strong>。这时，InnoDB的处理流程如下：</p><ul><li>对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束；</li><li>对于普通索引来说，则是将更新记录在change buffer，语句执行就结束了。</li></ul><p><strong>将数据从磁盘读入内存涉及随机IO的访问，是数据库里面成本最高的操作之一</strong>。change buffer 因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的。</p><p>之前我就碰到过一件事儿，有个DBA的同学跟我反馈说，他负责的某个业务的库内存命中率突然从99%降低到了75%，整个系统处于阻塞状态，更新语句全部堵住。而探究其原因后，我发现这个业务有大量插入数据的操作，而他在前一天把其中的某个普通索引改成了唯一索引。</p><h2 id="change-buffer的使用场景"><a href="#change-buffer的使用场景" class="headerlink" title="change buffer的使用场景"></a><strong>change buffer的使用场景</strong></h2><p>通过上面的分析，你已经清楚了使用 <code>change buffer</code> 对更新过程的加速作用，也清楚了 <code>change buffer</code> 只限于用在普通索引的场景下，而不适用于唯一索引。那么，现在有一个问题就是：<em>普通索引的所有场景，使用change buffer都可以起到加速作用吗？</em></p><p>因为 <code>merge</code> 的时候是真正进行数据更新的时刻，而 <code>change buffer</code> 的主要目的就是<strong>将记录的变更动作缓存下来</strong>，所以在一个数据页做<code>merge</code>之前，<code>change buffer</code>记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大。因此，对于<strong>写多读少</strong>的业务来说，页面在写完以后马上被访问到的概率比较小，此时change buffer的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。</p><p>反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在change buffer，但之后由于马上要访问这个数据页，会立即触发merge过程。这样随机访问IO的次数不会减少，反而增加了change buffer的维护代价。所以，对于这种业务模式来说，change buffer反而起到了副作用。</p><h2 id="索引选择和实践"><a href="#索引选择和实践" class="headerlink" title="索引选择和实践"></a><strong>索引选择和实践</strong></h2><p>其实，普通索引和唯一索引，这两类索引在查询能力上是没差别的，主要考虑的是对更新性能的影响。所以，我建议你<strong>尽量选择普通索引</strong>。</p><p>如果所有的更新后面，都马上伴随着对这个记录的查询，那么你应该关闭 change buffer。而在其他情况下，change buffer 都能提升更新性能。在实际使用中，你会发现，普通索引和 change buffer 的配合使用，对于数据量大的表的更新优化还是很明显的。</p><p>特别地，在使用机械硬盘时，change buffer 这个机制的收效是非常显著的。所以，当你有一个类似“历史数据”的库，并且出于成本考虑用的是机械硬盘时，那你应该特别关注这些表里的索引，尽量使用普通索引，然后把 change buffer 尽量开大，以确保这个“历史数据”表的数据写入速度。</p><h2 id="change-buffer-和-redo-log"><a href="#change-buffer-和-redo-log" class="headerlink" title="change buffer 和 redo log"></a><strong>change buffer 和 redo log</strong></h2><p>理解了change buffer的原理，你可能会联想到我在前面文章中和你介绍过的redo log和WAL。在前面文章的评论中，我发现有同学混淆了redo log和change buffer。</p><p>WAL 提升性能的核心机制，也的确是尽量减少随机读写，这两个概念确实容易混淆。所以，这里我把它们放到了同一个流程里来说明，便于你区分这两个概念。</p><p>现在，我们要在表上执行这个插入语句：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t(id,k) <span class="keyword">values</span>(id1,k1),(id2,k2);</span><br></pre></td></tr></table></figure><p>假设当前k索引树的状态，查找到位置后，k1所在的数据页在内存(InnoDB buffer pool)中，k2所在的数据页不在内存中。</p><p>如图所示是带change buffer的更新状态图。</p><img src="980a2b786f0ea7adabef2e64fb4c4ca3.png" alt="img" style="zoom:50%;" /><p>分析这条更新语句，你会发现它涉及了四个部分：<strong>内存</strong>、<strong>redo log（ib_log_fileX）</strong>、 <strong>数据表空间（t.ibd）</strong>、<strong>系统表空间（ibdata1）</strong></p><p>这条更新语句做了如下的操作（按照图中的数字顺序）：</p><ol><li>Page 1 在内存中，直接更新内存；</li><li>Page 2 没有在内存中，就在内存的 change buffer 区域，记录下“我要往Page 2插入一行”这个信息</li><li>将上述两个动作记入 redo log 中（图中3和4）。</li></ol><p>做完上面这些，事务就可以完成了。所以，你会看到，执行这条更新语句的成本很低，就是写了两处内存，然后写了一处磁盘（两次操作合在一起写了一次磁盘），而且还是顺序写的。同时，图中的两个虚线箭头，是后台操作，不影响更新的响应时间。</p><p><strong>那在这之后的读请求，要怎么处理呢？</strong></p><p>比如，我们现在要执行 <code>select * from t where k in (k1, k2)</code>。这里，我画了这两个读请求的流程图。</p><p>如果读语句发生在更新语句后不久，内存中的数据都还在，那么此时的这两个读操作就与系统表空间（ibdata1）和 redo log（ib_log_fileX）无关了。所以，我在图中就没画出这两部分。</p><img src="6dc743577af1dbcbb8550bddbfc5f98e.png" alt="img" style="zoom:50%;" /><p>从图中可以看到：</p><ol><li>读 Page 1 的时候，直接从内存返回。</li><li>要读 Page 2 的时候，需要把Page 2从磁盘读入内存中，然后应用change buffer里面的操作日志，生成一个正确的版本并返回结果。</li></ol><p>可以看到，直到需要读Page 2的时候，这个数据页才会被读入内存。所以，如果要简单地对比这两个机制在提升更新性能上的收益的话，<strong>redo log 主要节省的是随机写磁盘的IO消耗（转成顺序写），而change buffer主要节省的则是随机读磁盘的IO消耗。</strong></p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><strong>小结</strong></h2><p>今天，我从普通索引和唯一索引的选择开始，和你分享了数据的查询和更新过程，然后说明了change buffer的机制以及应用场景，最后讲到了索引选择的实践。</p><p>由于唯一索引用不上change buffer的优化机制，因此如果业务可以接受，从性能角度出发我建议你优先考虑非唯一索引。</p><p>评论区大家对“是否使用唯一索引”有比较多的讨论，主要是纠结在“业务可能无法确保”的情况。这里，我再说明一下：</p><ul><li>首先，业务正确性优先。咱们这篇文章的前提是“业务代码已经保证不会写入重复数据”的情况下，讨论性能问题。如果业务不能保证，或者业务就是要求数据库来做约束，那么没得选，必须创建唯一索引。这种情况下，本篇文章的意义在于，如果碰上了大量插入数据慢、内存命中率低的时候，可以给你多提供一个排查思路。</li><li>然后，在一些“归档库”的场景，你是可以考虑使用唯一索引的。比如，线上数据只需要保留半年，然后历史数据保存在归档库。这时候，归档数据已经是确保没有唯一键冲突了。要提高归档效率，可以考虑把表里面的唯一索引改成普通索引。</li></ul><p><strong>思考题</strong></p><p>通过图2你可以看到，change buffer一开始是写内存的，那么如果这个时候机器掉电重启，会不会导致change buffer丢失呢？change buffer丢失可不是小事儿，再从磁盘读入数据可就没有了merge过程，就等于是数据丢失了。会不会出现这种情况呢？</p><p>这个问题的答案是不会丢失。</p><p>虽然是只更新内存，但是在事务提交的时候，我们把change buffer的操作也记录到redo log里了，所以崩溃恢复的时候，change buffer也能找回来。</p><p>在评论区有同学问到，merge的过程是否会把数据直接写回磁盘，这是个好问题。这里，我再为你分析一下。</p><p>merge的执行流程是这样的：</p><ol><li>从磁盘读入数据页到内存（老版本的数据页）；</li><li>从change buffer里找出这个数据页的change buffer 记录(可能有多个），依次应用，得到新版数据页；</li><li>写redo log。这个redo log包含了数据的变更和change buffer的变更。</li></ol><p>到这里 merge 过程就结束了。这时候，数据页和内存中change buffer对应的磁盘位置都还没有修改，属于脏页，之后各自刷回自己的物理数据，就是另外一个过程了。</p>]]></content>
    
    
    <summary type="html">MySQL</summary>
    
    
    
    <category term="MySQL实战" scheme="http://example.com/categories/MySQL%E5%AE%9E%E6%88%98/"/>
    
    
    <category term="MySQL" scheme="http://example.com/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>10、MySQL为什么有时候会选错索引</title>
    <link href="http://example.com/2021/04/04/MySQL/10/"/>
    <id>http://example.com/2021/04/04/MySQL/10/</id>
    <published>2021-04-04T14:13:56.000Z</published>
    <updated>2021-04-04T17:07:00.651Z</updated>
    
    <content type="html"><![CDATA[<p><strong>使用哪个索引是由MySQL来确定的</strong></p><p>不知道你有没有碰到过这种情况，一条本来可以执行得很快的语句，却由于MySQL选错了索引，而导致执行速度变得很慢？</p><p>我们一起来看一个例子吧。</p><p>我们先建一个简单的表，表里有a、b两个字段，并分别建上索引：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `t` (</span><br><span class="line">  `id` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `a` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `b` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  <span class="keyword">PRIMARY</span> KEY (`id`),</span><br><span class="line">  KEY `a` (`a`),</span><br><span class="line">  KEY `b` (`b`)</span><br><span class="line">) ENGINE<span class="operator">=</span>InnoDB；</span><br></pre></td></tr></table></figure><p>然后，我们往表t中插入10万行记录，取值按整数递增，即：(1,1,1)，(2,2,2)，(3,3,3) 直到(100000,100000,100000)。</p><p>我是用存储过程来插入数据的，这里我贴出来方便你复现：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">delimiter ;;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">procedure</span> idata()</span><br><span class="line"><span class="keyword">begin</span></span><br><span class="line">  <span class="keyword">declare</span> i <span class="type">int</span>;</span><br><span class="line">  <span class="keyword">set</span> i<span class="operator">=</span><span class="number">1</span>;</span><br><span class="line">  while(i<span class="operator">&lt;=</span><span class="number">100000</span>)do</span><br><span class="line">    <span class="keyword">insert</span> <span class="keyword">into</span> t <span class="keyword">values</span>(i, i, i);</span><br><span class="line">    <span class="keyword">set</span> i<span class="operator">=</span>i<span class="operator">+</span><span class="number">1</span>;</span><br><span class="line">  <span class="keyword">end</span> while;</span><br><span class="line"><span class="keyword">end</span>;;</span><br><span class="line">delimiter ;</span><br><span class="line"><span class="keyword">call</span> idata();</span><br></pre></td></tr></table></figure><p>接下来，我们分析一条SQL语句：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t <span class="keyword">where</span> a <span class="keyword">between</span> <span class="number">10000</span> <span class="keyword">and</span> <span class="number">20000</span>;</span><br></pre></td></tr></table></figure><p>你一定会说，这个语句还用分析吗，很简单呀，a上有索引，肯定是要使用索引a的。你说得没错，图1显示的就是使用explain命令看到的这条语句的执行情况。这条查询语句的执行也确实符合预期，key这个字段值是’a’，表示优化器选择了索引a。</p><img src="/2021/04/04/MySQL/10/2cfce769551c6eac9bfbee0563d48fe3.png" class="" title="img"><p>不过别急，这个案例不会这么简单。在我们已经准备好的包含了10万行数据的表上，我们再做如下操作。</p><img src="1e5ba1c2934d3b2c0d96b210a27e1a1e.png" alt="img" style="zoom:67%;" /><p>session A的操作你已经很熟悉了，它就是开启了一个事务。随后，session B 把数据都删除后，又调用了 idata这个存储过程，插入了10万行数据。这时候，session B的查询语句 <code>select * from t where a between 10000 and 20000</code> 就不会再选择索引a了。我们可以通过慢查询日志（slow log）来查看一下具体的执行情况。</p><p>为了说明优化器选择的结果是否正确，我增加了一个对照，即：使用 <code>force index(a)</code> 来让优化器强制使用索引a（这部分内容，我还会在这篇文章的后半部分中提到）。</p><p>下面的三条SQL语句，就是这个实验过程。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> long_query_time<span class="operator">=</span><span class="number">0</span>;</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t <span class="keyword">where</span> a <span class="keyword">between</span> <span class="number">10000</span> <span class="keyword">and</span> <span class="number">20000</span>; <span class="comment">/*Q1*/</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t force index(a) <span class="keyword">where</span> a <span class="keyword">between</span> <span class="number">10000</span> <span class="keyword">and</span> <span class="number">20000</span>;<span class="comment">/*Q2*/</span></span><br></pre></td></tr></table></figure><ul><li>第一句，是将慢查询日志的阈值设置为0，表示这个线程接下来的语句都会被记录入慢查询日志中；</li><li>第二句，Q1 是session B原来的查询；</li><li>第三句，Q2 是加了force index(a)来和 session B原来的查询语句执行情况对比。</li></ul><p>如图所示是这三条SQL语句执行完成后的慢查询日志。</p><img src="7c58b9c71853b8bba1a8ad5e926de1f6.png" alt="img" style="zoom:67%;" /><p>可以看到，Q1扫描了10万行，显然是走了全表扫描，执行时间是40毫秒。Q2扫描了10001行，执行了21毫秒。也就是说，我们在没有使用force index的时候，MySQL用错了索引，导致了更长的执行时间。</p><p>这个例子对应的是我们平常不断地删除历史数据和新增数据的场景。这时，MySQL竟然会选错索引，是不是有点奇怪呢？今天，我们就从这个奇怪的结果说起吧。 </p><h3 id="优化器的逻辑"><a href="#优化器的逻辑" class="headerlink" title="优化器的逻辑"></a><strong>优化器的逻辑</strong></h3><p>选择索引是优化器的工作。而优化器选择索引的目的，是找到一个最优的执行方案，并用最小的代价去执行语句。</p><p>在数据库里面，扫描行数是影响执行代价的因素之一。扫描的行数越少，意味着访问磁盘数据的次数越少，消耗的CPU资源越少。</p><p>当然，扫描行数并不是唯一的判断标准，优化器还会结合是否使用临时表、是否排序等因素进行综合判断。</p><p><strong>扫描行数是怎么判断的？</strong></p><p>MySQL在真正开始执行语句之前，并不能精确地知道满足这个条件的记录有多少条，而只能根据统计信息来估算记录数。这个统计信息就是索引的“<strong>区分度</strong>”。</p><p>显然，一个索引上不同的值越多，这个索引的区分度就越好。而一个索引上不同的值的个数，我们称之为“基数”（<code>cardinality</code>）。也就是说，这个基数越大，索引的区分度越好。我们可以使用<code>show index</code>方法，看到一个索引的基数。</p><p>如图所示，就是表t的show index 的结果 。虽然这个表的每一行的三个字段值都是一样的，但是在统计信息中，这三个索引的基数值并不同，而且其实都不准确。</p><img src="/2021/04/04/MySQL/10/16dbf8124ad529fec0066950446079d4.png" class="" title="img"><p><strong>MySQL是怎样得到索引的基数的呢？</strong></p><p>把整张表取出来一行行统计，虽然可以得到精确的结果，但是代价太高了，所以只能选择“采样统计”。</p><p>采样统计的时候，InnoDB默认会选择N个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数。而数据表是会持续更新的，索引统计信息也不会固定不变。所以，当变更的数据行数超过1/M的时候，会自动触发重新做一次索引统计。</p><p>在MySQL中，有两种存储索引统计的方式，可以通过设置参数 <code>innodb_stats_persistent</code> 的值来选择：</p><ul><li>设置为on的时候，表示统计信息会持久化存储。这时，默认的N是20，M是10。</li><li>设置为off的时候，表示统计信息只存储在内存中。这时，默认的N是8，M是16。</li></ul><p>由于是采样统计，所以不管N是20还是8，这个基数都是很容易不准的。索引统计值（cardinality列）虽然不够精确，但大体上还是差不多的，选错索引一定还有别的原因。其实索引统计只是一个输入，对于一个具体的语句来说，优化器还要判断，执行这个语句本身要扫描多少行。</p><p>接下来，我们再一起看看优化器预估的，这两个语句的扫描行数是多少。</p><img src="/2021/04/04/MySQL/10/e2bc5f120858391d4accff05573e1289.png" class="" title="img"><p>rows这个字段表示的是预计扫描行数。其中，Q1的结果还是符合预期的，rows的值是104620；但是Q2的rows值是37116，偏差就大了。而图1中我们用explain命令看到的rows是只有10001行，是这个偏差误导了优化器的判断。</p><p>优化器为什么放着扫描37000行的执行计划不用，却选择了扫描行数是100000的执行计划呢？</p><p>这是因为，如果使用索引a，每次从索引a上拿到一个值，都要回到主键索引上查出整行数据，这个代价优化器也要算进去的。而如果选择扫描10万行，是直接在主键索引上扫描的，没有额外的代价。</p><p>优化器会估算这两个选择的代价，从结果看来，优化器认为直接扫描主键索引更快。当然，从执行时间看来，这个选择并不是最优的。使用普通索引需要把回表的代价算进去，在图1执行explain的时候，也考虑了这个策略的代价 ，但图1的选择是对的。也就是说，这个策略并没有问题。</p><p>既然是统计信息不对，那就修正。analyze table t 命令，可以用来重新统计索引信息。我们来看一下执行效果。</p><img src="/2021/04/04/MySQL/10/209e9d3514688a3bcabbb75e54e1e49c.png" class="" title="img"><p>所以在实践中，如果你发现explain的结果预估的rows值跟实际情况差距比较大，可以采用这个方法来处理。其实，如果只是索引统计不准确，通过analyze命令可以解决很多问题，但是前面我们说了，优化器可不止是看扫描行数。</p><p><code>select * from t where (a between 1 and 1000)  and (b between 50000 and 100000) order by b limit 1;</code></p><p>从条件上看，这个查询没有符合条件的记录，因此会返回空集合。在开始执行这条语句之前，你可以先设想一下，如果你来选择索引，会选择哪一个呢？为了便于分析，我们先来看一下a、b这两个索引的结构图。</p><img src="1d037f92063e800c3bfff3f4dbf1a2b9.png" alt="img" style="zoom:67%;" /><p>如果使用索引a进行查询，那么就是扫描索引a的前1000个值，然后取到对应的id，再到主键索引上去查出每一行，然后根据字段b来过滤。显然这样需要扫描1000行。</p><p>如果使用索引b进行查询，那么就是扫描索引b的最后50001个值，与上面的执行过程相同，也是需要回到主键索引上取值再判断，所以需要扫描50001行。</p><p>所以你一定会想，如果使用索引a的话，执行速度明显会快很多。那么，下面我们就来看看到底是不是这么一回事儿。执行explain的结果如下图</p><img src="/2021/04/04/MySQL/10/483bcb1ef3bb902844e80d9cbdd73ab8.png" class="" title="img"><p>可以看到，返回结果中key字段显示，这次优化器选择了索引b，而rows字段显示需要扫描的行数是50198。从这个结果中，你可以得到两个结论：扫描行数的估计值依然不准确；这个例子里MySQL又选错了索引。</p><p><strong>索引选择异常和处理</strong></p><p>其实大多数时候优化器都能找到正确的索引，但偶尔你还是会碰到我们上面举例的这两种情况：原本可以执行得很快的SQL语句，执行速度却比你预期的慢很多，你应该怎么办呢？</p><p><strong>第一种方法是，像我们第一个例子一样，采用force index强行选择一个索引。</strong></p><p><strong>第二种方法是，我们可以考虑修改语句，引导MySQL使用我们期望的索引****。</strong></p><p><strong>第三种方法是，在有些场景下，我们可以新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。</strong></p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a><strong>小结</strong></h3><p>今天我们一起聊了聊索引统计的更新机制，并提到了优化器存在选错索引的可能性。</p><p>对于由于索引统计信息不准确导致的问题，你可以用analyze table来解决。</p><p>而对于其他优化器误判的情况，你可以在应用端用force index来强行指定索引，也可以通过修改语句来引导优化器，还可以通过增加或者删除索引来绕过这个问题。</p><h3 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a><strong>思考题</strong></h3><p>前面我们在构造第一个例子的过程中，通过session A的配合，让session B删除数据后又重新插入了一遍数据，然后就发现explain结果中，rows字段从10001变成37000多。</p><p>而如果没有session A的配合，只是单独执行delete from t 、call idata()、explain这三句话，会看到rows字段其实还是10000左右。你可以自己验证一下这个结果。</p><p>这是什么原因呢？也请你分析一下吧。</p><p>delete 语句删掉了所有的数据，然后再通过call idata()插入了10万行数据，看上去是覆盖了原来的10万行。但是，session A开启了事务并没有提交，所以之前插入的10万行数据是不能删除的。这样，之前的数据每一行数据都有两个版本，旧版本是delete之前的数据，新版本是标记为deleted的数据。</p><p>这样，索引a上的数据其实就有两份。然后你会说，不对啊，主键上的数据也不能删，那没有使用force index的语句，使用explain命令看到的扫描行数为什么还是100000左右？（潜台词，如果这个也翻倍，也许优化器还会认为选字段a作为索引更合适）</p><p>是的，不过这个是主键，主键是直接按照表的行数来估计的。而表的行数，优化器直接用的是show table status的值。</p><p>这个值的计算方法，我会在后面有文章为你详细讲解。</p><img src="/2021/04/04/MySQL/10/%E6%88%AA%E5%9B%BE-1616842483382.png" class="" title="img">]]></content>
    
    
    <summary type="html">MySQL</summary>
    
    
    
    <category term="MySQL实战" scheme="http://example.com/categories/MySQL%E5%AE%9E%E6%88%98/"/>
    
    
    <category term="MySQL" scheme="http://example.com/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>0、重新理解晋升</title>
    <link href="http://example.com/2021/04/04/%E6%99%8B%E5%8D%87/0/"/>
    <id>http://example.com/2021/04/04/%E6%99%8B%E5%8D%87/0/</id>
    <published>2021-04-04T14:13:56.000Z</published>
    <updated>2021-04-05T09:41:06.125Z</updated>
    
    <content type="html"><![CDATA[<h2 id="晋升体系"><a href="#晋升体系" class="headerlink" title="晋升体系"></a>晋升体系</h2><p>我会为你介绍职业等级体系和晋升的流程、原则、逻辑，然后结合自己总结的 COMD  能力评估模型，带你看透不同级别的要求。学完这一部分，你就能理解公司的晋升是怎样运作的，什么样的人可以晋升，怎么做才能更好地晋升。</p><h2 id="职级详解"><a href="#职级详解" class="headerlink" title="职级详解"></a>职级详解</h2><p>我会结合 COMD 能力模型，为你详细地解读从 P5 到 P9  每个级别的具体能力要求，以及每个级别晋升的关键点和技巧。学完这一部分，你就能“对号入座”，根据自己的级别做清晰明确的规划，采取更有效的行动来提升晋升的效率。</p><h2 id="晋升技巧"><a href="#晋升技巧" class="headerlink" title="晋升技巧"></a>晋升技巧</h2><p>我针对面评中的几个关键步骤，分享了很多实战技巧，包括怎么写 PPT、怎么讲  PPT、怎么回应答辩问题等等。学完这一部分，你就能充分地展现自己的能力，发挥出应有的水平。</p><h2 id="学习方法"><a href="#学习方法" class="headerlink" title="学习方法"></a>学习方法</h2><p>我总结了一套系统的学习方法论，涵盖时间管理、任务拆解、技术提升等多个维度，其中有很多我个人独创的理念和技巧。学完这一部分，你不但可以高效地提升能力，而且可以让自己的技能兼具深度、宽度和广度，更容易在晋升答辩的时候打动评委。</p><h2 id="做事方法"><a href="#做事方法" class="headerlink" title="做事方法"></a>做事方法</h2><p>我系统地总结了经过大量实践验证的做事方法，涵盖端到端的做事流程，包括定目标、执行、总结、汇报和复盘等环节。学完这一部分，你既能够在平时拿到更好的绩效，又能够在答辩的时候充分展现你的做事水平。</p><h2 id="专项提升"><a href="#专项提升" class="headerlink" title="专项提升"></a>专项提升</h2><p>随着级别的提升，理解业务和管理团队的能力越来越重要，而技术人员恰好缺少这方面的知识和经验。我把自己在业务和管理两大领域的技能和经验积累，提炼成了快速入门的套路。学完这一部分，你能更有效地掌握不同级别所需的业务理解能力，以及 50 人以内团队的管理技巧。</p><p>第一步，先完整地跟着课程的节奏学习一遍，对晋升形成整体的认知。</p><p>第二步，根据自己当前的情况，按图索骥寻找对应的章节深入学习并实践。</p><p>第三步，当你有了一定的实践经验之后，再来重新学习对应的章节，做到“知行合一”。</p><img src="image-20210210232147188-1617552212473.png" alt="image-20210210232147188-1617552212473" style="zoom:67%;" />]]></content>
    
    
    <summary type="html">晋升</summary>
    
    
    
    <category term="大厂晋升指南" scheme="http://example.com/categories/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97/"/>
    
    
    <category term="晋升" scheme="http://example.com/tags/%E6%99%8B%E5%8D%87/"/>
    
  </entry>
  
  <entry>
    <title>06、职级档次：你现在应该具备的核心能力是什么？</title>
    <link href="http://example.com/2021/04/04/%E6%99%8B%E5%8D%87/06/"/>
    <id>http://example.com/2021/04/04/%E6%99%8B%E5%8D%87/06/</id>
    <published>2021-04-04T14:13:56.000Z</published>
    <updated>2021-04-04T16:54:58.686Z</updated>
    
    <content type="html"><![CDATA[<img src="image-20210210232147188-1617552212473.png" alt="image-20210210232147188" style="zoom: 50%;" /><h2 id="P5-P6：专业工匠P5-P6"><a href="#P5-P6：专业工匠P5-P6" class="headerlink" title="P5/P6：专业工匠P5/P6"></a>P5/P6：专业工匠P5/P6</h2><p><strong>核心能力是完成任务</strong>。P5 和 P6 的职责一样，比较简单，不需要太多解读。这两个级别的区别是，P5 需要在别人的指导下完成工作，而 P6  可以独立完成工作。其实只要有意愿在技术领域发展，基本上每个人都能达到 P6 的水平。</p><p>P5/P6 的核心职责如下表所示。</p><img src="image-20210210232318771-1617552217405.png" alt="image-20210210232318771" style="zoom: 67%;" /><h2 id="P7-P8：乐团指挥P7-P8"><a href="#P7-P8：乐团指挥P7-P8" class="headerlink" title="P7/P8：乐团指挥P7/P8"></a>P7/P8：乐团指挥P7/P8</h2><p><strong>核心能力是指挥团队</strong></p><p>为什么我要这么类比呢？因为 P7/P8  的职责和乐团指挥的职责非常相似。</p><p>乐团指挥的核心工作职责，具体可以分为三个阶段：</p><p>第一阶段是总谱研究，对总谱进行深入细致的研究分析，识别和标注演奏的重点、难点和风险点。</p><p>第二阶段是排练准备，明确演奏需要的人手和乐器，根据乐团情况制定排练计划。</p><p>第三阶段是正式排练，拆解具体排练步骤（比如个体练习、分声部练习和全体排练等），抓好每一个关键环节的落实，做好风险预防措施，推动整个乐团完成演奏。</p><p>P7/P8  的任务和乐团指挥非常像，也可以分为三个阶段，跟乐团指挥的三个阶段正好一一对应。你只要把总谱换成团队的工作目标，把人手和乐器换成资源，把演奏排练换成工作目标落地就行了。首先是分析阶段，对应乐团指挥的总谱研究；然后是计划阶段，对应排练准备；最后是落地阶段，对应正式排练。我把这个对应关系总结在了下面的表格里。</p><img src="image-20210210232537356.png" alt="image-20210210232537356" style="zoom:67%;" /><p>P7/P8 的核心职责如下表所示</p><img src="image-20210210233058104.png" alt="image-20210210233058104" style="zoom:67%;" /><h2 id="P9-P10：电影导演P9-P10"><a href="#P9-P10：电影导演P9-P10" class="headerlink" title="P9/P10：电影导演P9/P10"></a>P9/P10：电影导演P9/P10</h2><p><strong>核心能力是导演作品</strong></p><p>P9/P10  的工作跟电影导演很像，具体表现在三个方面：</p><p>第一，他们的工作都具有一定的规模。比如说你只是拍一段 60 秒的  vlog，还算不上电影导演；真正的电影导演拍出来的是几十分钟以上，剧本、服饰、化妆、道具、表演、运镜和剪辑都非常成熟的作品。同样地，P5～P8  这几个级别的工作都会产出一些成果，但这些成果在规模上还不足以跟 P9/P10  这个级别相比。</p><p>第二，他们都是总决策者。在一个剧组里，一般情况下导演就是老大，有绝对的话语权。同样地，虽然 P6 可以指导别人，P7/P8  可以带团队，但工作仍然会在很大程度上受到制约，关键的目标制定、资源整合和关键决策的工作，还是得由 P9/P10 来完成。具体一点说，P9/P10 需要制定有挑战的业务目标；整合不同的团队，包括多个技术团队（比如 Android、iOS、前端、Java  后端、测试、运维等）和多个业务团队（比如腾讯的广告平台的某个业务，可能涉及  QQ、微信和应用宝等多个业务团队）；做出关键决策（例如要做什么、不做什么、先做什么和后做什么等）。</p><p>第三，他们都是总负责人。一部电影作品会打上导演的烙印，甚至呈现出强烈的导演个人风格。电影拍得不好，观众第一个骂的就是导演；拍得好，赞美和荣誉也首先给到导演身上。同样地，P9/P10  的水平、眼界、价值观和做事风格，直接决定了一条业务线的质量，因为这些因素会体现在工作过程中的各种决策里面，决定了最终的呈现效果。另外，导演往往有自己擅长的题材，比如文艺片、喜剧片；而 P9/P10 一般也都聚焦于某个业务或者专业领域，比如电商业务、出行业务、安全领域、算法领域，很少有跨领域样样精通的人才。</p><p>P9 和 P10  的核心差异在于成果质量。我还是拿电影导演来类比，P9 是成熟的导演，能拍出 7 分以上的作品（基本合格）；P10 是成名的导演，能拍出 8  分以上的作品（比较优质）。虽然对于 P9/P10  的工作成果，并没有一个通用的打分机制，但是公司能通过一些硬指标来衡量，最典型的就是直接看业务结果。如果你负责的业务结果实现了既定的业务目标，那么你就是成熟的导演，可以胜任 P9；如果你负责的业务结果按照某个标准（用户量、收入和权威机构的测评等），进入了业界前列，有一定的名气和影响力，那么你就是成名的导演，可以胜任 P10。</p><p>P9/P10 的核心职责如下表所示。</p><img src="image-20210210234946963.png" alt="image-20210210234946963" style="zoom:67%;" />]]></content>
    
    
    <summary type="html">晋升</summary>
    
    
    
    <category term="大厂晋升指南" scheme="http://example.com/categories/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97/"/>
    
    
    <category term="晋升" scheme="http://example.com/tags/%E6%99%8B%E5%8D%87/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://example.com/2021/04/04/HelloWorld/hello-world/"/>
    <id>http://example.com/2021/04/04/HelloWorld/hello-world/</id>
    <published>2021-04-03T18:21:31.614Z</published>
    <updated>2021-04-04T17:47:30.506Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p><img src="/2021/04/04/HelloWorld/hello-world/image-20210405003053970.png" class="" title="image-20210405003053970"><img src="hello-world/image-20210405003053970.png" alt="image-20210405003053970" style="zoom:67%;" /><img src="hello-world.assets/image-20210405014043517.png" alt="image-20210405014043517" style="zoom:50%;" /><p><img src="image-20210405014348925.png" alt="image-20210405014348925"></p><img src="image-20210405014352483.png" alt="image-20210405014352483" style="zoom:67%;" />]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.io/docs/&quot;&gt;documentation&lt;/a&gt; for</summary>
      
    
    
    
    
  </entry>
  
</feed>
