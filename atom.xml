<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>HelloWorld</title>
  
  
  <link href="http://universeinheart.github.io/atom.xml" rel="self"/>
  
  <link href="http://universeinheart.github.io/"/>
  <updated>2021-04-17T09:18:32.736Z</updated>
  <id>http://universeinheart.github.io/</id>
  
  <author>
    <name>xjf</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>00、Netty基础</title>
    <link href="http://universeinheart.github.io/2021/04/16/Netty/01/"/>
    <id>http://universeinheart.github.io/2021/04/16/Netty/01/</id>
    <published>2021-04-16T15:26:37.000Z</published>
    <updated>2021-04-17T09:18:32.736Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>学习本课程的目标</p><ol><li>掌握<code>Java</code>网络编程基础知识和原理</li><li>使用<code>Netty</code>构建一个<code>Java</code>网络服务器</li><li>熟悉<code>Netty</code>核心源码以及深层原理</li><li>熟练诊断、分析并排查<code>Netty</code>使用中的故障</li></ol></blockquote><ul><li>本质：网络应用程序框架</li><li>实现：异步，事件驱动</li><li>特性：高性能、可维护、快速开发</li><li>用途：开发服务器和客户端</li></ul><img src="/2021/04/16/Netty/01/image-20210416233502685.png" class="" title="image-20210416233502685"><p>第一章、<code>Netty</code> 背景，现状与趋势</p><p>第二章、<code>Netty</code> 源码，从领域知识的角度剖析</p><p>第三章、<code>Netty</code> 源码，从请求处理的角度剖析</p><p>第四章、<code>Netty</code> 实战入门，写一个玩具项目</p><p>第五章、<code>Netty</code> 实战进阶，把玩具变产品</p><p>第六章、成为<code>Netty</code> 贡献者</p><h2 id="经典的三种IO模型"><a href="#经典的三种IO模型" class="headerlink" title="经典的三种IO模型"></a>经典的三种IO模型</h2><blockquote><p>BIO 同步阻塞方式</p><p>NIO 同步非阻塞方式</p><p>AIO 异步非阻塞方式</p></blockquote><img src="/2021/04/16/Netty/01/image-20210417142957552.png" class="" title="image-20210417142957552"><h4 id="阻塞与非阻塞"><a href="#阻塞与非阻塞" class="headerlink" title="阻塞与非阻塞"></a>阻塞与非阻塞</h4><ul><li>菜没好，要不要死等 -&gt; 数据就绪前要不要等待？</li><li>没有数据传过来时，读会阻塞直到有数据；缓冲区满时，写操作也会阻塞。</li><li>非阻塞遇到这些情况，都是直接返回。</li></ul><h4 id="同步与异步"><a href="#同步与异步" class="headerlink" title="同步与异步"></a>同步与异步</h4><ul><li>菜好了，谁端 -&gt; 数据就绪后，数据操作谁完成？</li><li>数据就绪后需要自己去读是同步</li><li>数据就绪直接读好再回调给程序是异步</li></ul><h3 id="为什么Netty目前只支持NIO"><a href="#为什么Netty目前只支持NIO" class="headerlink" title="为什么Netty目前只支持NIO"></a>为什么Netty目前只支持NIO</h3><p>为什么不建议使用BIO？</p><ul><li>连接数高的情况下：阻塞-&gt; 耗资源、效率低</li></ul><p>为什么删掉已经做好的AIO？</p><ul><li>Windows实现成熟，但是很少用来做服务器。</li><li>Linux常用来做服务器，但是AIO实现不够成熟。</li><li>Linux下AIO相比较NIO的性能提升不明显</li></ul><h2 id="Reactor的三种版本"><a href="#Reactor的三种版本" class="headerlink" title="Reactor的三种版本"></a>Reactor的三种版本</h2><p>Reactor是一种开发模式， 模式的核心流程：</p><ol><li>注册感兴趣的事件</li><li>扫描是否有感兴趣的事件发生</li><li>事件发生后作出相应的处理</li></ol><img src="/2021/04/16/Netty/01/image-20210417145140095.png" class="" title="image-20210417145140095"><h4 id="Reactor模式V1：单线程"><a href="#Reactor模式V1：单线程" class="headerlink" title="Reactor模式V1：单线程"></a>Reactor模式V1：单线程</h4><img src="/2021/04/16/Netty/01/image-20210417150923036.png" class="" title="image-20210417150923036"><h4 id="Reactor模式V2：多线程"><a href="#Reactor模式V2：多线程" class="headerlink" title="Reactor模式V2：多线程"></a>Reactor模式V2：多线程</h4><img src="/2021/04/16/Netty/01/image-20210417150944752.png" class="" title="image-20210417150944752"><h4 id="Reactor模式V3：主从多线程"><a href="#Reactor模式V3：主从多线程" class="headerlink" title="Reactor模式V3：主从多线程"></a>Reactor模式V3：主从多线程</h4><img src="/2021/04/16/Netty/01/image-20210417151004621.png" class="" title="image-20210417151004621"><h4 id="如何在Netty中使用Reactor模式"><a href="#如何在Netty中使用Reactor模式" class="headerlink" title="如何在Netty中使用Reactor模式"></a>如何在Netty中使用Reactor模式</h4><img src="/2021/04/16/Netty/01/image-20210417151230262.png" class="" title="image-20210417151230262"><h2 id="解析Netty对Reactor模式支持的常见疑问"><a href="#解析Netty对Reactor模式支持的常见疑问" class="headerlink" title="解析Netty对Reactor模式支持的常见疑问"></a>解析Netty对Reactor模式支持的常见疑问</h2><h4 id="Netty如何支持主从Reactor模式的？"><a href="#Netty如何支持主从Reactor模式的？" class="headerlink" title="Netty如何支持主从Reactor模式的？"></a>Netty如何支持主从Reactor模式的？</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//io.netty.bootstrap.ServerBootstrap#group(io.netty.channel.EventLoopGroup, io.netty.channel.EventLoopGroup)</span></span><br><span class="line">    <span class="keyword">volatile</span> EventLoopGroup group;</span><br><span class="line"><span class="function"><span class="keyword">public</span> ServerBootstrap <span class="title">group</span><span class="params">(EventLoopGroup parentGroup, EventLoopGroup childGroup)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 对group进行赋值</span></span><br><span class="line">        <span class="keyword">super</span>.group(parentGroup);</span><br><span class="line">        ObjectUtil.checkNotNull(childGroup, <span class="string">&quot;childGroup&quot;</span>);</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">this</span>.childGroup != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(<span class="string">&quot;childGroup set already&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">this</span>.childGroup = childGroup;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">   <span class="comment">//io.netty.bootstrap.AbstractBootstrap#initAndRegister</span></span><br><span class="line">    <span class="comment">//开始register</span></span><br><span class="line">   <span class="comment">// parentGroup 绑定 channel  -&gt;  NioServerSocketChannel</span></span><br><span class="line">        ChannelFuture regFuture = config().group().register(channel);</span><br><span class="line">        <span class="keyword">if</span> (regFuture.cause() != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">if</span> (channel.isRegistered()) &#123;</span><br><span class="line">                channel.close();</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                channel.unsafe().closeForcibly();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//io.netty.bootstrap.ServerBootstrap.ServerBootstrapAcceptor#channelRead</span></span><br><span class="line"><span class="comment">// msg -&gt; NioSocketChannel</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">channelRead</span><span class="params">(ChannelHandlerContext ctx, Object msg)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">final</span> Channel child = (Channel) msg;</span><br><span class="line"></span><br><span class="line">            child.pipeline().addLast(childHandler);</span><br><span class="line"></span><br><span class="line">            setChannelOptions(child, childOptions, logger);</span><br><span class="line">            setAttributes(child, childAttrs);</span><br><span class="line"></span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="comment">// childGroup 绑定 channel  -&gt;  NioSocketChannel</span></span><br><span class="line">                childGroup.register(child).addListener(<span class="keyword">new</span> ChannelFutureListener() &#123;</span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">operationComplete</span><span class="params">(ChannelFuture future)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                        <span class="keyword">if</span> (!future.isSuccess()) &#123;</span><br><span class="line">                            forceClose(child, future.cause());</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">                forceClose(child, t);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="为什么说Netty的main-reactor-大多并不能用到一个线程组，只能线程组里面的一个？"><a href="#为什么说Netty的main-reactor-大多并不能用到一个线程组，只能线程组里面的一个？" class="headerlink" title="为什么说Netty的main reactor 大多并不能用到一个线程组，只能线程组里面的一个？"></a>为什么说Netty的main reactor 大多并不能用到一个线程组，只能线程组里面的一个？</h4><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 绑定地址和端口</span></span><br><span class="line">io.netty.bootstrap.AbstractBootstrap#doBind </span><br><span class="line">   |</span><br><span class="line">   v</span><br><span class="line"><span class="comment">// parentGroup 绑定 channel  -&gt;  NioServerSocketChannel</span></span><br><span class="line">io.netty.bootstrap.AbstractBootstrap#initAndRegister</span><br></pre></td></tr></table></figure><p>因为服务一般只绑定一个端口，<code>doBind</code>只会调用一次，所以<code>initAndRegister</code>只调用一次</p><h4 id="Netty给Channel-分配NIO-event-loop-的规则是什么？"><a href="#Netty给Channel-分配NIO-event-loop-的规则是什么？" class="headerlink" title="Netty给Channel 分配NIO event loop 的规则是什么？"></a>Netty给Channel 分配NIO event loop 的规则是什么？</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// NioEventLoopGroup 继承 MultithreadEventLoopGroup</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//io.netty.channel.MultithreadEventLoopGroup#register(io.netty.channel.Channel)</span></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> ChannelFuture <span class="title">register</span><span class="params">(Channel channel)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// next()方法根据下面的选择器中next方法选择一个NioEventLoop，将channel绑定到上面</span></span><br><span class="line">    <span class="keyword">return</span> next().register(channel);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// executors -&gt; NioEventLoop[]</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> EventExecutorChooser <span class="title">newChooser</span><span class="params">(EventExecutor[] executors)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//根据待绑定的executor是否是2的幂次方，做出不同的选择</span></span><br><span class="line">    <span class="keyword">if</span> (isPowerOfTwo(executors.length)) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> PowerOfTwoEventExecutorChooser(executors);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> GenericEventExecutorChooser(executors);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="通用模式的NIO-实现多路复用器是怎么跨平台的？"><a href="#通用模式的NIO-实现多路复用器是怎么跨平台的？" class="headerlink" title="通用模式的NIO 实现多路复用器是怎么跨平台的？"></a>通用模式的NIO 实现多路复用器是怎么跨平台的？</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//SelectorProvider.provider 不同的JDK有不同的实现 </span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">NioEventLoopGroup</span><span class="params">(<span class="keyword">int</span> nThreads, ThreadFactory threadFactory)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">this</span>(nThreads, threadFactory, SelectorProvider.provider());</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">Netty基础</summary>
    
    
    
    <category term="Netty" scheme="http://universeinheart.github.io/categories/Netty/"/>
    
    
    <category term="网络" scheme="http://universeinheart.github.io/tags/%E7%BD%91%E7%BB%9C/"/>
    
    <category term="Netty" scheme="http://universeinheart.github.io/tags/Netty/"/>
    
  </entry>
  
  <entry>
    <title>09、Redis 切片集群</title>
    <link href="http://universeinheart.github.io/2021/04/16/Redis/09/"/>
    <id>http://universeinheart.github.io/2021/04/16/Redis/09/</id>
    <published>2021-04-16T14:00:00.000Z</published>
    <updated>2021-04-16T14:49:06.307Z</updated>
    
    <content type="html"><![CDATA[<p>在使用 <code>RDB</code> 进行持久化时，Redis 会  <code>fork</code> 子进程来完成，<code>fork</code> 操作的用时和 Redis 的数据量是 <strong>正相关</strong> 的，而 fork 在执行时会阻塞主线程。数据量越大，<code>fork</code>  操作造成的主线程阻塞的时间越长。所以，在使用 RDB 对 25GB 的数据进行持久化时，数据量较大，后台运行的子进程在 fork  创建时阻塞了主线程，于是就导致 Redis 响应变慢了。</p><p>切片集群，也叫分片集群，就是指启动多个  Redis 实例组成一个集群，然后按照一定的规则，把收到的数据划分成多份，每一份用一个实例来保存。 在切片集群中，实例在为 5GB 数据生成 RDB 时，数据量就小了很多，fork 子进程一般不会给主线程带来较长时间的阻塞。采用多个实例保存数据切片后，我们既能保存 25GB 数据，又避免了 fork 子进程阻塞主线程而导致的响应突然变慢。</p><h2 id="数据切片和实例的对应分布关系"><a href="#数据切片和实例的对应分布关系" class="headerlink" title="数据切片和实例的对应分布关系"></a>数据切片和实例的对应分布关系</h2><p><code>Redis Cluster</code> 方案中就规定了数据和实例的对应规则。</p><p><code>Redis Cluster</code>  方案采用哈希槽（<code>Hash Slot</code>，接下来我会直接称之为 <code>Slot</code>），来处理数据和实例之间的映射关系。在 <code>Redis Cluster</code>  方案中，一个切片集群共有 <code>16384</code> 个哈希槽，这些哈希槽类似于数据分区，每个键值对都会根据它的 key，被映射到一个哈希槽中。</p><p>首先根据键值对的 key，按照 <code>CRC16</code> 算法计算一个 16 bit 的值；然后，再用这个 16bit 值对 <code>16384</code> 取模，得到 0~16383 范围内的模数，每个模数代表一个相应编号的哈希槽</p><p>在部署 <code>Redis Cluster</code> 方案时，可以使用 <code>cluster create</code> 命令创建集群，此时，Redis 会自动把这些槽平均分布在集群实例上。例如，如果集群中有 N 个实例，那么，每个实例上的槽个数为 16384/N 个。我们也可以使用 <code>cluster meet</code> 命令手动建立实例间的连接，形成集群，再使用 <code>cluster addslots</code> 命令，指定每个实例上的哈希槽个数。<strong>在手动分配哈希槽时，需要把 16384 个槽都分配完，否则 Redis 集群无法正常工作。</strong></p><h2 id="客户端如何定位数据？"><a href="#客户端如何定位数据？" class="headerlink" title="客户端如何定位数据？"></a>客户端如何定位数据？</h2><blockquote><p>客户端为什么可以在访问任何一个实例时，都能获得所有的哈希槽信息呢？</p><p>这是因为，Redis 实例会把自己的哈希槽信息发给和它相连接的其它实例，来完成哈希槽分配信息的扩散。当实例之间相互连接后，每个实例就有所有哈希槽的映射关系了。</p><p>客户端收到哈希槽信息后，会把哈希槽信息缓存在本地。当客户端请求键值对时，会先计算键所对应的哈希槽，然后就可以给相应的实例发送请求了。</p></blockquote><p>实例和哈希槽的对应关系变更：</p><p>1、在集群中，实例有新增或删除，Redis 需要重新分配哈希槽。</p><p>2、为了负载均衡，Redis 需要把哈希槽在所有实例上重新分布一遍。</p><blockquote><p>客户端是无法主动感知最新的哈希槽分配信息，怎么办？</p><p>答：Redis Cluster 方案提供了一种重定向机制，当客户端把一个键值对的操作请求发给一个实例时，如果这个实例上并没有这个键值对映射的哈希槽，那么，这个实例就会给客户端返回下面的 <code>MOVED</code> 命令响应结果，这个结果中就包含了新实例的访问地址。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; MOVED 命令表示，客户端请求的键值对所在的哈希槽 13320，实际是在 172.16.19.5 这个实例上</span><br><span class="line">GET hello:key</span><br><span class="line">(error) MOVED 13320 172.16.19.5:6379</span><br></pre></td></tr></table></figure><img src="/2021/04/16/Redis/09/image-20210119151846324.png" class="" title="image-20210119151846324">]]></content>
    
    
    <summary type="html">数据增多了，是该加内存还是加实例？</summary>
    
    
    
    <category term="极客时间Redis实战" scheme="http://universeinheart.github.io/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4Redis%E5%AE%9E%E6%88%98/"/>
    
    
    <category term="Redis" scheme="http://universeinheart.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>11、Redis String 为什么不好用了？</title>
    <link href="http://universeinheart.github.io/2021/04/16/Redis/10/"/>
    <id>http://universeinheart.github.io/2021/04/16/Redis/10/</id>
    <published>2021-04-16T14:00:00.000Z</published>
    <updated>2021-04-16T14:53:52.340Z</updated>
    
    <content type="html"><![CDATA[<p>String 类型并不是适用于所有场合的，它有一个明显的短板，就是它 <strong>保存数据时所消耗的内存空间较多</strong></p><p>使用 <strong>二级编码</strong>，实现 <strong>用集合类型保存单键值对</strong>，可以明显降低Redis实例的内存空间消耗</p><h3 id="String-类型的内存空间消耗在哪儿了"><a href="#String-类型的内存空间消耗在哪儿了" class="headerlink" title="String 类型的内存空间消耗在哪儿了?"></a>String 类型的内存空间消耗在哪儿了?</h3><p>除了记录实际数据，String 类型还需要额外的内存空间记录数据长度、空间使用等元数据信息</p><blockquote><p>String 类型具体是怎么保存数据的呢？</p><p>保存 64 位有符号整数时，String 类型会把它保存为一个 8 字节的 Long 类型整数，这种保存方式通常也叫作 int 编码方式。</p><p>保存的数据中包含字符时，String 类型就会用简单动态字符串（Simple Dynamic String，SDS）结构体来保存,在 <code>SDS</code> 中，<code>buf</code> 保存实际数据，而 <code>len</code> 和 <code>alloc</code> 本身其实是 <code>SDS</code> 结构体的额外开销。</p><ul><li><code>buf</code>：字节数组，保存实际数据。为了表示字节数组的结束，Redis 会自动在数组最后加一个“\0”，这就会额外占用 1 个字节的开销。</li><li><code>len</code>：占 4 个字节，表示 buf 的已用长度。</li><li><code>alloc</code>：也占个 4  字节，表示 buf 的实际分配长度，一般大于 len。</li></ul></blockquote><p>RedisObject </p><p>全局哈希表</p><p>jemalloc </p><h3 id="用什么数据结构可以节省内存"><a href="#用什么数据结构可以节省内存" class="headerlink" title="用什么数据结构可以节省内存?"></a>用什么数据结构可以节省内存?</h3><p><strong>压缩列表（ziplist）</strong>，这是一种非常节省内存的结构，压缩列表表头有三个字段 <code>zlbytes</code>、<code>zltail</code> 和 <code>zllen</code>，分别表示 <strong>列表长度</strong>、<strong>列表尾的偏移量</strong>，以及 <strong>列表中的 entry 个数</strong>。压缩列表尾还有一个 <code>zlend</code>，表示列表结束。</p><p>压缩列表之所以能节省内存，就在于它是用一系列 <strong>连续的 entry 保存数据</strong>。</p><p>每个 entry 的元数据包括下面几部分。</p><ul><li><code>prev_len</code>，表示前一个 entry  的长度。prev_len 有两种取值情况：1 字节或 5 字节。取值 1 字节时，表示上一个 entry 的长度小于 254 字节。虽然 1  字节的值能表示的数值范围是 0 到 255，但是压缩列表中 zlend 的取值默认是 255，因此，就默认用 255  表示整个压缩列表的结束，其他表示长度的地方就不能再用 255 这个值了。所以，当上一个 entry 长度小于 254 字节时，prev_len  取值为 1 字节，否则，就取值为 5 字节。</li><li><code>len</code>：表示自身长度，4 字节；</li><li><code>encoding</code>：表示编码方式，1  字节；</li><li><code>content</code>：保存实际数据。</li></ul><h3 id="如何用集合类型保存单值键值对"><a href="#如何用集合类型保存单值键值对" class="headerlink" title="如何用集合类型保存单值键值对?"></a>如何用集合类型保存单值键值对?</h3><p>采用基于 Hash 类型的二级编码方法。就是把一个单值的数据拆分成两部分，前一部分作为 Hash 集合的 key，后一部分作为 Hash 集合的 value，这样一来，我们就可以把单值数据保存到 Hash 集合中了。</p><p>以图片 ID 1101000060  和图片存储对象 ID 3302000080 为例，我们可以把图片 ID 的前 7 位（1101000）作为 <strong>Hash 类型的键</strong>，把图片 ID  的最后 3 位（060）和图片存储对象 ID 分别作为 <strong>Hash 类型值中的 key 和 value</strong>。按照这种设计方法，我在 Redis  中插入了一组图片 ID 及其存储对象 ID 的记录，并且用 info 命令查看了内存开销，我发现，增加一条记录后，内存占用只增加了 16  字节，如下所示：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">127.0.0.1:6379&gt; info memory</span><br><span class="line"><span class="comment"># Memory</span></span><br><span class="line">used_memory:1039120</span><br><span class="line">127.0.0.1:6379&gt; hset 1101000 060 3302000080</span><br><span class="line">(<span class="built_in">integer</span>) 1</span><br><span class="line">127.0.0.1:6379&gt; info memory</span><br><span class="line"><span class="comment"># Memory</span></span><br><span class="line">used_memory:1039136</span><br></pre></td></tr></table></figure><h3 id="Hash-类型底层结构什么时候使用压缩列表，什么时候使用哈希表呢？"><a href="#Hash-类型底层结构什么时候使用压缩列表，什么时候使用哈希表呢？" class="headerlink" title="Hash 类型底层结构什么时候使用压缩列表，什么时候使用哈希表呢？"></a>Hash 类型底层结构什么时候使用压缩列表，什么时候使用哈希表呢？</h3><p>Hash  类型设置了用压缩列表保存数据时的两个阈值，一旦超过了阈值，Hash  类型就会用哈希表来保存数据了。</p><p>这两个阈值分别对应以下两个配置项：</p><p><code>hash-max-ziplist-entries</code>：表示用压缩列表保存时哈希集合中的 <strong>最大元素个数</strong>。</p><p><code>hash-max-ziplist-value</code>：表示用压缩列表保存时哈希集合中 <strong>单个元素的最大长度</strong>。</p><p>如果我们往 Hash 集合中写入的元素个数超过了 <code>hash-max-ziplist-entries</code>，或者写入的单个元素大小超过了 <code>hash-max-ziplist-value</code>，Redis  就会自动把 Hash 类型的实现结构由 <strong>压缩列表转为哈希表</strong>。一旦从压缩列表转为了哈希表，Hash  类型就会一直用哈希表进行保存，而不会再转回压缩列表了。在节省内存空间方面，哈希表就没有压缩列表那么高效了。</p><p>为了能充分使用压缩列表的精简内存布局，我们一般要 <strong>控制保存在 Hash 集合中的元素个数</strong>。所以，在刚才的二级编码中，我们只用图片 ID 最后 3 位作为 Hash 集合的 key，也就保证了 Hash  集合的元素个数不超过 1000，同时，我们把 hash-max-ziplist-entries 设置为 1000，这样一来，Hash  集合就可以一直使用压缩列表来节省内存空间了。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;String 类型并不是适用于所有场合的，它有一个明显的短板，就是它 &lt;strong&gt;保存数据时所消耗的内存空间较多&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;使用 &lt;strong&gt;二级编码&lt;/strong&gt;，实现 &lt;strong&gt;用集合类型保存单键值对&lt;/strong&gt;，可以明显降</summary>
      
    
    
    
    <category term="极客时间Redis实战" scheme="http://universeinheart.github.io/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4Redis%E5%AE%9E%E6%88%98/"/>
    
    
    <category term="Redis" scheme="http://universeinheart.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>11、Redis String 为什么不好用了？</title>
    <link href="http://universeinheart.github.io/2021/04/16/Redis/11/"/>
    <id>http://universeinheart.github.io/2021/04/16/Redis/11/</id>
    <published>2021-04-16T14:00:00.000Z</published>
    <updated>2021-04-16T15:16:33.554Z</updated>
    
    <content type="html"><![CDATA[<p>String 类型并不是适用于所有场合的，它有一个明显的短板，就是它 <strong>保存数据时所消耗的内存空间较多</strong></p><p>使用 <strong>二级编码</strong>，实现 <strong>用集合类型保存单键值对</strong>，可以明显降低Redis实例的内存空间消耗</p><h3 id="String-类型的内存空间消耗在哪儿了"><a href="#String-类型的内存空间消耗在哪儿了" class="headerlink" title="String 类型的内存空间消耗在哪儿了?"></a>String 类型的内存空间消耗在哪儿了?</h3><p>除了记录实际数据，String 类型还需要额外的内存空间记录数据长度、空间使用等元数据信息</p><blockquote><p>String 类型具体是怎么保存数据的呢？</p><p>保存 64 位有符号整数时，String 类型会把它保存为一个 8 字节的 Long 类型整数，这种保存方式通常也叫作 int 编码方式。</p><p>保存的数据中包含字符时，String 类型就会用简单动态字符串（Simple Dynamic String，SDS）结构体来保存,在 <code>SDS</code> 中，<code>buf</code> 保存实际数据，而 <code>len</code> 和 <code>alloc</code> 本身其实是 <code>SDS</code> 结构体的额外开销。</p><ul><li><code>buf</code>：字节数组，保存实际数据。为了表示字节数组的结束，Redis 会自动在数组最后加一个“\0”，这就会额外占用 1 个字节的开销。</li><li><code>len</code>：占 4 个字节，表示 buf 的已用长度。</li><li><code>alloc</code>：也占个 4  字节，表示 buf 的实际分配长度，一般大于 len。</li></ul></blockquote><p>RedisObject </p><p>全局哈希表</p><p>jemalloc </p><h3 id="用什么数据结构可以节省内存"><a href="#用什么数据结构可以节省内存" class="headerlink" title="用什么数据结构可以节省内存?"></a>用什么数据结构可以节省内存?</h3><p><strong>压缩列表（ziplist）</strong>，这是一种非常节省内存的结构，压缩列表表头有三个字段 <code>zlbytes</code>、<code>zltail</code> 和 <code>zllen</code>，分别表示 <strong>列表长度</strong>、<strong>列表尾的偏移量</strong>，以及 <strong>列表中的 entry 个数</strong>。压缩列表尾还有一个 <code>zlend</code>，表示列表结束。</p><img src="/2021/04/16/Redis/11/image-20210119201052779.png" class="" title="image-20210119201052779"><p>压缩列表之所以能节省内存，就在于它是用一系列 <strong>连续的 entry 保存数据</strong>。</p><p>每个 entry 的元数据包括下面几部分。</p><ul><li><code>prev_len</code>，表示前一个 entry  的长度。prev_len 有两种取值情况：1 字节或 5 字节。取值 1 字节时，表示上一个 entry 的长度小于 254 字节。虽然 1  字节的值能表示的数值范围是 0 到 255，但是压缩列表中 zlend 的取值默认是 255，因此，就默认用 255  表示整个压缩列表的结束，其他表示长度的地方就不能再用 255 这个值了。所以，当上一个 entry 长度小于 254 字节时，prev_len  取值为 1 字节，否则，就取值为 5 字节。</li><li><code>len</code>：表示自身长度，4 字节；</li><li><code>encoding</code>：表示编码方式，1  字节；</li><li><code>content</code>：保存实际数据。</li></ul><h3 id="如何用集合类型保存单值键值对"><a href="#如何用集合类型保存单值键值对" class="headerlink" title="如何用集合类型保存单值键值对?"></a>如何用集合类型保存单值键值对?</h3><p>采用基于 Hash 类型的二级编码方法。就是把一个单值的数据拆分成两部分，前一部分作为 Hash 集合的 key，后一部分作为 Hash 集合的 value，这样一来，我们就可以把单值数据保存到 Hash 集合中了。</p><p>以图片 ID 1101000060  和图片存储对象 ID 3302000080 为例，我们可以把图片 ID 的前 7 位（1101000）作为 <strong>Hash 类型的键</strong>，把图片 ID  的最后 3 位（060）和图片存储对象 ID 分别作为 <strong>Hash 类型值中的 key 和 value</strong>。按照这种设计方法，我在 Redis  中插入了一组图片 ID 及其存储对象 ID 的记录，并且用 info 命令查看了内存开销，我发现，增加一条记录后，内存占用只增加了 16  字节，如下所示：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">127.0.0.1:6379&gt; info memory</span><br><span class="line"><span class="comment"># Memory</span></span><br><span class="line">used_memory:1039120</span><br><span class="line">127.0.0.1:6379&gt; hset 1101000 060 3302000080</span><br><span class="line">(<span class="built_in">integer</span>) 1</span><br><span class="line">127.0.0.1:6379&gt; info memory</span><br><span class="line"><span class="comment"># Memory</span></span><br><span class="line">used_memory:1039136</span><br></pre></td></tr></table></figure><h3 id="Hash-类型底层结构什么时候使用压缩列表，什么时候使用哈希表呢？"><a href="#Hash-类型底层结构什么时候使用压缩列表，什么时候使用哈希表呢？" class="headerlink" title="Hash 类型底层结构什么时候使用压缩列表，什么时候使用哈希表呢？"></a>Hash 类型底层结构什么时候使用压缩列表，什么时候使用哈希表呢？</h3><p>Hash  类型设置了用压缩列表保存数据时的两个阈值，一旦超过了阈值，Hash  类型就会用哈希表来保存数据了。</p><p>这两个阈值分别对应以下两个配置项：</p><p><code>hash-max-ziplist-entries</code>：表示用压缩列表保存时哈希集合中的 <strong>最大元素个数</strong>。</p><p><code>hash-max-ziplist-value</code>：表示用压缩列表保存时哈希集合中 <strong>单个元素的最大长度</strong>。</p><p>如果我们往 Hash 集合中写入的元素个数超过了 <code>hash-max-ziplist-entries</code>，或者写入的单个元素大小超过了 <code>hash-max-ziplist-value</code>，Redis  就会自动把 Hash 类型的实现结构由 <strong>压缩列表转为哈希表</strong>。一旦从压缩列表转为了哈希表，Hash  类型就会一直用哈希表进行保存，而不会再转回压缩列表了。在节省内存空间方面，哈希表就没有压缩列表那么高效了。</p><p>为了能充分使用压缩列表的精简内存布局，我们一般要 <strong>控制保存在 Hash 集合中的元素个数</strong>。所以，在刚才的二级编码中，我们只用图片 ID 最后 3 位作为 Hash 集合的 key，也就保证了 Hash  集合的元素个数不超过 1000，同时，我们把 hash-max-ziplist-entries 设置为 1000，这样一来，Hash  集合就可以一直使用压缩列表来节省内存空间了。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;String 类型并不是适用于所有场合的，它有一个明显的短板，就是它 &lt;strong&gt;保存数据时所消耗的内存空间较多&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;使用 &lt;strong&gt;二级编码&lt;/strong&gt;，实现 &lt;strong&gt;用集合类型保存单键值对&lt;/strong&gt;，可以明显降</summary>
      
    
    
    
    <category term="极客时间Redis实战" scheme="http://universeinheart.github.io/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4Redis%E5%AE%9E%E6%88%98/"/>
    
    
    <category term="Redis" scheme="http://universeinheart.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>08、Redis 哨兵集群</title>
    <link href="http://universeinheart.github.io/2021/04/15/Redis/08/"/>
    <id>http://universeinheart.github.io/2021/04/15/Redis/08/</id>
    <published>2021-04-15T00:00:00.000Z</published>
    <updated>2021-04-16T15:17:21.400Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基于-pub-sub-机制的哨兵集群组成"><a href="#基于-pub-sub-机制的哨兵集群组成" class="headerlink" title="基于 pub/sub 机制的哨兵集群组成"></a>基于 pub/sub 机制的哨兵集群组成</h2><p>哨兵实例之间可以相互发现，要归功于 <strong>Redis 提供的 pub/sub 机制</strong>，也就是 <strong>发布 / 订阅机制</strong></p><p>哨兵只要和主库建立起了连接，就可以在主库上发布消息了，比如说发布它自己的<strong>连接信息</strong>（IP 和端口）。同时，它也可以从主库上订阅消息，获得<strong>其他哨兵发布的连接信息</strong>。当多个哨兵实例都在主库上做了发布和订阅操作后，它们之间就能知道彼此的 IP 地址和端口。</p><p>为了区分不同应用的消息，Redis 会以<strong>频道</strong>的形式，对这些消息进行分门别类的管理。只有订阅了同一个频道的应用，才能通过发布的消息进行信息交换。</p><blockquote><p>在主从集群中，主库上有一个名为**_ _ sentinel _ _:hello**的频道，不同哨兵就是通过它来相互发现，实现互相通信的。</p></blockquote><img src="/2021/04/15/Redis/08/image-20210116154316161.png" class="" title="image-20210116154316161"><h2 id="基于-pub-sub-机制的客户端事件通知"><a href="#基于-pub-sub-机制的客户端事件通知" class="headerlink" title="基于 pub/sub 机制的客户端事件通知"></a>基于 pub/sub 机制的客户端事件通知</h2><p>客户端可以从哨兵订阅消息。哨兵提供的消息订阅频道有很多，不同频道包含了主从库切换过程中的不同关键事件。</p><img src="/2021/04/15/Redis/08/image-20210116154651991.png" class="" title="image-20210116154651991"><p>客户端读取哨兵的配置文件后，可以获得哨兵的地址和端口，和哨兵建立网络连接。然后，我们可以在客户端执行 <strong>订阅命令</strong>，来获取不同的事件消息。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;订阅“所有实例进入客观下线状态的事件”</span><br><span class="line">SUBSCRIBE +odown</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;订阅所有的事件</span><br><span class="line">PSUBSCRIBE  *</span><br></pre></td></tr></table></figure><p>当哨兵把新主库选择出来后，客户端就会看到下面的 <code>switch-master</code> 事件。这个事件表示主库已经切换了，新主库的 IP 地址和端口信息已经有了。这个时候，客户端就可以用这里面的新主库地址和端口进行通信了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">switch-master &lt;master name&gt; &lt;oldip&gt; &lt;oldport&gt; &lt;newip&gt; &lt;newport&gt;</span><br></pre></td></tr></table></figure><p>有了这些事件通知，客户端不仅可以在主从切换后得到新主库的连接信息，还可以监控到主从库切换过程中发生的各个重要事件。这样，客户端就可以知道主从切换进行到哪一步了，有助于了解切换进度。</p><h2 id="由哪个哨兵执行主从切换？"><a href="#由哪个哨兵执行主从切换？" class="headerlink" title="由哪个哨兵执行主从切换？"></a>由哪个哨兵执行主从切换？</h2><h3 id="投票下线"><a href="#投票下线" class="headerlink" title="投票下线"></a>投票下线</h3><p>任何一个实例只要自身判断主库“主观下线”后，就会给其他实例发送 <code>is-master-down-by-addr</code> 命令。接着，其他实例会根据自己和主库的连接情况，做出 Y 或 N 的响应，Y 相当于赞成票，N 相当于反对票。</p><img src="/2021/04/15/Redis/08/image-20210116155725926.png" class="" title="image-20210116155725926"><p>一个哨兵获得了仲裁所需的赞成票数后，就可以标记主库为“客观下线”。这个所需的赞成票数是通过哨兵配置文件中的 <code>quorum</code> 配置项设定的。例如，现在有 5 个哨兵，<code>quorum</code> 配置的是 3，那么，一个哨兵需要 3  张赞成票，就可以标记主库为“客观下线”了。这 3 张赞成票包括哨兵自己的一张赞成票和另外两个哨兵的赞成票。</p><h3 id="投票确认Leader"><a href="#投票确认Leader" class="headerlink" title="投票确认Leader"></a>投票确认Leader</h3><p>这个哨兵就可以再给其他哨兵发送命令，表明希望由自己来执行主从切换，并让所有其他哨兵进行投票。这个投票过程称为“<strong>Leader 选举</strong>”。因为最终执行主从切换的哨兵称为 Leader，投票过程就是确定 Leader。</p><p>任何一个想成为 Leader  的哨兵，要满足两个条件：第一，拿到半数以上的赞成票；第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。以 3  个哨兵为例，假设此时的 quorum 设置为 2，那么，任何一个想成为 Leader 的哨兵只要拿到 2 张赞成票，就可以了。</p><img src="/2021/04/15/Redis/08/image-20210116160103639.png" class="" title="image-20210116160103639"><p>如果 S3 没有拿到 2 票  Y，那么这轮投票就不会产生 Leader。哨兵集群会等待一段时间（也就是哨兵故障转移超时时间的 2  倍），再重新选举。这是因为，哨兵集群能够进行成功投票，很大程度上依赖于选举命令的正常<strong>网络传播</strong>。如果网络压力较大或有短时堵塞，就可能导致没有一个哨兵能拿到半数以上的赞成票。所以，等到网络拥塞好转之后，再进行投票选举，成功的概率就会增加。</p><p>需要注意的是，如果哨兵集群只有 2 个实例，此时，一个哨兵要想成为 Leader，必须获得 2 票，而不是 1  票。所以，如果有个哨兵挂掉了，那么，此时的集群是无法进行主从库切换的。因此，通常我们<strong>至少会配置 3  个哨兵实例</strong>。这一点很重要，你在实际应用时可不能忽略了。</p>]]></content>
    
    
    <summary type="html">哨兵挂了，主从库还能切换么？</summary>
    
    
    
    <category term="极客时间Redis实战" scheme="http://universeinheart.github.io/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4Redis%E5%AE%9E%E6%88%98/"/>
    
    
    <category term="Redis" scheme="http://universeinheart.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>07、Redis 哨兵机制</title>
    <link href="http://universeinheart.github.io/2021/04/14/Redis/07/"/>
    <id>http://universeinheart.github.io/2021/04/14/Redis/07/</id>
    <published>2021-04-14T00:00:00.000Z</published>
    <updated>2021-04-14T00:30:25.354Z</updated>
    
    <content type="html"><![CDATA[<h2 id="哨兵机制的基本流程"><a href="#哨兵机制的基本流程" class="headerlink" title="哨兵机制的基本流程"></a>哨兵机制的基本流程</h2><p>哨兵其实就是一个运行在特殊模式下的 Redis 进程，主从库实例运行的同时，它也在运行。</p><p>哨兵主要负责的就是三个任务：<strong>监控</strong>、<strong>选主</strong> 和<strong>通知</strong>。</p><h3 id="监控"><a href="#监控" class="headerlink" title="监控"></a>监控</h3><p>监控是指哨兵进程在运行时，周期性地给所有的主从库发送 <code>PING</code> 命令，检测它们是否仍然在线运行。</p><p>如果<strong>从库</strong>没有在规定时间内响应哨兵的 <code>PING</code>  命令，哨兵就会把它标记为“下线状态”；</p><p>如果<strong>主库</strong>也没有在规定时间内响应哨兵的 <code>PING</code>  命令，哨兵就会判定主库下线，然后开始自动切换主库的流程。</p><blockquote><p><strong>哨兵如何判断主库是否处于下线状态?</strong></p><p>哨兵进程会使用 PING 命令检测它自己和主、从库的网络连接情况，用来判断实例的状态。如果哨兵发现主库或从库对 PING 命令的响应超时了，那么，哨兵就会先把它标记为“<strong>主观下线</strong>”。</p><p>如果检测的是从库，那么，哨兵简单地把它标记为“主观下线”就行了，因为从库的下线影响一般不太大，集群的对外服务不会间断。但是，如果检测的是主库，那么，哨兵还不能简单地把它标记为“主观下线”，开启主从切换。</p><p>因为很有可能存在这么一个情况：那就是哨兵误判了，其实主库并没有故障。要特别注意误判的情况，因为，一旦启动了主从切换，后续的选主和通知操作都会带来额外的计算和通信开销。</p><p>误判一般会发生在集群网络压力较大、网络拥塞，或者是主库本身压力较大的情况下。</p><p>哨兵机制也是类似的，它通常会采用 <strong>多实例组成的集群模式</strong> 进行部署，这也被称为哨兵集群。引入多个哨兵实例一起来判断，就可以避免单个哨兵因为自身网络状况不好，而误判主库下线的情况。同时，多个哨兵的网络同时不稳定的概率较小，由它们一起做决策，误判率也能降低。</p></blockquote><img src="/2021/04/14/Redis/07/image-20210115234805846.png" class="" title="image-20210115234805846"><p>当有 N 个哨兵实例时，最好要有 <strong>N/2 + 1</strong> 个实例判断主库为“<strong>主观下线</strong>”，才能最终判定主库为“<strong>客观下线</strong>”</p><h3 id="选主"><a href="#选主" class="headerlink" title="选主"></a>选主</h3><p>主库挂了以后，哨兵就需要从很多个从库里，按照一定的规则选择一个从库实例，把它作为新的主库。这一步完成后，现在的集群里就有了新主库。</p><blockquote><p><strong>哨兵如何决定选择哪个从库实例作为主库？</strong></p><p>多个从库中，先按照一定的筛选条件，把不符合条件的从库去掉。然后，我们再按照一定的规则，给剩下的从库逐个打分，将得分最高的从库选为新主库</p><img src="/2021/04/14/Redis/07/image-20210115235007844.png" class="" title="image-20210115235007844"><p>第一轮：优先级最高的从库得分高(<code>slave-priority</code> 配置项)</p><p>第二轮：和旧主库同步程度最接近的从库得分高。( <code>slave_repl_offset</code> 最接近 <code>master_repl_offset</code>)</p><p>第三轮：ID 号小的从库得分高。</p></blockquote><h3 id="通知"><a href="#通知" class="headerlink" title="通知"></a>通知</h3><p>在执行通知任务时，哨兵会把新主库的连接信息发给其他从库，让它们执行 <code>replicaof</code> 命令，和新主库建立连接，并进行数据复制。同时，哨兵会把新主库的连接信息通知给客户端，让它们把请求操作发到新主库上。</p><img src="/2021/04/14/Redis/07/image-20210115233901510.png" class="" title="image-20210115233901510">]]></content>
    
    
    <summary type="html">主库挂了，如何不间断服务？</summary>
    
    
    
    <category term="极客时间Redis实战" scheme="http://universeinheart.github.io/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4Redis%E5%AE%9E%E6%88%98/"/>
    
    
    <category term="Redis" scheme="http://universeinheart.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>06、Redis 数据同步</title>
    <link href="http://universeinheart.github.io/2021/04/14/Redis/06/"/>
    <id>http://universeinheart.github.io/2021/04/14/Redis/06/</id>
    <published>2021-04-13T16:08:15.000Z</published>
    <updated>2021-04-14T00:03:58.323Z</updated>
    
    <content type="html"><![CDATA[<p>Redis 提供了主从库模式，以保证数据副本的一致，主从库之间采用的是读写分离的方式。</p><ul><li>读操作：主库、从库都可以接收；</li><li>写操作：首先到主库执行，然后，主库将写操作同步给从库。</li></ul><img src="/2021/04/14/Redis/06/image-20210114224608756.png" class="" title="image-20210114224608756"><h3 id="主从库间如何进行第一次同步？"><a href="#主从库间如何进行第一次同步？" class="headerlink" title="主从库间如何进行第一次同步？"></a>主从库间如何进行第一次同步？</h3><p>通过 <code>replicaof</code>（Redis 5.0 之前使用 <code>slaveof</code>）命令形成主库和从库的关系</p><img src="/2021/04/14/Redis/06/image-20210114224736883.png" class="" title="image-20210114224736883"><p><strong>第一阶段：建立连接，协商同步</strong></p><p>从库给主库发送 <code>psync</code> 命令，表示要进行数据同步，主库根据这个命令的参数来启动复制。</p><p><code>psync</code> 命令包含了 <strong>主库的 <code>runID</code></strong> 和 <strong>复制进度 <code>offset</code></strong> 两个参数。</p><ul><li><code>runID</code>，是每个 Redis 实例启动时都会自动生成的一个随机 ID，用来唯一标记这个实例。当从库和主库第一次复制时，因为不知道主库的 runID，所以将 runID 设为“？”</li><li><code>offset</code>，此时设为 -1，表示第一次复制。</li></ul><p>主库收到 <code>psync</code> 命令后，会用 <code>FULLRESYNC</code> 响应命令带上两个参数：<strong>主库 runID</strong> 和 <strong>主库目前的复制进度 offset</strong>，返回给从库。从库收到响应后，会记录下这两个参数。这里有个地方需要注意，**<code>FULLRESYNC</code> 响应表示第一次复制采用的全量复制，也就是说，主库会把当前所有的数据都复制给从库**</p><p><strong>第二阶段，主库将所有数据同步给从库。从库收到数据后，在本地完成数据加载。</strong></p><p>具体来说，主库执行 <code>bgsave</code> 命令，生成 RDB 文件，接着将文件发给从库。从库接收到 RDB 文件后，会先 <strong>清空当前数据库</strong>，然后加载 RDB 文件。这是因为从库在通过 replicaof 命令开始和主库同步前，可能保存了其他数据。为了避免之前数据的影响，从库需要先把当前数据库清空。</p><p>在主库将数据同步给从库的过程中，主库不会被阻塞，但是，这些请求中的写操作并没有记录到刚刚生成的 RDB 文件中。为了保证主从库的数据一致性，主库会在内存中用专门的 <code>replication buffer</code>，<strong>记录 RDB 文件生成后收到的所有写操作</strong>。</p><p><strong>第三个阶段，主库会把第二阶段执行过程中新收到的写命令，再发送给从库。</strong></p><p>具体的操作是，当主库完成 RDB 文件发送后，就会把此时 <code>replication buffer</code> 中的修改操作发给从库，从库再重新执行这些操作。这样一来，主从库就实现同步了。</p><h3 id="主从级联模式分担全量复制时的主库压力"><a href="#主从级联模式分担全量复制时的主库压力" class="headerlink" title="主从级联模式分担全量复制时的主库压力"></a>主从级联模式分担全量复制时的主库压力</h3><p>通过“主 - 从 - 从”模式将主库生成 RDB 和传输 RDB 的压力，以级联的方式分散到从库上。</p><img src="/2021/04/14/Redis/06/image-20210114225744977.png" class="" title="image-20210114225744977"><p>一旦主从库完成了全量复制，它们之间就会一直维护一个网络连接，主库会通过这个连接将后续陆续收到的命令操作再同步给从库，这个过程也称为<strong>基于长连接的命令传播</strong>，可以避免频繁建立连接的开销。</p><h3 id="主从库间网络断了怎么办？"><a href="#主从库间网络断了怎么办？" class="headerlink" title="主从库间网络断了怎么办？"></a>主从库间网络断了怎么办？</h3><p>在 Redis 2.8 之前，如果主从库在命令传播时出现了网络闪断，那么，从库就会和主库重新进行一次全量复制，开销非常大。</p><p>从 Redis 2.8 开始，网络断了之后，主从库会采用 <strong>增量复制</strong> 的方式继续同步。全量复制是同步所有数据，而增量复制只会把主从库网络断连期间主库收到的命令，同步给从库。</p><blockquote><p> 增量复制时，主从库之间具体是怎么保持同步的呢？</p><p> <strong>repl_backlog_buffer 缓冲区</strong></p><p> 当主从库断连后，主库会把断连期间收到的写操作命令，写入 <code>replication buffer</code>，同时也会把这些操作命令也写入 <code>repl_backlog_buffer</code>  这个缓冲区。</p><p> <code>repl_backlog_buffer</code> 是一个环形缓冲区，主库会记录自己写到的位置，从库则会记录自己已经读到的位置。</p><p> 刚开始的时候，主库和从库的写读位置在一起，这算是它们的起始位置。随着主库不断接收新的写操作，它在缓冲区中的写位置会逐步偏离起始位置，我们通常用偏移量来衡量这个偏移距离的大小，对主库来说，对应的偏移量就是  <code>master_repl_offset</code>。主库接收的新写操作越多，这个值就会越大。同样，从库在复制完写操作命令后，它在缓冲区中的读位置也开始逐步偏移刚才的起始位置，此时，从库已复制的偏移量 slave_repl_offset 也在不断增加。正常情况下，这两个偏移量基本相等。</p></blockquote><img src="/2021/04/14/Redis/06/image-20210115232735345.png" class="" title="image-20210115232735345"><blockquote><p>主从库的连接恢复之后，从库首先会给主库发送  <code>psync</code> 命令，并把自己当前的 <code>slave_repl_offset</code> 发给主库，主库会判断自己的 <code>master_repl_offset</code> 和  <code>slave_repl_offset</code>  之间的差距。</p><p>在网络断连阶段，主库可能会收到新的写操作命令，所以，一般来说，<code>master_repl_offset</code> 会大于  <code>slave_repl_offset</code>。此时，主库只用把 <code>master_repl_offset</code> 和 <code>slave_repl_offset</code>  之间的命令操作同步给从库就行。就像刚刚示意图的中间部分，主库和从库之间相差了 put d e 和 put d f  两个操作，在增量复制时，主库只需要把它们同步给从库，就行了。</p></blockquote><img src="/2021/04/14/Redis/06/image-20210115232858938.png" class="" title="image-20210115232858938"><p>因为 <code>repl_backlog_buffer</code> 是一个 <strong>环形缓冲区</strong>，所以在缓冲区写满后，主库会继续写入，此时，就会覆盖掉之前写入的操作。<strong>如果从库的读取速度比较慢，就有可能导致从库还未读取的操作被主库新写的操作覆盖了，这会导致主从库间的数据不一致</strong>。可以调整 <code>repl_backlog_size</code>  这个参数。这个参数和所需的缓冲空间大小有关。</p><p>缓冲空间的计算公式是：缓冲空间大小 = 主库写入命令速度 * 操作大小 - 主从库间网络传输命令速度 * 操作大小。</p><p>在实际应用中，考虑到可能存在一些突发的请求压力，我们通常需要把这个缓冲空间扩大一到两倍</p>]]></content>
    
    
    <summary type="html">主从库如何实现数据一致</summary>
    
    
    
    <category term="极客时间Redis实战" scheme="http://universeinheart.github.io/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4Redis%E5%AE%9E%E6%88%98/"/>
    
    
    <category term="Redis" scheme="http://universeinheart.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>12、Redis 统计集合</title>
    <link href="http://universeinheart.github.io/2021/04/14/Redis/12/"/>
    <id>http://universeinheart.github.io/2021/04/14/Redis/12/</id>
    <published>2021-04-13T16:00:00.000Z</published>
    <updated>2021-04-16T15:15:53.667Z</updated>
    
    <content type="html"><![CDATA[<h2 id="聚合统计"><a href="#聚合统计" class="headerlink" title="聚合统计"></a>聚合统计</h2><p>所谓的聚合统计，就是指 <strong>统计多个集合元素的聚合结果</strong>，包括：<strong>交集统计</strong>，<strong>差集统计</strong>，<strong>并集统计</strong></p><blockquote><p>统计手机 App 每天的<strong>新增用户数</strong>和第二天的<strong>留存用户数</strong>，正好对应了聚合统计。</p><p>用一个集合记录所有登录过 App 的用户 ID，直接使用 <strong>Set 类型</strong>，把 key 设置为 <code>user:id</code>，<strong>表示记录的是用户 ID</strong>，value 就是一个 <strong>Set 集合</strong>，里面是所有登录过 App 的用户 ID，我们可以把这个 Set 叫作<strong>累计用户 Set</strong></p><p>用另一个集合记录每一天登录过 App 的用户 ID，key 是 user:id 以及当天日期，例如 user：id:20200803，叫做<strong>每日用户 Set</strong></p><p><strong>在统计每天的新增用户时，我们只用计算每日用户 Set 和累计用户 Set 的差集就行。</strong></p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 并集，将每日用户合并到累计用户Set</span></span><br><span class="line">SUNIONSTORE  user:id  user:id  user:id:<span class="number">20200803</span> </span><br><span class="line"></span><br><span class="line"><span class="comment">// 差集，0804新增用户</span></span><br><span class="line">SDIFFSTORE  user:<span class="keyword">new</span>  user:id:<span class="number">20200804</span> user:id  </span><br><span class="line"></span><br><span class="line"><span class="comment">// 交集，0804留存用户</span></span><br><span class="line">SINTERSTORE user:id:rem user:id:<span class="number">20200803</span> user:id:<span class="number">20200804</span></span><br></pre></td></tr></table></figure><p>Set  的差集、并集和交集的计算复杂度较高，在数据量较大的情况下，如果直接执行这些计算，会导致 Redis  实例阻塞。所以，我给你分享一个小建议：<strong>你可以从主从集群中选择一个从库，让它专门负责聚合计算，或者是把数据读取到客户端，在客户端来完成聚合统计</strong>，这样就可以规避阻塞主库实例和其他从库实例的风险了。</p><h2 id="排序统计"><a href="#排序统计" class="headerlink" title="排序统计"></a>排序统计</h2><p><code>Sorted Set</code>  根据元素的实际权重来排序和获取数据的。</p><p><code>Sorted Set</code> 的 <code>ZRANGEBYSCORE</code>  命令就可以按权重排序后返回元素。即使集合中的元素频繁更新，<code>Sorted Set</code> 也能通过 <code>ZRANGEBYSCORE</code>  命令准确地获取到按序排列的数据</p><p>假设越新的评论权重越大，目前最新评论的权重是 N，我们执行下面的命令时，就可以获得最新的 10 条评论：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RANGEBYSCORE comments N-9 N</span><br></pre></td></tr></table></figure><p>所以，在面对需要展示最新列表、排行榜等场景时，如果<strong>数据更新频繁</strong>或者<strong>需要分页显示</strong>，建议你<strong>优先考虑使用 Sorted Set</strong></p><h2 id="二值状态统计"><a href="#二值状态统计" class="headerlink" title="二值状态统计"></a>二值状态统计</h2><p>二值状态就是指集合元素的取值就 <strong>只有 0 和 1 两种</strong>。在签到打卡的场景中，我们只用记录签到（1）或未签到（0），所以它就是非常典型的二值状态</p><p><code>Bitmap</code> 是用 String 类型作为底层数据结构实现的一种统计二值状态的数据类型。String 类型是会保存为二进制的字节数组，所以，Redis 就把字节数组的每个 bit 位利用起来，用来表示一个元素的二值状态。<strong>可以把 <code>Bitmap</code> 看作是一个 bit 数组</strong></p><p><code>Bitmap</code> 提供了 <code>GETBIT/SETBIT</code> 操作，使用一个偏移值 <code>offset</code> 对 bit 数组的某一个 bit 位进行读和写。不过，需要注意的是，Bitmap 的偏移量是从 0  开始算的，也就是说 offset 的最小值是 0。当使用 <code>SETBIT</code> 对一个 bit 位进行写操作时，这个 bit 位会被设置为  1。Bitmap 还提供了 <code>BITCOUNT</code> 操作，用来统计这个 bit 数组中所有“1”的个数。</p><blockquote><p><strong>怎么用 <code>Bitmap</code> 进行签到统计呢？</strong></p><p>假设我们要统计 ID 3000 的用户在 2020 年 8 月份的签到情况，就可以按照下面的步骤进行操作。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//第一步，执行下面的命令，记录该用户 8 月 3 号已签到。</span></span><br><span class="line">SETBIT uid:sign:<span class="number">3000</span>:<span class="number">202008</span> <span class="number">2</span> <span class="number">1</span> </span><br><span class="line"></span><br><span class="line"><span class="comment">//第二步，检查该用户 8 月 3 日是否签到</span></span><br><span class="line">GETBIT uid:sign:<span class="number">3000</span>:<span class="number">202008</span> <span class="number">2</span> </span><br><span class="line"></span><br><span class="line"><span class="comment">//第三步，统计该用户在 8 月份的签到次数。</span></span><br><span class="line">BITCOUNT uid:sign:<span class="number">3000</span>:<span class="number">202008</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></blockquote><blockquote><p><strong>如果记录了 1 亿个用户 10 天的签到情况，你有办法统计出这 10 天连续签到的用户总数吗？</strong></p><p><code>Bitmap</code> 支持用 <code>BITOP</code> 命令对多个 <code>Bitmap</code> 按位做“与”“或”“异或”的操作，操作的结果会保存到一个新的 <code>Bitmap</code> 中。</p><p>在统计 1 亿个用户连续 10  天的签到情况时，可以把每天的日期作为 key，每个 key 对应一个 1 亿位的 Bitmap，每一个 bit  对应一个用户当天的签到情况。</p><p>接下来，我们对 10 个 Bitmap 做“与”操作，得到的结果也是一个 Bitmap。在这个 Bitmap  中，只有 10 天都签到的用户对应的 bit 位上的值才会是 1。</p><p>最后，我们可以用 BITCOUNT 统计下 Bitmap 中的 1  的个数，这就是连续签到 10 天的用户总数了。</p><p>现在，我们可以计算一下记录了 10 天签到情况后的内存开销。每天使用 1 个 1 亿位的  Bitmap，大约占 12MB 的内存（10^8/8/1024/1024），10 天的 Bitmap 的内存开销约为  120MB，内存压力不算太大。不过，在实际应用时，最好对 Bitmap 设置过期时间，让 Redis  自动删除不再需要的签到记录，以节省内存开销。</p></blockquote><h2 id="基数统计"><a href="#基数统计" class="headerlink" title="基数统计"></a>基数统计</h2><p>基数统计就是指 统计一个集合中<strong>不重复的元素个数</strong>。</p><p>网页 UV 的统计有个独特的地方，就是需要<strong>去重</strong>，一个用户一天内的多次访问只能算作一次。在 Redis 的集合类型中，<strong>Set 类型</strong>默认支持去重，所以看到有去重需求时，我们可能第一时间就会想到用 Set 类型。如果 page 非常火爆，UV 达到了千万，这个时候，一个 Set 就要记录千万个用户 ID。对于一个搞大促的电商网站而言，这样的页面可能有成千上万个，如果每个页面都用这样的一个 Set，就会消耗很大的内存空间。</p><p><code>HyperLogLog</code> 是一种用于统计基数的数据集合类型，它的最大优势就在于，<strong>当集合元素数量非常多时，它计算基数所需的空间总是固定的，而且还很小</strong></p><p>在 Redis 中，每个 <code>HyperLogLog</code> 只需要花费 12 KB 内存，就可以计算接近 2^64 个元素的基数。和元素越多就越耗费内存的 Set 和 Hash 类型相比，<code>HyperLogLog</code> 就非常节省空间。</p><p><code>HyperLogLog</code>  的统计规则是基于概率完成的，所以它给出的统计结果是有一定误差的，标准误算率是 0.81%。这也就意味着，你使用 HyperLogLog 统计的  UV 是 100 万，但实际的 UV 可能是 101 万。虽然误差率不算大，但是，如果你需要精确统计结果的话，最好还是继续用 Set 或  Hash 类型。</p><img src="/2021/04/14/Redis/12/image-20210121212414231.png" class="" title="image-20210121212414231">]]></content>
    
    
    <summary type="html">有一亿个keys要统计，应该用哪种集合？</summary>
    
    
    
    <category term="极客时间Redis实战" scheme="http://universeinheart.github.io/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4Redis%E5%AE%9E%E6%88%98/"/>
    
    
    <category term="Redis" scheme="http://universeinheart.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>06、Redis</title>
    <link href="http://universeinheart.github.io/2021/04/14/Redis/13/"/>
    <id>http://universeinheart.github.io/2021/04/14/Redis/13/</id>
    <published>2021-04-13T16:00:00.000Z</published>
    <updated>2021-04-16T15:17:00.102Z</updated>
    
    
    
    
    <category term="极客时间Redis实战" scheme="http://universeinheart.github.io/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4Redis%E5%AE%9E%E6%88%98/"/>
    
    
    <category term="Redis" scheme="http://universeinheart.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>名句</title>
    <link href="http://universeinheart.github.io/2021/04/13/%E5%B0%8F%E5%86%8C%E5%AD%90/%E5%90%8D%E5%8F%A5/"/>
    <id>http://universeinheart.github.io/2021/04/13/%E5%B0%8F%E5%86%8C%E5%AD%90/%E5%90%8D%E5%8F%A5/</id>
    <published>2021-04-13T15:26:37.000Z</published>
    <updated>2021-04-13T15:40:07.184Z</updated>
    
    <content type="html"><![CDATA[<h3 id="爱比克泰德：古罗马哲学家"><a href="#爱比克泰德：古罗马哲学家" class="headerlink" title="爱比克泰德：古罗马哲学家"></a>爱比克泰德：古罗马哲学家</h3><ol><li>只有受过教育的人才是自由的。</li><li>我们登上并非我们所选择的舞台,演绎并非我们所选择的剧本。</li><li>连自己的命运都不能主宰的人是没有自由可以享受的</li></ol><h3 id="艾森豪威尔的母亲"><a href="#艾森豪威尔的母亲" class="headerlink" title="艾森豪威尔的母亲"></a>艾森豪威尔的母亲</h3><ol><li>人生犹如打牌，牌是上帝发的，不管是好是坏，你都别无选择，唯一可以选择做的，就是调整好自己的心态，让浮躁的心平静下来，认真对待每一张牌，力争最好效果。只有这样的人生高度才是有意义的</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;爱比克泰德：古罗马哲学家&quot;&gt;&lt;a href=&quot;#爱比克泰德：古罗马哲学家&quot; class=&quot;headerlink&quot; title=&quot;爱比克泰德：古罗马哲学家&quot;&gt;&lt;/a&gt;爱比克泰德：古罗马哲学家&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;只有受过教育的人才是自由的。&lt;/li&gt;
&lt;li&gt;</summary>
      
    
    
    
    <category term="杂记" scheme="http://universeinheart.github.io/categories/%E6%9D%82%E8%AE%B0/"/>
    
    
    <category term="杂记" scheme="http://universeinheart.github.io/tags/%E6%9D%82%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>复利</title>
    <link href="http://universeinheart.github.io/2021/04/13/%E5%B0%8F%E5%86%8C%E5%AD%90/%E5%A4%8D%E5%88%A9/"/>
    <id>http://universeinheart.github.io/2021/04/13/%E5%B0%8F%E5%86%8C%E5%AD%90/%E5%A4%8D%E5%88%A9/</id>
    <published>2021-04-13T15:26:37.000Z</published>
    <updated>2021-04-13T15:41:40.789Z</updated>
    
    <content type="html"><![CDATA[<p>自然对数的底 e=2.718281828459045</p><p>复利： F = P(1+i)^n</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;自然对数的底 e=2.718281828459045&lt;/p&gt;
&lt;p&gt;复利： F = P(1+i)^n&lt;/p&gt;
</summary>
      
    
    
    
    <category term="杂记" scheme="http://universeinheart.github.io/categories/%E6%9D%82%E8%AE%B0/"/>
    
    
    <category term="杂记" scheme="http://universeinheart.github.io/tags/%E6%9D%82%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>历史上的经济泡沫</title>
    <link href="http://universeinheart.github.io/2021/04/13/%E5%B0%8F%E5%86%8C%E5%AD%90/%E7%BB%8F%E6%B5%8E%E6%B3%A1%E6%B2%AB/"/>
    <id>http://universeinheart.github.io/2021/04/13/%E5%B0%8F%E5%86%8C%E5%AD%90/%E7%BB%8F%E6%B5%8E%E6%B3%A1%E6%B2%AB/</id>
    <published>2021-04-13T15:26:37.000Z</published>
    <updated>2021-04-13T15:40:02.186Z</updated>
    
    <content type="html"><![CDATA[<h2 id="郁金香狂热"><a href="#郁金香狂热" class="headerlink" title="郁金香狂热"></a>郁金香狂热</h2><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>荷-西战争:政治独立</p><p>东印度公司：经济独立</p><p>中亚—-&gt; 西欧</p><h3 id="发生"><a href="#发生" class="headerlink" title="发生"></a>发生</h3><p>自然生成5-7年，球茎1年</p><p>炒作 1634年</p><p>1634年12月  —&gt;  1637年4月  (期货)</p><p> 奥古斯都 6290荷兰盾 </p><p>长春君子兰</p><p>击鼓传花</p><h2 id="史上最有钱的公司"><a href="#史上最有钱的公司" class="headerlink" title="史上最有钱的公司"></a>史上最有钱的公司</h2><h4 id="荷兰东印度公司-成熟的经济模式"><a href="#荷兰东印度公司-成熟的经济模式" class="headerlink" title="荷兰东印度公司  成熟的经济模式"></a>荷兰东印度公司  成熟的经济模式</h4><p>7.9万亿美金</p><p>香料</p><p>公司建立</p><p>1、相互竞争，风险承受力差</p><p>2、1602年 14家合起来成立荷兰东印度公司</p><p>第一家股份公司，股息，董事会，证券交易</p><h4 id="法国密西西比公司-6-5万亿-泡沫"><a href="#法国密西西比公司-6-5万亿-泡沫" class="headerlink" title="法国密西西比公司  6.5万亿 泡沫"></a>法国密西西比公司  6.5万亿 泡沫</h4><h4 id="英国南海公司-4-33万亿-泡沫"><a href="#英国南海公司-4-33万亿-泡沫" class="headerlink" title="英国南海公司 4.33万亿 泡沫"></a>英国南海公司 4.33万亿 泡沫</h4><p>黑奴贸易</p><h2 id="日本房地产"><a href="#日本房地产" class="headerlink" title="日本房地产"></a>日本房地产</h2><p>美国经济，最大的债权国–&gt; 最大的债务国</p><p>广场协议</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;郁金香狂热&quot;&gt;&lt;a href=&quot;#郁金香狂热&quot; class=&quot;headerlink&quot; title=&quot;郁金香狂热&quot;&gt;&lt;/a&gt;郁金香狂热&lt;/h2&gt;&lt;h3 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背</summary>
      
    
    
    
    <category term="杂记" scheme="http://universeinheart.github.io/categories/%E6%9D%82%E8%AE%B0/"/>
    
    
    <category term="杂记" scheme="http://universeinheart.github.io/tags/%E6%9D%82%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>如何快速阅读</title>
    <link href="http://universeinheart.github.io/2021/04/13/%E5%B0%8F%E5%86%8C%E5%AD%90/%E5%A6%82%E4%BD%95%E5%BF%AB%E9%80%9F%E9%98%85%E8%AF%BB/"/>
    <id>http://universeinheart.github.io/2021/04/13/%E5%B0%8F%E5%86%8C%E5%AD%90/%E5%A6%82%E4%BD%95%E5%BF%AB%E9%80%9F%E9%98%85%E8%AF%BB/</id>
    <published>2021-04-13T15:26:37.000Z</published>
    <updated>2021-04-13T15:40:18.174Z</updated>
    
    <content type="html"><![CDATA[<h2 id=""><a href="#" class="headerlink" title=""></a></h2><p>1、专注</p><p>2、消除干扰</p><p>3、增加视野，在书每页的两侧画垂直线，减少阅读范围</p><p>4、消除回溯，手指</p><p>5、想象，身临其境，可视化</p><p>6、长时间阅读</p><p>7、休息</p><p>8、练习</p><p>9、摘要</p>]]></content>
    
    
    <summary type="html">如何快速阅读</summary>
    
    
    
    <category term="杂记" scheme="http://universeinheart.github.io/categories/%E6%9D%82%E8%AE%B0/"/>
    
    
    <category term="杂记" scheme="http://universeinheart.github.io/tags/%E6%9D%82%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>05、Redis 内存快照</title>
    <link href="http://universeinheart.github.io/2021/04/10/Redis/05/"/>
    <id>http://universeinheart.github.io/2021/04/10/Redis/05/</id>
    <published>2021-04-10T11:57:15.000Z</published>
    <updated>2021-04-10T12:17:57.841Z</updated>
    
    <content type="html"><![CDATA[<p><strong>内存快照</strong>，就是指内存中的数据在某一个时刻的状态记录。这就类似于照片，当你给朋友拍照时，一张照片就能把朋友一瞬间的形象完全记下来。</p><p>和 AOF 相比，RDB 记录的是某一时刻的数据，并不是操作，所以，在做数据恢复时，我们可以直接把 RDB 文件读入内存，很快地完成恢复</p><h3 id="对哪些数据做快照？-快照的执行效率问题"><a href="#对哪些数据做快照？-快照的执行效率问题" class="headerlink" title="对哪些数据做快照？(快照的执行效率问题?)"></a>对哪些数据做快照？(快照的执行效率问题?)</h3><p> Redis 的数据都在内存中，为了提供所有数据的可靠性保证，它执行的是全量快照</p><p> Redis 提供了两个命令来生成 RDB 文件，分别是 <code>save</code> 和 <code>bgsave</code>。</p><ul><li>save：在主线程中执行，会导致阻塞</li><li>bgsave：创建一个子进程，专门用于写入 RDB 文件，避免了主线程的阻塞，这也是 Redis RDB 文件生成的默认配置</li></ul><h3 id="做快照时，数据还能被增删改吗？-Redis-是否被阻塞，能否同时正常处理请求"><a href="#做快照时，数据还能被增删改吗？-Redis-是否被阻塞，能否同时正常处理请求" class="headerlink" title="做快照时，数据还能被增删改吗？( Redis 是否被阻塞，能否同时正常处理请求?)"></a>做快照时，数据还能被增删改吗？( Redis 是否被阻塞，能否同时正常处理请求?)</h3><p> 为了快照而暂停写操作，肯定是不能接受的。Redis 就会借助操作系统提供的 <strong>写时复制技术（Copy-On-Write, COW）</strong>，在执行快照的同时，正常处理写操作。</p><p> bgsave 子进程是由主线程 fork 生成的，可以共享主线程的所有内存数据。bgsave 子进程运行后，开始读取主线程的内存数据，并把它们写入 RDB 文件。</p><p>如果主线程对这些数据也都是读操作（例如图中的键值对 A），那么，主线程和 bgsave 子进程相互不影响。但是，如果主线程要修改一块数据（例如图中的键值对 C），那么，这块数据就会被复制一份，生成该数据的副本。然后，<code>bgsave</code> 子进程会把这个副本数据写入 RDB 文件，而在这个过程中，主线程仍然可以直接修改原来的数据。</p><img src="/2021/04/10/Redis/05/image-20210114000648827.png" class="" title="image-20210114000648827"><p>虽然 bgsave 执行时不阻塞主线程，但是，如果频繁地执行全量快照，也会带来两方面的开销。</p><p>一方面，频繁将全量数据写入磁盘，会给磁盘带来很大压力，多个快照竞争有限的磁盘带宽，前一个快照还没有做完，后一个又开始做了，容易造成恶性循环。</p><p>另一方面，bgsave 子进程需要通过 fork 操作从主线程创建出来。虽然，子进程在创建后不会再阻塞主线程，但是，fork 这个创建过程本身会阻塞主线程，而且主线程的内存越大，阻塞时间越长。如果频繁 fork 出 bgsave 子进程，这就会频繁阻塞主线程了。</p><h3 id="增量快照"><a href="#增量快照" class="headerlink" title="增量快照"></a>增量快照</h3><p>增量快照，就是指，做了一次全量快照后，后续的快照只对修改的数据进行快照记录，这样可以避免每次全量快照的开销。但是需要我们使用额外的元数据信息去记录哪些数据被修改了，这会带来额外的空间开销问题</p><img src="/2021/04/10/Redis/05/image-20210114224110088.png" class="" title="image-20210114224110088"><h3 id="混合使用-AOF-日志和内存快照"><a href="#混合使用-AOF-日志和内存快照" class="headerlink" title="混合使用 AOF 日志和内存快照"></a>混合使用 AOF 日志和内存快照</h3><p>内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。</p><p>这样一来，快照不用很频繁地执行，这就避免了频繁 fork 对主线程的影响。而且，AOF 日志也只用记录两次快照间的操作，也就是说，不需要记录所有操作了，因此，就不会出现文件过大的情况了，也可以避免重写开销。</p><p>如下图所示，T1 和 T2 时刻的修改，用 AOF 日志记录，等到第二次做全量快照时，就可以清空 AOF 日志，因为此时的修改都已经记录到快照中了，恢复时就不再用日志了</p><img src="/2021/04/10/Redis/05/image-20210114224334522.png" class="" title="image-20210114224334522">]]></content>
    
    
    <summary type="html">宕机后，Redis如何实现快速恢复</summary>
    
    
    
    <category term="极客时间Redis实战" scheme="http://universeinheart.github.io/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4Redis%E5%AE%9E%E6%88%98/"/>
    
    
    <category term="Redis" scheme="http://universeinheart.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>03、Redis 高性能IO模型</title>
    <link href="http://universeinheart.github.io/2021/04/10/Redis/03/"/>
    <id>http://universeinheart.github.io/2021/04/10/Redis/03/</id>
    <published>2021-04-10T11:50:15.000Z</published>
    <updated>2021-04-10T12:17:46.226Z</updated>
    
    <content type="html"><![CDATA[<p>Redis 是单线程，主要是指 Redis 的 <strong>网络 IO</strong> 和 <strong>键值对读写</strong> 是由一个线程来完成的，这也是 Redis 对外提供键值存储服务的主要流程。但 Redis 的其他功能，比如持久化、异步删除、集群数据同步等，其实是由额外的线程执行的。</p><h2 id="Redis-为什么用单线程？-避免了多线程的开销"><a href="#Redis-为什么用单线程？-避免了多线程的开销" class="headerlink" title="Redis 为什么用单线程？(避免了多线程的开销)"></a>Redis 为什么用单线程？(避免了多线程的开销)</h2><p>多线程编程模式面临的<strong>共享资源的并发访问控制问题</strong></p><h2 id="单线程-Redis-为什么那么快？"><a href="#单线程-Redis-为什么那么快？" class="headerlink" title="单线程 Redis 为什么那么快？"></a>单线程 Redis 为什么那么快？</h2><ol><li>Redis 的大部分操作在 <strong>内存</strong> 上完成，再加上它采用了高效的数据结构，例如哈希表和跳表</li><li>Redis 采用了 <strong>多路复用机制</strong>，使其在网络 IO 操作中能并发处理大量的客户端请求，实现高吞吐率</li></ol><h2 id="基本-IO-模型与阻塞点"><a href="#基本-IO-模型与阻塞点" class="headerlink" title="基本 IO 模型与阻塞点"></a>基本 IO 模型与阻塞点</h2><p>以 <code>Get</code> 请求为例，为了处理一个 <code>Get</code> 请求，需要监听客户端请求（<code>bind/listen</code>），和客户端建立连接（<code>accept</code>），从 <code>socket</code> 中读取请求（<code>recv</code>），解析客户端发送请求（<code>parse</code>），根据请求类型读取键值数据（<code>get</code>），最后给客户端返回结果，即向 <code>socket</code> 中写回数据（<code>send</code>）。</p><p>下图显示了这一过程，其中，<code>bind/listen</code>、<code>accept</code>、<code>recv</code>、<code>parse</code> 和 <code>send</code> 属于网络 IO 处理，而 <code>get</code> 属于键值数据操作。既然 Redis 是单线程，那么，最基本的一种实现是在一个线程中依次执行上面说的这些操作。</p><img src="/2021/04/10/Redis/03/image-20210110182324959.png" class="" title="image-20210110182324959"><p>网络 IO 操作中，有潜在的阻塞点，分别是 <code>accept()</code> 和 <code>recv()</code>。当 Redis 监听到一个客户端有连接请求，但一直未能成功建立起连接时，会阻塞在 <code>accept()</code> 函数这里，导致其他客户端无法和 Redis 建立连接。类似的，当 <code>Redis</code> 通过 <code>recv()</code> 从一个客户端读取数据时，如果数据一直没有到达，Redis 也会一直阻塞在 <code>recv()</code>。</p><p>这就导致 Redis 整个线程阻塞，无法处理其他客户端请求，效率很低。不过，幸运的是，<strong>socket 网络模型本身支持非阻塞模式</strong></p><h3 id="非阻塞模式"><a href="#非阻塞模式" class="headerlink" title="非阻塞模式"></a>非阻塞模式</h3><p><code>Socket</code> 网络模型的非阻塞模式设置，主要体现在三个关键的函数调用上，如果想要使用 <code>socket</code> 非阻塞模式，就必须要了解这三个函数的调用返回类型和设置模式</p><p>在 <code>socket</code> 模型中，不同操作调用后会返回不同的套接字类型。<code>socket()</code> 方法会返回主动套接字，然后调用 <code>listen()</code> 方法，将主动套接字转化为监听套接字，此时，可以监听来自客户端的连接请求。最后，调用 <code>accept()</code> 方法接收到达的客户端连接，并返回已连接套接字。</p><img src="/2021/04/10/Redis/03/image-20210110185051995.png" class="" title="image-20210110185051995"><p>针对<strong>监听套接字</strong>设置非阻塞模式：当 Redis 调用 <code>accept()</code> 但一直未有连接请求到达时，Redis 线程可以返回处理其他操作，而不用一直等待。但是，你要注意的是，调用 <code>accept()</code> 时，已经存在监听套接字了。虽然 Redis 线程可以不用继续等待，但是总得有机制继续在监听套接字上等待后续连接请求，并在有请求时通知 Redis。</p><p>针对<strong>已连接套接字</strong>设置非阻塞模式：Redis 调用 <code>recv()</code> 后，如果已连接套接字上一直没有数据到达，Redis 线程同样可以返回处理其他操作。我们也需要有机制继续监听该已连接套接字，并在有数据达到时通知 Redis。</p><p>这样才能保证 Redis 线程，既不会像基本 IO 模型中一直在阻塞点等待，也不会导致 Redis 无法处理实际到达的连接请求或数据。到此，Linux 中的 IO 多路复用机制就要登场了。</p><h3 id="基于多路复用的高性能-I-O-模型"><a href="#基于多路复用的高性能-I-O-模型" class="headerlink" title="基于多路复用的高性能 I/O 模型"></a>基于多路复用的高性能 I/O 模型</h3><p>Linux 中的 IO 多路复用机制是指<strong>一个线程处理多个 IO 流</strong>，就是我们经常听到的 <strong>select/epoll 机制</strong></p><p>在 Redis 只运行单线程的情况下，<strong>该机制允许内核中，同时存在多个监听套接字和已连接套接字</strong>。内核会一直监听这些套接字上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。</p><img src="/2021/04/10/Redis/03/image-20210110190900846.png" class="" title="image-20210110190900846"><p>图中的多个 <code>FD</code> 就是刚才所说的多个套接字。Redis 网络框架调用 epoll 机制，让内核监听这些套接字。此时，<code>Redis</code> 线程不会阻塞在某一个特定的监听或已连接套接字上，也就是说，不会阻塞在某一个特定的客户端请求处理上。正因为此，Redis 可以同时和多个客户端连接并处理请求，从而提升并发性。</p><p>为了在请求到达时能通知到 Redis 线程，<code>select/epoll</code> 提供了<strong>基于事件的回调机制</strong>，即针对不同事件的发生，调用相应的处理函数。<code>select/epoll</code> 一旦监测到 <code>FD</code> 上有请求到达时，就会触发相应的事件。</p><p>这些事件会被放进一个事件队列，Redis 单线程对该事件队列不断进行处理。这样一来，Redis 无需一直轮询是否有请求实际发生，这就可以避免造成 CPU 资源浪费。同时，Redis 在对事件队列中的事件进行处理时，会调用相应的处理函数，这就实现了基于事件的回调。因为 Redis 一直在对事件队列进行处理，所以能及时响应客户端请求，提升 Redis 的响应性能。</p><p>方便理解，再以连接请求和读数据请求为例，具体解释一下。如两个请求分别对应 <code>Accept</code> 事件和 <code>Read</code> 事件，<code>Redis</code> 分别对这两个事件注册 <code>accept</code> 和 <code>get</code> 回调函数。当 Linux 内核监听到有连接请求或读数据请求时，就会触发 <code>Accept</code> 事件和 <code>Read</code> 事件，此时，内核就会回调 <code>Redis</code> 相应的 <code>accept</code> 和 <code>get</code> 函数进行处理。</p>]]></content>
    
    
    <summary type="html">为什么单线程Redis能这么快？</summary>
    
    
    
    <category term="极客时间Redis实战" scheme="http://universeinheart.github.io/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4Redis%E5%AE%9E%E6%88%98/"/>
    
    
    <category term="Redis" scheme="http://universeinheart.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>04、Redis AOF日志</title>
    <link href="http://universeinheart.github.io/2021/04/10/Redis/04/"/>
    <id>http://universeinheart.github.io/2021/04/10/Redis/04/</id>
    <published>2021-04-10T11:50:15.000Z</published>
    <updated>2021-04-13T15:59:42.390Z</updated>
    
    <content type="html"><![CDATA[<p>Redis 的持久化主要有两大机制，即 **AOF（Append Only File）日志 **和  <strong>RDB 快照</strong></p><h2 id="AOF-日志是如何实现的？"><a href="#AOF-日志是如何实现的？" class="headerlink" title="AOF 日志是如何实现的？"></a>AOF 日志是如何实现的？</h2><p>数据库的 <strong>写前日志（Write Ahead Log, WAL）</strong>，在实际写数据前，先把修改的数据记到日志文件中，以便故障时进行恢复。</p><p>不过，AOF 日志正好相反，它是 <strong>写后日志</strong>，“写后”的意思是 <strong>Redis 是先执行命令，把数据写入内存，然后才记录日志</strong>，如下图所示：</p><img src="/2021/04/10/Redis/04/image-20210111232040747.png" class="" title="image-20210111232040747"><h3 id="那-AOF-为什么要先执行命令再记日志呢？"><a href="#那-AOF-为什么要先执行命令再记日志呢？" class="headerlink" title="那 AOF 为什么要先执行命令再记日志呢？"></a>那 AOF 为什么要先执行命令再记日志呢？</h3><p>传统数据库的日志，例如 <strong>redo log（重做日志）</strong>，记录的是修改后的数据，而 AOF 里记录的是 <strong>Redis 收到的每一条命令</strong>，这些命令是以文本形式保存的。</p><blockquote><p>以 Redis 收到“set testkey testvalue”命令后记录的日志为例，看看 AOF 日志的内容。</p><p>其中，“*3”表示当前命令有三个部分，每部分都是由“$+数字”开头，后面紧跟着具体的命令、键或值。这里，“数字”表示这部分中的命令、键或值一共有多少字节。例如，“$3 set”表示这部分有 3 个字节，也就是“set”命令。</p></blockquote><img src="/2021/04/10/Redis/04/image-20210111232612880.png" class="" title="image-20210111232612880"><p>为了避免额外的检查开销，Redis 在向 AOF 里面记录日志的时候，并不会先去对这些命令进行语法检查。所以，如果先记日志再执行命令的话，日志中就有可能记录了错误的命令，Redis 在使用日志恢复数据时，就可能会出错。而写后日志这种方式，就是先让系统执行命令，只有命令能执行成功，才会被记录到日志中，否则，系统就会直接向客户端报错。</p><p>所以，Redis 使用写后日志这一方式的一大好处是，可以 <strong>避免出现记录错误命令</strong> 的情况。AOF 还有一个好处：它是在命令执行后才记录日志，所以<strong>不会阻塞当前的写操作</strong>。</p><h3 id="AOF-也有两个潜在的风险"><a href="#AOF-也有两个潜在的风险" class="headerlink" title="AOF 也有两个潜在的风险"></a>AOF 也有两个潜在的风险</h3><p>首先，如果刚执行完一个命令，还没有来得及记日志就宕机了，那么这个命令和相应的数据就有丢失的风险。如果此时 Redis 是用作缓存，还可以从后端数据库重新读入数据进行恢复，但是，如果 Redis 是直接用作数据库的话，此时，因为命令没有记入日志，所以就无法用日志进行恢复了。</p><p>其次，AOF 虽然避免了对当前命令的阻塞，但可能会给下一个操作带来阻塞风险。这是因为，AOF 日志也是在主线程中执行的，如果在把日志文件写入磁盘时，磁盘写压力大，就会导致写盘很慢，进而导致后续的操作也无法执行了。</p><p>仔细分析的话，你就会发现，这两个风险都是和 <strong>AOF 写回磁盘的时机</strong>相关的。这也就意味着，如果我们能够控制一个写命令执行完后 AOF 日志写回磁盘的时机，这两个风险就解除了。</p><h2 id="三种写回策略"><a href="#三种写回策略" class="headerlink" title="三种写回策略"></a>三种写回策略</h2><p>AOF 机制给我们提供了三个选择，也就是 AOF 配置项 <code>appendfsync</code> 的三个可选值。</p><ul><li><strong>Always</strong>，<strong>同步写回</strong>：每个写命令执行完，立马同步地将日志写回磁盘；不可避免地会影响主线程性能</li><li><strong>Everysec</strong>，<strong>每秒写回</strong>：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘；在避免影响主线程性能和避免数据丢失两者间取了个折中。</li><li><strong>No</strong>，<strong>操作系统控制的写回</strong>：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。落盘的时机已经不在 Redis 手中了，只要 AOF 记录没有写回磁盘，一旦宕机对应的数据就丢失了</li></ul><img src="/2021/04/10/Redis/04/image-20210111233115916.png" class="" title="image-20210111233115916"><p>随着接收的写命令越来越多，AOF 文件会越来越大。一定要小心 AOF 文件过大带来的性能问题。</p><p>一、文件系统本身对文件大小有限制，无法保存过大的文件</p><p>二、如果文件太大，之后再往里面追加命令记录的话，效率也会变低</p><p>三、如果发生宕机，AOF 中记录的命令要一个个被重新执行，用于故障恢复，如果日志文件太大，整个恢复过程就会非常缓慢，这就会影响到 Redis 的正常使用。</p><h2 id="日志文件太大了怎么办？（AOF-重写机制）"><a href="#日志文件太大了怎么办？（AOF-重写机制）" class="headerlink" title="日志文件太大了怎么办？（AOF 重写机制）"></a>日志文件太大了怎么办？（AOF 重写机制）</h2><p>重写机制具有“多变一”功能。旧日志文件中的多条命令，在重写后的新日志中变成了一条命令。</p><p><code>AOF</code> 文件是以追加的方式，逐一记录接收到的写命令的。当一个键值对被多条写命令反复修改时，AOF 文件会记录相应的多条命令。但是，在重写的时候，是根据这个键值对当前的最新状态，为它生成对应的写入命令。这样一来，一个键值对在重写日志中只用一条命令就行了，而且，在日志恢复时，只用执行这条命令，就可以直接完成这个键值对的写入了。</p><img src="/2021/04/10/Redis/04/image-20210113224725050.png" class="" title="image-20210113224725050"><h2 id="AOF-重写会阻塞吗"><a href="#AOF-重写会阻塞吗" class="headerlink" title="AOF 重写会阻塞吗?"></a>AOF 重写会阻塞吗?</h2><p>和 <strong>AOF 日志由主线程写回</strong> 不同，重写过程是由后台子进程 <code>bgrewriteaof</code> 来完成的，这也是为了避免阻塞主线程，导致数据库性能下降。</p><p>每次执行重写时，主线程 fork 出后台的 <code>bgrewriteaof</code> 子进程。此时，fork 会把主线程的内存拷贝一份给 <code>bgrewriteaof</code> 子进程，这里面就包含了数据库的最新数据。然后，<code>bgrewriteaof</code> 子进程就可以在不影响主线程的情况下，逐一把拷贝的数据写成操作，记入重写日志。</p><p>因为主线程未阻塞，仍然可以处理新来的操作。此时，如果有写操作，Redis 会把这个操作写到它的缓冲区。这样一来，即使宕机了，这个 AOF 日志的操作仍然是齐全的，可以用于恢复。这个操作也会被写到重写日志的缓冲区。这样，重写日志也不会丢失最新的操作。等到拷贝数据的所有操作记录重写完成后，重写日志记录的这些最新操作也会写入新的 AOF 文件，以保证数据库最新状态的记录。此时，我们就可以用新的 AOF 文件替代旧文件了。</p><img src="/2021/04/10/Redis/04/image-20210113233333814.png" class="" title="image-20210113233333814"><p>每次 AOF 重写时，Redis 会先执行一个内存拷贝，用于重写；然后，使用两个日志保证在重写过程中，新写入的数据不会丢失。而且，因为 Redis 采用额外的线程进行数据重写，所以，这个过程并不会阻塞主线程。</p>]]></content>
    
    
    <summary type="html">宕机了，Redis如何避免数据丢失</summary>
    
    
    
    <category term="极客时间Redis实战" scheme="http://universeinheart.github.io/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4Redis%E5%AE%9E%E6%88%98/"/>
    
    
    <category term="Redis" scheme="http://universeinheart.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>00、Redis 相关</title>
    <link href="http://universeinheart.github.io/2021/04/09/Redis/0/"/>
    <id>http://universeinheart.github.io/2021/04/09/Redis/0/</id>
    <published>2021-04-09T14:00:15.000Z</published>
    <updated>2021-04-10T12:17:38.083Z</updated>
    
    <content type="html"><![CDATA[<img src="/2021/04/09/Redis/0/image-20210109194509294.png" class="" title="image-20210109194509294"><img src="/2021/04/09/Redis/0/image-20210109194543978.png" class="" title="image-20210109194543978">]]></content>
    
    
    <summary type="html">Redis描述</summary>
    
    
    
    <category term="极客时间Redis实战" scheme="http://universeinheart.github.io/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4Redis%E5%AE%9E%E6%88%98/"/>
    
    
    <category term="Redis" scheme="http://universeinheart.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>01、Redis 基础架构</title>
    <link href="http://universeinheart.github.io/2021/04/09/Redis/01/"/>
    <id>http://universeinheart.github.io/2021/04/09/Redis/01/</id>
    <published>2021-04-09T14:00:15.000Z</published>
    <updated>2021-04-10T12:17:04.651Z</updated>
    
    <content type="html"><![CDATA[<p>更好的学习方式就是先建立起“<code>系统观</code>”</p><p>一个键值数据库包括了<code>访问框架</code>、<code>索引模块</code>、<code>操作模块</code>和<code>存储模块</code>四部分，我们从这四个部分入手，构建我们的 <code>SimpleKV</code></p><img src="/2021/04/09/Redis/01/image-20210109195252143.png" class="" title="image-20210109201055704"><h2 id="采用什么访问模式？"><a href="#采用什么访问模式？" class="headerlink" title="采用什么访问模式？"></a>采用什么访问模式？</h2><p>访问模式通常有两种：</p><p>一、通过函数库调用的方式供外部应用使用，比如，上图中的 libsimplekv.so，就是以动态链接库的形式链接到我们自己的程序中，提供键值存储功能；</p><p>二、通过网络框架以 Socket 通信的形式对外提供键值对操作，网络框架中包括 Socket Server 和协议解析。（Redis使用）</p><blockquote><p>通过网络框架提供键值存储服务，一方面扩大了键值数据库的受用面，但另一方面，也给键值数据库的性能、运行模型提供了不同的设计选择，带来了一些潜在的问题。</p><p>举个例子，当客户端发送一个如下的命令后，该命令会被封装在网络包中发送给键值数据库：<code>PUT hello world</code></p><p>键值数据库网络框架接收到网络包，并按照相应的协议进行解析之后，就可以知道，客户端想写入一个键值对，并开始实际的写入流程。此时，我们会遇到一个系统设计上的问题，简单来说，就是<strong>网络连接的处理</strong>、<strong>网络请求的解析</strong>，以及<strong>数据存取的处理</strong>，是用一个线程、多个线程，还是多个进程来交互处理呢？该如何进行设计和取舍呢？我们一般把这个问题称为 I/O 模型设计。不同的 I/O 模型对键值数据库的性能和可扩展性会有不同的影响。</p><p>举个例子，如果一个线程既要处理网络连接、解析请求，又要完成数据存取，一旦某一步操作发生阻塞，整个线程就会阻塞住，这就降低了系统响应速度。如果我们采用不同线程处理不同操作，那么，某个线程被阻塞时，其他线程还能正常运行。但是，不同线程间如果需要访问共享资源，那又会产生线程竞争，也会影响系统效率，这又该怎么办呢？所以，这的确是个“两难”选择，需要我们进行精心的设计。</p></blockquote><h2 id="如何定位键值对的位置？"><a href="#如何定位键值对的位置？" class="headerlink" title="如何定位键值对的位置？"></a>如何定位键值对的位置？</h2><p>**索引 **的作用是让键值数据库根据 <code>key</code> 找到相应 <code>value</code> 的存储位置，进而执行操作。</p><p><code>Redis</code> 采用哈希表作为 <code>key-value</code> 索引，也会采用跳表（）</p><h2 id="不同操作的具体逻辑是怎样的？"><a href="#不同操作的具体逻辑是怎样的？" class="headerlink" title="不同操作的具体逻辑是怎样的？"></a>不同操作的具体逻辑是怎样的？</h2><ul><li>对于 <code>GET/SCAN</code> 操作而言，此时根据 <code>value</code> 的存储位置返回 <code>value</code> 值即可；</li><li>对于 <code>PUT</code> 一个新的键值对数据而言，需要为该键值对分配内存空间；</li><li>对于 <code>DELETE</code> 操作，需要删除键值对，并释放相应的内存空间，这个过程由分配器完成。</li></ul><p>对于 <code>PUT</code> 和 <code>DELETE</code> 两种操作来说，除了新写入和删除键值对，还需要分配和释放内存。这就需要存储模块了。</p><blockquote><p> SimpleKV 采用了常用的内存分配器 <code>glibc</code> 的 <code>malloc</code> 和 <code>free</code>，因此，SimpleKV 并不需要特别考虑内存空间的管理问题。但是，键值数据库的键值对通常大小不一，<code>glibc</code> 的分配器在处理随机的大小内存块分配时，表现并不好。一旦保存的键值对数据规模过大，就可能会造成较严重的内存碎片问题。因此，分配器是键值数据库中的一个关键因素。</p><p>对于以内存存储为主的 Redis 而言，这点尤为重要。Redis 的内存分配器提供了多种选择，分配效率也不一样 </p></blockquote><h2 id="如何实现重启后快速提供服务？"><a href="#如何实现重启后快速提供服务？" class="headerlink" title="如何实现重启后快速提供服务？"></a>如何实现重启后快速提供服务？</h2><p>存储模块中增加了持久化功能，重启后能快速重新提供服务</p><blockquote><p>不过，鉴于磁盘管理要比内存管理复杂，SimpleKV 就直接采用了文件形式，将键值数据通过调用本地文件系统的操作接口保存在磁盘上。此时，SimpleKV 只需要考虑何时将内存中的键值数据保存到文件中，就可以了。</p><p>一种方式是，对于每一个键值对，SimpleKV 都对其进行落盘保存，这虽然让 SimpleKV 的数据更加可靠，但是，因为每次都要写盘，SimpleKV 的性能会受到很大影响。</p><p>另一种方式是，SimpleKV 只是周期性地把内存中的键值数据保存到文件中，这样可以避免频繁写盘操作的性能影响。但是，一个潜在的代价是 SimpleKV 的数据仍然有丢失的风险。</p><p>和 SimpleKV 一样，Redis 也提供了持久化功能。不过，为了适应不同的业务场景，Redis 为持久化提供了诸多的执行机制和优化改进 </p></blockquote><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>从 <code>SimpleKV</code> 演进到 <code>Redis</code>，有以下几个重要变化：</p><ul><li><code>Redis</code> 主要通过网络框架进行访问，而不再是动态库了，这也使得 Redis 可以作为一个基础性的网络服务进行访问，扩大了 Redis 的应用范围。</li><li><code>Redis</code> 数据模型中的 value 类型很丰富，因此也带来了更多的操作接口，例如面向列表的 <code>LPUSH/LPOP</code>，面向集合的 <code>SADD/SREM</code> 等。</li><li><code>Redis</code> 的持久化模块能支持两种方式：日志（<code>AOF</code>）和快照（<code>RDB</code>），这两种持久化方式具有不同的优劣势，影响到 <code>Redis</code> 的访问性能和可靠性。</li><li><code>SimpleKV</code> 是个简单的单机键值数据库，但是，<code>Redis</code> 支持高可靠集群和高可扩展集群，因此，<code>Redis</code> 中包含了相应的集群功能支撑模块。</li></ul><img src="/2021/04/09/Redis/01/image-20210109201055704.png" class="" title="image-20210109201055704">]]></content>
    
    
    <summary type="html">一个键值数据库包含什么？</summary>
    
    
    
    <category term="极客时间Redis实战" scheme="http://universeinheart.github.io/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4Redis%E5%AE%9E%E6%88%98/"/>
    
    
    <category term="Redis" scheme="http://universeinheart.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>02、Redis 数据结构</title>
    <link href="http://universeinheart.github.io/2021/04/09/Redis/02/"/>
    <id>http://universeinheart.github.io/2021/04/09/Redis/02/</id>
    <published>2021-04-09T14:00:15.000Z</published>
    <updated>2021-04-10T12:17:40.744Z</updated>
    
    <content type="html"><![CDATA[<p>数据库这么多，为啥 Redis 能有这么突出的表现呢？一方面，这是因为它是 <strong>内存数据库</strong>，所有操作都在内存上完成，内存的访问速度本身就很快。另一方面，这要归功于它的<strong>数据结构</strong>。这是因为，键值对是按一定的数据结构来组织的，操作键值对最终就是对数据结构进行增删改查操作，所以高效的数据结构是 Redis 快速处理数据的基础。</p><p>底层数据结构一共有 6 种，分别是 <strong>简单动态字符串</strong>、<strong>双向链表</strong>、<strong>压缩列表</strong>、<strong>哈希表</strong>、<strong>跳表</strong>和<strong>整数数组</strong>。</p><p>它们和数据类型的对应关系如下图所示：</p><img src="/2021/04/09/Redis/02/image-20210110094110377.png" class="" title="image-20210110094110377"><p><code>String</code> 类型的底层实现只有一种数据结构，也就是简单动态字符串。</p><p><code>List</code>、<code>Hash</code>、<code>Set</code> 和 <code>Sorted Set</code> 这四种数据类型，都有两种底层实现结构。特点是<strong>一个键对应了一个集合的数据</strong>。</p><blockquote><p>问题1. 这些数据结构都是值的底层实现，键和值本身之间用什么结构组织？</p><p>问题2. 为什么集合类型有那么多的底层结构，它们都是怎么组织数据的，都很快吗？</p><p>问题3. 什么是简单动态字符串，和常用的字符串是一回事吗？</p></blockquote><h3 id="键和值用什么结构组织？"><a href="#键和值用什么结构组织？" class="headerlink" title="键和值用什么结构组织？"></a>键和值用什么结构组织？</h3><p>为了实现从键到值的快速访问，Redis 使用了一个<strong>哈希表</strong>来保存所有键值对。一个哈希表，其实就是一个数组，数组的每个元素称为一个哈希桶</p><blockquote><p>Q:如果值是集合类型的话，作为数组元素的哈希桶怎么来保存呢？</p><p>A:哈希桶中的元素保存的并不是值本身，而是指向具体值的指针。这也就是说，不管值是 String，还是集合类型，哈希桶中的元素都是指向它们的指针。</p></blockquote><img src="/2021/04/09/Redis/02/image-20210110095737063.png" class="" title="image-20210110095737063"><p><strong>潜在的风险点: 哈希表的冲突问题和 rehash 可能带来的操作阻塞。</strong></p><p>哈希冲突 –&gt;  链式哈希  –&gt;  效率降低 –&gt; rehash(增加哈希桶数量)</p><p>为了使 <code>rehash</code> 操作更高效，<code>Redis</code> 默认使用了两个全局哈希表：<strong>哈希表 1</strong> 和<strong>哈希表 2</strong>。</p><p>一开始，当你刚插入数据时，默认使用<strong>哈希表 1</strong>，此时的<strong>哈希表 2</strong> 并没有被分配空间。</p><p>随着数据逐步增多，Redis 开始执行 <code>rehash</code>，这个过程分为三步：</p><ol><li><p>给<strong>哈希表 2</strong> 分配更大的空间，例如是当前<strong>哈希表 1</strong> 大小的两倍；</p></li><li><p>把<strong>哈希表 1</strong> 中的数据重新映射并拷贝到<strong>哈希表 2</strong> 中；</p></li><li><p>释放<strong>哈希表 1</strong> 的空间。</p></li></ol><p>到此，我们就可以从 <strong>哈希表 1</strong> 切换到 <strong>哈希表 2</strong>，用增大的 <strong>哈希表 2</strong> 保存更多数据，而原来的<strong>哈希表 1</strong> 留作下一次 <code>rehash</code> 扩容备用。</p><p>这个过程看似简单，但是第二步涉及大量的数据拷贝，如果一次性把<strong>哈希表 1</strong> 中的数据都迁移完，会造成 <strong>Redis 线程阻塞</strong>，无法服务其他请求。此时，Redis 就无法快速访问数据了。</p><p>为了避免这个问题，Redis 采用了 <strong>渐进式 rehash</strong>。</p><p><strong>渐进式 rehash</strong>在第二步拷贝数据时，Redis 仍然正常处理客户端请求，每处理一个请求时，从 <strong>哈希表 1</strong> 中的第一个索引位置开始，顺带着将这个索引位置上的所有 <code>entries</code> 拷贝到 <strong>哈希表 2</strong> 中；等处理下一个请求时，再顺带拷贝 <strong>哈希表 1</strong> 中的下一个索引位置的 <code>entries</code>。如下图所示</p><img src="/2021/04/09/Redis/02/image-20210110163432821.png" class="" title="image-20210110163432821"><p>巧妙地把一次性大量拷贝的开销，分摊到了多次处理请求的过程中，避免了耗时操作，保证了数据的快速访问。</p><h3 id="底层数据结构？"><a href="#底层数据结构？" class="headerlink" title="底层数据结构？"></a>底层数据结构？</h3><p>整数数组</p><p>双向链表</p><p>哈希表</p><h4 id="压缩列表"><a href="#压缩列表" class="headerlink" title="压缩列表"></a>压缩列表</h4><p>压缩列表实际上类似于一个数组，数组中的每一个元素都对应保存一个数据。</p><p>和数组不同的是，压缩列表在表头有三个字段 <code>zlbytes</code>、<code>zltail</code> 和 <code>zllen</code>，分别表示 <strong>列表长度</strong>、<strong>列表尾的偏移量</strong> 和 <strong>列表中的 entry 个数</strong>；压缩列表在表尾还有一个 <code>zlend</code>，表示列表结束。</p><img src="/2021/04/09/Redis/02/image-20210110164229889.png" class="" title="image-20210110164229889"><p>在压缩列表中，如果我们要查找定位第一个元素和最后一个元素，可以通过表头三个字段的长度直接定位，复杂度是 O(1)。而查找其他元素时，就没有这么高效了，只能逐个查找，此时的复杂度就是 O(N) 了。</p><h4 id="跳表"><a href="#跳表" class="headerlink" title="跳表"></a>跳表</h4><p>跳表在链表的基础上，增加了多级索引，通过索引位置的几个跳转，实现<strong>有序数据</strong>的快速定位</p><img src="/2021/04/09/Redis/02/image-20210110165006388.png" class="" title="image-20210110165006388"><h3 id="不同操作的复杂度"><a href="#不同操作的复杂度" class="headerlink" title="不同操作的复杂度"></a>不同操作的复杂度</h3><h4 id="单元素操作是基础"><a href="#单元素操作是基础" class="headerlink" title="单元素操作是基础"></a>单元素操作是基础</h4><p>单元素操作，是指每一种集合类型对单个数据实现的增删改查操作。</p><p>例如，<code>Hash</code> 类型的 <code>HGET</code>、<code>HSET</code> 和 <code>HDEL</code>，<code>Set</code> 类型的 <code>SADD</code>、<code>SREM</code>、<code>SRANDMEMBER</code> 等。</p><p>这些操作的复杂度由集合采用的数据结构决定，例如，<code>HGET</code>、<code>HSET</code> 和 <code>HDEL</code> 是对哈希表做操作，所以它们的复杂度都是 O(1)；Set 类型用哈希表作为底层数据结构时，它的 <code>SADD</code>、<code>SREM</code>、<code>SRANDMEMBER</code> 复杂度也是 O(1)。</p><h4 id="范围操作非常耗时"><a href="#范围操作非常耗时" class="headerlink" title="范围操作非常耗时"></a>范围操作非常耗时</h4><p>范围操作，是指集合类型中的遍历操作，可以返回集合中的所有数据，比如 <code>Hash</code> 类型的 <code>HGETALL</code> 和 <code>Set</code> 类型的 <code>SMEMBERS</code>，或者返回一个范围内的部分数据，比如 <code>List</code> 类型的 <code>LRANGE</code> 和 <code>ZSet</code> 类型的 <code>ZRANGE</code>。这类操作的复杂度一般是 O(N)，比较耗时，我们应该尽量避免。</p><p>不过，Redis 从 2.8 版本开始提供了 <code>SCAN</code> 系列操作（包括 <code>HSCAN</code>，<code>SSCAN</code> 和 <code>ZSCAN</code>），这类操作实现了<strong>渐进式遍历</strong>，每次只返回有限数量的数据。这样一来，相比于 <code>HGETALL</code>、<code>SMEMBERS</code> 这类操作来说，就避免了一次性返回所有元素而导致的 Redis 阻塞。</p><h4 id="统计操作通常高效"><a href="#统计操作通常高效" class="headerlink" title="统计操作通常高效"></a>统计操作通常高效</h4><p><strong>集合类型对集合中所有元素个数的记录，例如 <code>LLEN</code> 和 <code>SCARD</code></strong></p><h4 id="例外情况只有几个"><a href="#例外情况只有几个" class="headerlink" title="例外情况只有几个"></a>例外情况只有几个</h4><p>例外情况，是指某些数据结构的特殊记录，例如压缩列表和双向链表都会记录表头和表尾的偏移量。这样一来，对于 List 类型的 <code>LPOP</code>、<code>RPOP</code>、<code>LPUSH</code>、<code>RPUSH</code> 这四个操作来说，它们是在列表的头尾增删元素，这就可以通过偏移量直接定位，所以它们的复杂度也只有 O(1)，可以实现快速操作。</p>]]></content>
    
    
    <summary type="html">快速的Redis有哪些慢操作？</summary>
    
    
    
    <category term="极客时间Redis实战" scheme="http://universeinheart.github.io/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4Redis%E5%AE%9E%E6%88%98/"/>
    
    
    <category term="Redis" scheme="http://universeinheart.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>CAP定理</title>
    <link href="http://universeinheart.github.io/2021/04/05/%E5%88%86%E5%B8%83%E5%BC%8F/CAP/"/>
    <id>http://universeinheart.github.io/2021/04/05/%E5%88%86%E5%B8%83%E5%BC%8F/CAP/</id>
    <published>2021-04-05T09:52:56.000Z</published>
    <updated>2021-04-05T10:04:03.478Z</updated>
    
    <content type="html"><![CDATA[<p>分布式系统的最大难点，就是各个节点的状态如何同步。</p><p>CAP 定理是这方面的基本定理，也是理解分布式系统的起点。</p><h2 id="一、分布式系统的三个指标"><a href="#一、分布式系统的三个指标" class="headerlink" title="一、分布式系统的三个指标"></a>一、分布式系统的三个指标</h2><img src="/2021/04/05/%E5%88%86%E5%B8%83%E5%BC%8F/CAP/image-20210405175903359.png" class="" title="image-20210405175903359"><blockquote><ul><li>Consistency  一致性</li><li>Availability  可用性</li><li>Partition tolerance  分区容错</li></ul><p>这三个指标不可能同时做到。这个结论就叫做 CAP 定理。</p></blockquote><h2 id="二、Partition-tolerance"><a href="#二、Partition-tolerance" class="headerlink" title="二、Partition tolerance"></a>二、Partition tolerance</h2><p>大多数分布式系统都分布在多个子网络。每个子网络就叫做一个区（partition）。分区容错的意思是，区间通信可能失败。比如，一台服务器放在中国，另一台服务器放在美国，这就是两个区，它们之间可能无法通信。</p><img src="/2021/04/05/%E5%88%86%E5%B8%83%E5%BC%8F/CAP/image-20210405175847147.png" class="" title="image-20210405175847147"><p>上图中，G1 和 G2 是两台跨区的服务器。G1 向 G2 发送一条消息，G2 可能无法收到。系统设计的时候，必须考虑到这种情况。</p><p>一般来说，分区容错无法避免，因此可以认为 CAP 的 P 总是成立。CAP 定理告诉我们，剩下的 C 和 A 无法同时做到。</p><h2 id="三、Consistency"><a href="#三、Consistency" class="headerlink" title="三、Consistency"></a>三、Consistency</h2><p>举例来说，某条记录是 v0，用户向 G1 发起一个写操作，将其改为 v1。</p><img src="/2021/04/05/%E5%88%86%E5%B8%83%E5%BC%8F/CAP/image-20210405175832086.png" class="" title="image-20210405175832086"><p>接下来，用户的读操作就会得到 v1。这就叫一致性。</p><img src="/2021/04/05/%E5%88%86%E5%B8%83%E5%BC%8F/CAP/image-20210405175948520.png" class="" title="image-20210405175948520"><p>问题是，用户有可能向 G2 发起读操作，由于 G2 的值没有发生变化，因此返回的是 v0。G1 和 G2 读操作的结果不一致，这就不满足一致性了。</p><img src="/2021/04/05/%E5%88%86%E5%B8%83%E5%BC%8F/CAP/image-20210405180011013.png" class="" title="image-20210405180011013"><p>为了让 G2 也能变为 v1，就要在 G1 写操作的时候，让 G1 向 G2 发送一条消息，要求 G2 也改成 v1。</p><img src="/2021/04/05/%E5%88%86%E5%B8%83%E5%BC%8F/CAP/image-20210405180026995.png" class="" title="image-20210405180026995"><p>这样的话，用户向 G2 发起读操作，也能得到 v1。</p><img src="/2021/04/05/%E5%88%86%E5%B8%83%E5%BC%8F/CAP/image-20210405180038257.png" class="" title="image-20210405180038257"><h2 id="四、Availability"><a href="#四、Availability" class="headerlink" title="四、Availability"></a>四、Availability</h2><p>用户可以选择向 G1 或 G2 发起读操作。不管是哪台服务器，只要收到请求，就必须告诉用户，到底是 v0 还是 v1，否则就不满足可用性。</p><h2 id="五、Consistency-和-Availability-的矛盾"><a href="#五、Consistency-和-Availability-的矛盾" class="headerlink" title="五、Consistency 和 Availability 的矛盾"></a>五、Consistency 和 Availability 的矛盾</h2><p>一致性和可用性，为什么不可能同时成立？答案很简单，因为可能通信失败（即出现分区容错）。</p><p>如果保证 G2 的一致性，那么 G1 必须在写操作时，锁定 G2 的读操作和写操作。只有数据同步后，才能重新开放读写。锁定期间，G2 不能读写，没有可用性不。</p><p>如果保证 G2 的可用性，那么势必不能锁定 G2，所以一致性不成立。</p><p>综上所述，G2 无法同时做到一致性和可用性。系统设计时只能选择一个目标。如果追求一致性，那么无法保证所有节点的可用性；如果追求所有节点的可用性，那就没法做到一致性。</p><blockquote><p><strong>读者问，在什么场合，可用性高于一致性？</strong></p><p>举例来说，发布一张网页到 CDN，多个服务器有这张网页的副本。后来发现一个错误，需要更新网页，这时只能每个服务器都更新一遍。</p><p>一般来说，网页的更新不是特别强调一致性。短时期内，一些用户拿到老版本，另一些用户拿到新版本，问题不会特别大。当然，所有人最终都会看到新版本。所以，这个场合就是可用性高于一致性。</p></blockquote><p>原文：<a href="http://www.ruanyifeng.com/blog/2018/07/cap.html">http://www.ruanyifeng.com/blog/2018/07/cap.html</a></p>]]></content>
    
    
    <summary type="html">分布式系统的CAP定理</summary>
    
    
    
    <category term="分布式" scheme="http://universeinheart.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="CAP" scheme="http://universeinheart.github.io/tags/CAP/"/>
    
    <category term="分布式" scheme="http://universeinheart.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
</feed>
