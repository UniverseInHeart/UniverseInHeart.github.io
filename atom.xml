<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>HelloWorld</title>
  
  
  <link href="http://universeinheart.github.io/atom.xml" rel="self"/>
  
  <link href="http://universeinheart.github.io/"/>
  <updated>2021-04-15T00:38:46.122Z</updated>
  <id>http://universeinheart.github.io/</id>
  
  <author>
    <name>xjf</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>08、Redis 哨兵集群</title>
    <link href="http://universeinheart.github.io/2021/04/15/Redis/08/"/>
    <id>http://universeinheart.github.io/2021/04/15/Redis/08/</id>
    <published>2021-04-15T00:00:00.000Z</published>
    <updated>2021-04-15T00:38:46.122Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基于-pub-sub-机制的哨兵集群组成"><a href="#基于-pub-sub-机制的哨兵集群组成" class="headerlink" title="基于 pub/sub 机制的哨兵集群组成"></a>基于 pub/sub 机制的哨兵集群组成</h2><p>哨兵实例之间可以相互发现，要归功于 <strong>Redis 提供的 pub/sub 机制</strong>，也就是 <strong>发布 / 订阅机制</strong></p><p>哨兵只要和主库建立起了连接，就可以在主库上发布消息了，比如说发布它自己的<strong>连接信息</strong>（IP 和端口）。同时，它也可以从主库上订阅消息，获得<strong>其他哨兵发布的连接信息</strong>。当多个哨兵实例都在主库上做了发布和订阅操作后，它们之间就能知道彼此的 IP 地址和端口。</p><p>为了区分不同应用的消息，Redis 会以<strong>频道</strong>的形式，对这些消息进行分门别类的管理。只有订阅了同一个频道的应用，才能通过发布的消息进行信息交换。</p><blockquote><p>在主从集群中，主库上有一个名为**_ _ sentinel _ _:hello**的频道，不同哨兵就是通过它来相互发现，实现互相通信的。</p></blockquote><img src="/2021/04/15/Redis/08/image-20210116154316161.png" class="" title="image-20210116154316161"><h2 id="基于-pub-sub-机制的客户端事件通知"><a href="#基于-pub-sub-机制的客户端事件通知" class="headerlink" title="基于 pub/sub 机制的客户端事件通知"></a>基于 pub/sub 机制的客户端事件通知</h2><p>客户端可以从哨兵订阅消息。哨兵提供的消息订阅频道有很多，不同频道包含了主从库切换过程中的不同关键事件。</p><img src="/2021/04/15/Redis/08/image-20210116154651991.png" class="" title="image-20210116154651991"><p>客户端读取哨兵的配置文件后，可以获得哨兵的地址和端口，和哨兵建立网络连接。然后，我们可以在客户端执行 <strong>订阅命令</strong>，来获取不同的事件消息。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;订阅“所有实例进入客观下线状态的事件”</span><br><span class="line">SUBSCRIBE +odown</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;订阅所有的事件</span><br><span class="line">PSUBSCRIBE  *</span><br></pre></td></tr></table></figure><p>当哨兵把新主库选择出来后，客户端就会看到下面的 <code>switch-master</code> 事件。这个事件表示主库已经切换了，新主库的 IP 地址和端口信息已经有了。这个时候，客户端就可以用这里面的新主库地址和端口进行通信了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">switch-master &lt;master name&gt; &lt;oldip&gt; &lt;oldport&gt; &lt;newip&gt; &lt;newport&gt;</span><br></pre></td></tr></table></figure><p>有了这些事件通知，客户端不仅可以在主从切换后得到新主库的连接信息，还可以监控到主从库切换过程中发生的各个重要事件。这样，客户端就可以知道主从切换进行到哪一步了，有助于了解切换进度。</p><h2 id="由哪个哨兵执行主从切换？"><a href="#由哪个哨兵执行主从切换？" class="headerlink" title="由哪个哨兵执行主从切换？"></a>由哪个哨兵执行主从切换？</h2><h3 id="投票下线"><a href="#投票下线" class="headerlink" title="投票下线"></a>投票下线</h3><p>任何一个实例只要自身判断主库“主观下线”后，就会给其他实例发送 <code>is-master-down-by-addr</code> 命令。接着，其他实例会根据自己和主库的连接情况，做出 Y 或 N 的响应，Y 相当于赞成票，N 相当于反对票。</p><img src="/2021/04/15/Redis/08/image-20210116155725926.png" class="" title="image-20210116155725926"><p>一个哨兵获得了仲裁所需的赞成票数后，就可以标记主库为“客观下线”。这个所需的赞成票数是通过哨兵配置文件中的 <code>quorum</code> 配置项设定的。例如，现在有 5 个哨兵，<code>quorum</code> 配置的是 3，那么，一个哨兵需要 3  张赞成票，就可以标记主库为“客观下线”了。这 3 张赞成票包括哨兵自己的一张赞成票和另外两个哨兵的赞成票。</p><h3 id="投票确认Leader"><a href="#投票确认Leader" class="headerlink" title="投票确认Leader"></a>投票确认Leader</h3><p>这个哨兵就可以再给其他哨兵发送命令，表明希望由自己来执行主从切换，并让所有其他哨兵进行投票。这个投票过程称为“<strong>Leader 选举</strong>”。因为最终执行主从切换的哨兵称为 Leader，投票过程就是确定 Leader。</p><p>任何一个想成为 Leader  的哨兵，要满足两个条件：第一，拿到半数以上的赞成票；第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。以 3  个哨兵为例，假设此时的 quorum 设置为 2，那么，任何一个想成为 Leader 的哨兵只要拿到 2 张赞成票，就可以了。</p><img src="/2021/04/15/Redis/08/image-20210116160103639.png" class="" title="image-20210116160103639"><p>如果 S3 没有拿到 2 票  Y，那么这轮投票就不会产生 Leader。哨兵集群会等待一段时间（也就是哨兵故障转移超时时间的 2  倍），再重新选举。这是因为，哨兵集群能够进行成功投票，很大程度上依赖于选举命令的正常<strong>网络传播</strong>。如果网络压力较大或有短时堵塞，就可能导致没有一个哨兵能拿到半数以上的赞成票。所以，等到网络拥塞好转之后，再进行投票选举，成功的概率就会增加。</p><p>需要注意的是，如果哨兵集群只有 2 个实例，此时，一个哨兵要想成为 Leader，必须获得 2 票，而不是 1  票。所以，如果有个哨兵挂掉了，那么，此时的集群是无法进行主从库切换的。因此，通常我们<strong>至少会配置 3  个哨兵实例</strong>。这一点很重要，你在实际应用时可不能忽略了。</p>]]></content>
    
    
    <summary type="html">哨兵挂了，主从库还能切换么？</summary>
    
    
    
    <category term="极客时间Redis实战" scheme="http://universeinheart.github.io/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4Redis%E5%AE%9E%E6%88%98/"/>
    
    
    <category term="Redis" scheme="http://universeinheart.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>07、Redis 哨兵机制</title>
    <link href="http://universeinheart.github.io/2021/04/14/Redis/07/"/>
    <id>http://universeinheart.github.io/2021/04/14/Redis/07/</id>
    <published>2021-04-14T00:00:00.000Z</published>
    <updated>2021-04-14T00:30:25.354Z</updated>
    
    <content type="html"><![CDATA[<h2 id="哨兵机制的基本流程"><a href="#哨兵机制的基本流程" class="headerlink" title="哨兵机制的基本流程"></a>哨兵机制的基本流程</h2><p>哨兵其实就是一个运行在特殊模式下的 Redis 进程，主从库实例运行的同时，它也在运行。</p><p>哨兵主要负责的就是三个任务：<strong>监控</strong>、<strong>选主</strong> 和<strong>通知</strong>。</p><h3 id="监控"><a href="#监控" class="headerlink" title="监控"></a>监控</h3><p>监控是指哨兵进程在运行时，周期性地给所有的主从库发送 <code>PING</code> 命令，检测它们是否仍然在线运行。</p><p>如果<strong>从库</strong>没有在规定时间内响应哨兵的 <code>PING</code>  命令，哨兵就会把它标记为“下线状态”；</p><p>如果<strong>主库</strong>也没有在规定时间内响应哨兵的 <code>PING</code>  命令，哨兵就会判定主库下线，然后开始自动切换主库的流程。</p><blockquote><p><strong>哨兵如何判断主库是否处于下线状态?</strong></p><p>哨兵进程会使用 PING 命令检测它自己和主、从库的网络连接情况，用来判断实例的状态。如果哨兵发现主库或从库对 PING 命令的响应超时了，那么，哨兵就会先把它标记为“<strong>主观下线</strong>”。</p><p>如果检测的是从库，那么，哨兵简单地把它标记为“主观下线”就行了，因为从库的下线影响一般不太大，集群的对外服务不会间断。但是，如果检测的是主库，那么，哨兵还不能简单地把它标记为“主观下线”，开启主从切换。</p><p>因为很有可能存在这么一个情况：那就是哨兵误判了，其实主库并没有故障。要特别注意误判的情况，因为，一旦启动了主从切换，后续的选主和通知操作都会带来额外的计算和通信开销。</p><p>误判一般会发生在集群网络压力较大、网络拥塞，或者是主库本身压力较大的情况下。</p><p>哨兵机制也是类似的，它通常会采用 <strong>多实例组成的集群模式</strong> 进行部署，这也被称为哨兵集群。引入多个哨兵实例一起来判断，就可以避免单个哨兵因为自身网络状况不好，而误判主库下线的情况。同时，多个哨兵的网络同时不稳定的概率较小，由它们一起做决策，误判率也能降低。</p></blockquote><img src="/2021/04/14/Redis/07/image-20210115234805846.png" class="" title="image-20210115234805846"><p>当有 N 个哨兵实例时，最好要有 <strong>N/2 + 1</strong> 个实例判断主库为“<strong>主观下线</strong>”，才能最终判定主库为“<strong>客观下线</strong>”</p><h3 id="选主"><a href="#选主" class="headerlink" title="选主"></a>选主</h3><p>主库挂了以后，哨兵就需要从很多个从库里，按照一定的规则选择一个从库实例，把它作为新的主库。这一步完成后，现在的集群里就有了新主库。</p><blockquote><p><strong>哨兵如何决定选择哪个从库实例作为主库？</strong></p><p>多个从库中，先按照一定的筛选条件，把不符合条件的从库去掉。然后，我们再按照一定的规则，给剩下的从库逐个打分，将得分最高的从库选为新主库</p><img src="/2021/04/14/Redis/07/image-20210115235007844.png" class="" title="image-20210115235007844"><p>第一轮：优先级最高的从库得分高(<code>slave-priority</code> 配置项)</p><p>第二轮：和旧主库同步程度最接近的从库得分高。( <code>slave_repl_offset</code> 最接近 <code>master_repl_offset</code>)</p><p>第三轮：ID 号小的从库得分高。</p></blockquote><h3 id="通知"><a href="#通知" class="headerlink" title="通知"></a>通知</h3><p>在执行通知任务时，哨兵会把新主库的连接信息发给其他从库，让它们执行 <code>replicaof</code> 命令，和新主库建立连接，并进行数据复制。同时，哨兵会把新主库的连接信息通知给客户端，让它们把请求操作发到新主库上。</p><img src="/2021/04/14/Redis/07/image-20210115233901510.png" class="" title="image-20210115233901510">]]></content>
    
    
    <summary type="html">主库挂了，如何不间断服务？</summary>
    
    
    
    <category term="极客时间Redis实战" scheme="http://universeinheart.github.io/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4Redis%E5%AE%9E%E6%88%98/"/>
    
    
    <category term="Redis" scheme="http://universeinheart.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>06、Redis 数据同步</title>
    <link href="http://universeinheart.github.io/2021/04/14/Redis/06/"/>
    <id>http://universeinheart.github.io/2021/04/14/Redis/06/</id>
    <published>2021-04-13T16:08:15.000Z</published>
    <updated>2021-04-14T00:03:58.323Z</updated>
    
    <content type="html"><![CDATA[<p>Redis 提供了主从库模式，以保证数据副本的一致，主从库之间采用的是读写分离的方式。</p><ul><li>读操作：主库、从库都可以接收；</li><li>写操作：首先到主库执行，然后，主库将写操作同步给从库。</li></ul><img src="/2021/04/14/Redis/06/image-20210114224608756.png" class="" title="image-20210114224608756"><h3 id="主从库间如何进行第一次同步？"><a href="#主从库间如何进行第一次同步？" class="headerlink" title="主从库间如何进行第一次同步？"></a>主从库间如何进行第一次同步？</h3><p>通过 <code>replicaof</code>（Redis 5.0 之前使用 <code>slaveof</code>）命令形成主库和从库的关系</p><img src="/2021/04/14/Redis/06/image-20210114224736883.png" class="" title="image-20210114224736883"><p><strong>第一阶段：建立连接，协商同步</strong></p><p>从库给主库发送 <code>psync</code> 命令，表示要进行数据同步，主库根据这个命令的参数来启动复制。</p><p><code>psync</code> 命令包含了 <strong>主库的 <code>runID</code></strong> 和 <strong>复制进度 <code>offset</code></strong> 两个参数。</p><ul><li><code>runID</code>，是每个 Redis 实例启动时都会自动生成的一个随机 ID，用来唯一标记这个实例。当从库和主库第一次复制时，因为不知道主库的 runID，所以将 runID 设为“？”</li><li><code>offset</code>，此时设为 -1，表示第一次复制。</li></ul><p>主库收到 <code>psync</code> 命令后，会用 <code>FULLRESYNC</code> 响应命令带上两个参数：<strong>主库 runID</strong> 和 <strong>主库目前的复制进度 offset</strong>，返回给从库。从库收到响应后，会记录下这两个参数。这里有个地方需要注意，**<code>FULLRESYNC</code> 响应表示第一次复制采用的全量复制，也就是说，主库会把当前所有的数据都复制给从库**</p><p><strong>第二阶段，主库将所有数据同步给从库。从库收到数据后，在本地完成数据加载。</strong></p><p>具体来说，主库执行 <code>bgsave</code> 命令，生成 RDB 文件，接着将文件发给从库。从库接收到 RDB 文件后，会先 <strong>清空当前数据库</strong>，然后加载 RDB 文件。这是因为从库在通过 replicaof 命令开始和主库同步前，可能保存了其他数据。为了避免之前数据的影响，从库需要先把当前数据库清空。</p><p>在主库将数据同步给从库的过程中，主库不会被阻塞，但是，这些请求中的写操作并没有记录到刚刚生成的 RDB 文件中。为了保证主从库的数据一致性，主库会在内存中用专门的 <code>replication buffer</code>，<strong>记录 RDB 文件生成后收到的所有写操作</strong>。</p><p><strong>第三个阶段，主库会把第二阶段执行过程中新收到的写命令，再发送给从库。</strong></p><p>具体的操作是，当主库完成 RDB 文件发送后，就会把此时 <code>replication buffer</code> 中的修改操作发给从库，从库再重新执行这些操作。这样一来，主从库就实现同步了。</p><h3 id="主从级联模式分担全量复制时的主库压力"><a href="#主从级联模式分担全量复制时的主库压力" class="headerlink" title="主从级联模式分担全量复制时的主库压力"></a>主从级联模式分担全量复制时的主库压力</h3><p>通过“主 - 从 - 从”模式将主库生成 RDB 和传输 RDB 的压力，以级联的方式分散到从库上。</p><img src="/2021/04/14/Redis/06/image-20210114225744977.png" class="" title="image-20210114225744977"><p>一旦主从库完成了全量复制，它们之间就会一直维护一个网络连接，主库会通过这个连接将后续陆续收到的命令操作再同步给从库，这个过程也称为<strong>基于长连接的命令传播</strong>，可以避免频繁建立连接的开销。</p><h3 id="主从库间网络断了怎么办？"><a href="#主从库间网络断了怎么办？" class="headerlink" title="主从库间网络断了怎么办？"></a>主从库间网络断了怎么办？</h3><p>在 Redis 2.8 之前，如果主从库在命令传播时出现了网络闪断，那么，从库就会和主库重新进行一次全量复制，开销非常大。</p><p>从 Redis 2.8 开始，网络断了之后，主从库会采用 <strong>增量复制</strong> 的方式继续同步。全量复制是同步所有数据，而增量复制只会把主从库网络断连期间主库收到的命令，同步给从库。</p><blockquote><p> 增量复制时，主从库之间具体是怎么保持同步的呢？</p><p> <strong>repl_backlog_buffer 缓冲区</strong></p><p> 当主从库断连后，主库会把断连期间收到的写操作命令，写入 <code>replication buffer</code>，同时也会把这些操作命令也写入 <code>repl_backlog_buffer</code>  这个缓冲区。</p><p> <code>repl_backlog_buffer</code> 是一个环形缓冲区，主库会记录自己写到的位置，从库则会记录自己已经读到的位置。</p><p> 刚开始的时候，主库和从库的写读位置在一起，这算是它们的起始位置。随着主库不断接收新的写操作，它在缓冲区中的写位置会逐步偏离起始位置，我们通常用偏移量来衡量这个偏移距离的大小，对主库来说，对应的偏移量就是  <code>master_repl_offset</code>。主库接收的新写操作越多，这个值就会越大。同样，从库在复制完写操作命令后，它在缓冲区中的读位置也开始逐步偏移刚才的起始位置，此时，从库已复制的偏移量 slave_repl_offset 也在不断增加。正常情况下，这两个偏移量基本相等。</p></blockquote><img src="/2021/04/14/Redis/06/image-20210115232735345.png" class="" title="image-20210115232735345"><blockquote><p>主从库的连接恢复之后，从库首先会给主库发送  <code>psync</code> 命令，并把自己当前的 <code>slave_repl_offset</code> 发给主库，主库会判断自己的 <code>master_repl_offset</code> 和  <code>slave_repl_offset</code>  之间的差距。</p><p>在网络断连阶段，主库可能会收到新的写操作命令，所以，一般来说，<code>master_repl_offset</code> 会大于  <code>slave_repl_offset</code>。此时，主库只用把 <code>master_repl_offset</code> 和 <code>slave_repl_offset</code>  之间的命令操作同步给从库就行。就像刚刚示意图的中间部分，主库和从库之间相差了 put d e 和 put d f  两个操作，在增量复制时，主库只需要把它们同步给从库，就行了。</p></blockquote><img src="/2021/04/14/Redis/06/image-20210115232858938.png" class="" title="image-20210115232858938"><p>因为 <code>repl_backlog_buffer</code> 是一个 <strong>环形缓冲区</strong>，所以在缓冲区写满后，主库会继续写入，此时，就会覆盖掉之前写入的操作。<strong>如果从库的读取速度比较慢，就有可能导致从库还未读取的操作被主库新写的操作覆盖了，这会导致主从库间的数据不一致</strong>。可以调整 <code>repl_backlog_size</code>  这个参数。这个参数和所需的缓冲空间大小有关。</p><p>缓冲空间的计算公式是：缓冲空间大小 = 主库写入命令速度 * 操作大小 - 主从库间网络传输命令速度 * 操作大小。</p><p>在实际应用中，考虑到可能存在一些突发的请求压力，我们通常需要把这个缓冲空间扩大一到两倍</p>]]></content>
    
    
    <summary type="html">主从库如何实现数据一致</summary>
    
    
    
    <category term="极客时间Redis实战" scheme="http://universeinheart.github.io/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4Redis%E5%AE%9E%E6%88%98/"/>
    
    
    <category term="Redis" scheme="http://universeinheart.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>06、Redis</title>
    <link href="http://universeinheart.github.io/2021/04/14/Redis/09/"/>
    <id>http://universeinheart.github.io/2021/04/14/Redis/09/</id>
    <published>2021-04-13T16:00:00.000Z</published>
    <updated>2021-04-14T00:31:40.759Z</updated>
    
    
    
    
    <category term="极客时间Redis实战" scheme="http://universeinheart.github.io/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4Redis%E5%AE%9E%E6%88%98/"/>
    
    
    <category term="Redis" scheme="http://universeinheart.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>06、Redis</title>
    <link href="http://universeinheart.github.io/2021/04/14/Redis/10/"/>
    <id>http://universeinheart.github.io/2021/04/14/Redis/10/</id>
    <published>2021-04-13T16:00:00.000Z</published>
    <updated>2021-04-14T00:31:43.128Z</updated>
    
    
    
    
    <category term="极客时间Redis实战" scheme="http://universeinheart.github.io/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4Redis%E5%AE%9E%E6%88%98/"/>
    
    
    <category term="Redis" scheme="http://universeinheart.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>06、Redis</title>
    <link href="http://universeinheart.github.io/2021/04/14/Redis/11/"/>
    <id>http://universeinheart.github.io/2021/04/14/Redis/11/</id>
    <published>2021-04-13T16:00:00.000Z</published>
    <updated>2021-04-14T00:31:45.901Z</updated>
    
    
    
    
    <category term="极客时间Redis实战" scheme="http://universeinheart.github.io/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4Redis%E5%AE%9E%E6%88%98/"/>
    
    
    <category term="Redis" scheme="http://universeinheart.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>06、Redis</title>
    <link href="http://universeinheart.github.io/2021/04/14/Redis/12/"/>
    <id>http://universeinheart.github.io/2021/04/14/Redis/12/</id>
    <published>2021-04-13T16:00:00.000Z</published>
    <updated>2021-04-14T00:31:49.383Z</updated>
    
    
    
    
    <category term="极客时间Redis实战" scheme="http://universeinheart.github.io/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4Redis%E5%AE%9E%E6%88%98/"/>
    
    
    <category term="Redis" scheme="http://universeinheart.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>06、Redis</title>
    <link href="http://universeinheart.github.io/2021/04/14/Redis/13/"/>
    <id>http://universeinheart.github.io/2021/04/14/Redis/13/</id>
    <published>2021-04-13T16:00:00.000Z</published>
    <updated>2021-04-14T00:31:55.967Z</updated>
    
    
    
    
    <category term="极客时间Redis实战" scheme="http://universeinheart.github.io/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4Redis%E5%AE%9E%E6%88%98/"/>
    
    
    <category term="Redis" scheme="http://universeinheart.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>名句</title>
    <link href="http://universeinheart.github.io/2021/04/13/%E5%B0%8F%E5%86%8C%E5%AD%90/%E5%90%8D%E5%8F%A5/"/>
    <id>http://universeinheart.github.io/2021/04/13/%E5%B0%8F%E5%86%8C%E5%AD%90/%E5%90%8D%E5%8F%A5/</id>
    <published>2021-04-13T15:26:37.000Z</published>
    <updated>2021-04-13T15:40:07.184Z</updated>
    
    <content type="html"><![CDATA[<h3 id="爱比克泰德：古罗马哲学家"><a href="#爱比克泰德：古罗马哲学家" class="headerlink" title="爱比克泰德：古罗马哲学家"></a>爱比克泰德：古罗马哲学家</h3><ol><li>只有受过教育的人才是自由的。</li><li>我们登上并非我们所选择的舞台,演绎并非我们所选择的剧本。</li><li>连自己的命运都不能主宰的人是没有自由可以享受的</li></ol><h3 id="艾森豪威尔的母亲"><a href="#艾森豪威尔的母亲" class="headerlink" title="艾森豪威尔的母亲"></a>艾森豪威尔的母亲</h3><ol><li>人生犹如打牌，牌是上帝发的，不管是好是坏，你都别无选择，唯一可以选择做的，就是调整好自己的心态，让浮躁的心平静下来，认真对待每一张牌，力争最好效果。只有这样的人生高度才是有意义的</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;爱比克泰德：古罗马哲学家&quot;&gt;&lt;a href=&quot;#爱比克泰德：古罗马哲学家&quot; class=&quot;headerlink&quot; title=&quot;爱比克泰德：古罗马哲学家&quot;&gt;&lt;/a&gt;爱比克泰德：古罗马哲学家&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;只有受过教育的人才是自由的。&lt;/li&gt;
&lt;li&gt;</summary>
      
    
    
    
    <category term="杂记" scheme="http://universeinheart.github.io/categories/%E6%9D%82%E8%AE%B0/"/>
    
    
    <category term="杂记" scheme="http://universeinheart.github.io/tags/%E6%9D%82%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>复利</title>
    <link href="http://universeinheart.github.io/2021/04/13/%E5%B0%8F%E5%86%8C%E5%AD%90/%E5%A4%8D%E5%88%A9/"/>
    <id>http://universeinheart.github.io/2021/04/13/%E5%B0%8F%E5%86%8C%E5%AD%90/%E5%A4%8D%E5%88%A9/</id>
    <published>2021-04-13T15:26:37.000Z</published>
    <updated>2021-04-13T15:41:40.789Z</updated>
    
    <content type="html"><![CDATA[<p>自然对数的底 e=2.718281828459045</p><p>复利： F = P(1+i)^n</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;自然对数的底 e=2.718281828459045&lt;/p&gt;
&lt;p&gt;复利： F = P(1+i)^n&lt;/p&gt;
</summary>
      
    
    
    
    <category term="杂记" scheme="http://universeinheart.github.io/categories/%E6%9D%82%E8%AE%B0/"/>
    
    
    <category term="杂记" scheme="http://universeinheart.github.io/tags/%E6%9D%82%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>如何快速阅读</title>
    <link href="http://universeinheart.github.io/2021/04/13/%E5%B0%8F%E5%86%8C%E5%AD%90/%E5%A6%82%E4%BD%95%E5%BF%AB%E9%80%9F%E9%98%85%E8%AF%BB/"/>
    <id>http://universeinheart.github.io/2021/04/13/%E5%B0%8F%E5%86%8C%E5%AD%90/%E5%A6%82%E4%BD%95%E5%BF%AB%E9%80%9F%E9%98%85%E8%AF%BB/</id>
    <published>2021-04-13T15:26:37.000Z</published>
    <updated>2021-04-13T15:40:18.174Z</updated>
    
    <content type="html"><![CDATA[<h2 id=""><a href="#" class="headerlink" title=""></a></h2><p>1、专注</p><p>2、消除干扰</p><p>3、增加视野，在书每页的两侧画垂直线，减少阅读范围</p><p>4、消除回溯，手指</p><p>5、想象，身临其境，可视化</p><p>6、长时间阅读</p><p>7、休息</p><p>8、练习</p><p>9、摘要</p>]]></content>
    
    
    <summary type="html">如何快速阅读</summary>
    
    
    
    <category term="杂记" scheme="http://universeinheart.github.io/categories/%E6%9D%82%E8%AE%B0/"/>
    
    
    <category term="杂记" scheme="http://universeinheart.github.io/tags/%E6%9D%82%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>历史上的经济泡沫</title>
    <link href="http://universeinheart.github.io/2021/04/13/%E5%B0%8F%E5%86%8C%E5%AD%90/%E7%BB%8F%E6%B5%8E%E6%B3%A1%E6%B2%AB/"/>
    <id>http://universeinheart.github.io/2021/04/13/%E5%B0%8F%E5%86%8C%E5%AD%90/%E7%BB%8F%E6%B5%8E%E6%B3%A1%E6%B2%AB/</id>
    <published>2021-04-13T15:26:37.000Z</published>
    <updated>2021-04-13T15:40:02.186Z</updated>
    
    <content type="html"><![CDATA[<h2 id="郁金香狂热"><a href="#郁金香狂热" class="headerlink" title="郁金香狂热"></a>郁金香狂热</h2><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>荷-西战争:政治独立</p><p>东印度公司：经济独立</p><p>中亚—-&gt; 西欧</p><h3 id="发生"><a href="#发生" class="headerlink" title="发生"></a>发生</h3><p>自然生成5-7年，球茎1年</p><p>炒作 1634年</p><p>1634年12月  —&gt;  1637年4月  (期货)</p><p> 奥古斯都 6290荷兰盾 </p><p>长春君子兰</p><p>击鼓传花</p><h2 id="史上最有钱的公司"><a href="#史上最有钱的公司" class="headerlink" title="史上最有钱的公司"></a>史上最有钱的公司</h2><h4 id="荷兰东印度公司-成熟的经济模式"><a href="#荷兰东印度公司-成熟的经济模式" class="headerlink" title="荷兰东印度公司  成熟的经济模式"></a>荷兰东印度公司  成熟的经济模式</h4><p>7.9万亿美金</p><p>香料</p><p>公司建立</p><p>1、相互竞争，风险承受力差</p><p>2、1602年 14家合起来成立荷兰东印度公司</p><p>第一家股份公司，股息，董事会，证券交易</p><h4 id="法国密西西比公司-6-5万亿-泡沫"><a href="#法国密西西比公司-6-5万亿-泡沫" class="headerlink" title="法国密西西比公司  6.5万亿 泡沫"></a>法国密西西比公司  6.5万亿 泡沫</h4><h4 id="英国南海公司-4-33万亿-泡沫"><a href="#英国南海公司-4-33万亿-泡沫" class="headerlink" title="英国南海公司 4.33万亿 泡沫"></a>英国南海公司 4.33万亿 泡沫</h4><p>黑奴贸易</p><h2 id="日本房地产"><a href="#日本房地产" class="headerlink" title="日本房地产"></a>日本房地产</h2><p>美国经济，最大的债权国–&gt; 最大的债务国</p><p>广场协议</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;郁金香狂热&quot;&gt;&lt;a href=&quot;#郁金香狂热&quot; class=&quot;headerlink&quot; title=&quot;郁金香狂热&quot;&gt;&lt;/a&gt;郁金香狂热&lt;/h2&gt;&lt;h3 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背</summary>
      
    
    
    
    <category term="杂记" scheme="http://universeinheart.github.io/categories/%E6%9D%82%E8%AE%B0/"/>
    
    
    <category term="杂记" scheme="http://universeinheart.github.io/tags/%E6%9D%82%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>05、Redis 内存快照</title>
    <link href="http://universeinheart.github.io/2021/04/10/Redis/05/"/>
    <id>http://universeinheart.github.io/2021/04/10/Redis/05/</id>
    <published>2021-04-10T11:57:15.000Z</published>
    <updated>2021-04-10T12:17:57.841Z</updated>
    
    <content type="html"><![CDATA[<p><strong>内存快照</strong>，就是指内存中的数据在某一个时刻的状态记录。这就类似于照片，当你给朋友拍照时，一张照片就能把朋友一瞬间的形象完全记下来。</p><p>和 AOF 相比，RDB 记录的是某一时刻的数据，并不是操作，所以，在做数据恢复时，我们可以直接把 RDB 文件读入内存，很快地完成恢复</p><h3 id="对哪些数据做快照？-快照的执行效率问题"><a href="#对哪些数据做快照？-快照的执行效率问题" class="headerlink" title="对哪些数据做快照？(快照的执行效率问题?)"></a>对哪些数据做快照？(快照的执行效率问题?)</h3><p> Redis 的数据都在内存中，为了提供所有数据的可靠性保证，它执行的是全量快照</p><p> Redis 提供了两个命令来生成 RDB 文件，分别是 <code>save</code> 和 <code>bgsave</code>。</p><ul><li>save：在主线程中执行，会导致阻塞</li><li>bgsave：创建一个子进程，专门用于写入 RDB 文件，避免了主线程的阻塞，这也是 Redis RDB 文件生成的默认配置</li></ul><h3 id="做快照时，数据还能被增删改吗？-Redis-是否被阻塞，能否同时正常处理请求"><a href="#做快照时，数据还能被增删改吗？-Redis-是否被阻塞，能否同时正常处理请求" class="headerlink" title="做快照时，数据还能被增删改吗？( Redis 是否被阻塞，能否同时正常处理请求?)"></a>做快照时，数据还能被增删改吗？( Redis 是否被阻塞，能否同时正常处理请求?)</h3><p> 为了快照而暂停写操作，肯定是不能接受的。Redis 就会借助操作系统提供的 <strong>写时复制技术（Copy-On-Write, COW）</strong>，在执行快照的同时，正常处理写操作。</p><p> bgsave 子进程是由主线程 fork 生成的，可以共享主线程的所有内存数据。bgsave 子进程运行后，开始读取主线程的内存数据，并把它们写入 RDB 文件。</p><p>如果主线程对这些数据也都是读操作（例如图中的键值对 A），那么，主线程和 bgsave 子进程相互不影响。但是，如果主线程要修改一块数据（例如图中的键值对 C），那么，这块数据就会被复制一份，生成该数据的副本。然后，<code>bgsave</code> 子进程会把这个副本数据写入 RDB 文件，而在这个过程中，主线程仍然可以直接修改原来的数据。</p><img src="/2021/04/10/Redis/05/image-20210114000648827.png" class="" title="image-20210114000648827"><p>虽然 bgsave 执行时不阻塞主线程，但是，如果频繁地执行全量快照，也会带来两方面的开销。</p><p>一方面，频繁将全量数据写入磁盘，会给磁盘带来很大压力，多个快照竞争有限的磁盘带宽，前一个快照还没有做完，后一个又开始做了，容易造成恶性循环。</p><p>另一方面，bgsave 子进程需要通过 fork 操作从主线程创建出来。虽然，子进程在创建后不会再阻塞主线程，但是，fork 这个创建过程本身会阻塞主线程，而且主线程的内存越大，阻塞时间越长。如果频繁 fork 出 bgsave 子进程，这就会频繁阻塞主线程了。</p><h3 id="增量快照"><a href="#增量快照" class="headerlink" title="增量快照"></a>增量快照</h3><p>增量快照，就是指，做了一次全量快照后，后续的快照只对修改的数据进行快照记录，这样可以避免每次全量快照的开销。但是需要我们使用额外的元数据信息去记录哪些数据被修改了，这会带来额外的空间开销问题</p><img src="/2021/04/10/Redis/05/image-20210114224110088.png" class="" title="image-20210114224110088"><h3 id="混合使用-AOF-日志和内存快照"><a href="#混合使用-AOF-日志和内存快照" class="headerlink" title="混合使用 AOF 日志和内存快照"></a>混合使用 AOF 日志和内存快照</h3><p>内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。</p><p>这样一来，快照不用很频繁地执行，这就避免了频繁 fork 对主线程的影响。而且，AOF 日志也只用记录两次快照间的操作，也就是说，不需要记录所有操作了，因此，就不会出现文件过大的情况了，也可以避免重写开销。</p><p>如下图所示，T1 和 T2 时刻的修改，用 AOF 日志记录，等到第二次做全量快照时，就可以清空 AOF 日志，因为此时的修改都已经记录到快照中了，恢复时就不再用日志了</p><img src="/2021/04/10/Redis/05/image-20210114224334522.png" class="" title="image-20210114224334522">]]></content>
    
    
    <summary type="html">宕机后，Redis如何实现快速恢复</summary>
    
    
    
    <category term="极客时间Redis实战" scheme="http://universeinheart.github.io/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4Redis%E5%AE%9E%E6%88%98/"/>
    
    
    <category term="Redis" scheme="http://universeinheart.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>03、Redis 高性能IO模型</title>
    <link href="http://universeinheart.github.io/2021/04/10/Redis/03/"/>
    <id>http://universeinheart.github.io/2021/04/10/Redis/03/</id>
    <published>2021-04-10T11:50:15.000Z</published>
    <updated>2021-04-10T12:17:46.226Z</updated>
    
    <content type="html"><![CDATA[<p>Redis 是单线程，主要是指 Redis 的 <strong>网络 IO</strong> 和 <strong>键值对读写</strong> 是由一个线程来完成的，这也是 Redis 对外提供键值存储服务的主要流程。但 Redis 的其他功能，比如持久化、异步删除、集群数据同步等，其实是由额外的线程执行的。</p><h2 id="Redis-为什么用单线程？-避免了多线程的开销"><a href="#Redis-为什么用单线程？-避免了多线程的开销" class="headerlink" title="Redis 为什么用单线程？(避免了多线程的开销)"></a>Redis 为什么用单线程？(避免了多线程的开销)</h2><p>多线程编程模式面临的<strong>共享资源的并发访问控制问题</strong></p><h2 id="单线程-Redis-为什么那么快？"><a href="#单线程-Redis-为什么那么快？" class="headerlink" title="单线程 Redis 为什么那么快？"></a>单线程 Redis 为什么那么快？</h2><ol><li>Redis 的大部分操作在 <strong>内存</strong> 上完成，再加上它采用了高效的数据结构，例如哈希表和跳表</li><li>Redis 采用了 <strong>多路复用机制</strong>，使其在网络 IO 操作中能并发处理大量的客户端请求，实现高吞吐率</li></ol><h2 id="基本-IO-模型与阻塞点"><a href="#基本-IO-模型与阻塞点" class="headerlink" title="基本 IO 模型与阻塞点"></a>基本 IO 模型与阻塞点</h2><p>以 <code>Get</code> 请求为例，为了处理一个 <code>Get</code> 请求，需要监听客户端请求（<code>bind/listen</code>），和客户端建立连接（<code>accept</code>），从 <code>socket</code> 中读取请求（<code>recv</code>），解析客户端发送请求（<code>parse</code>），根据请求类型读取键值数据（<code>get</code>），最后给客户端返回结果，即向 <code>socket</code> 中写回数据（<code>send</code>）。</p><p>下图显示了这一过程，其中，<code>bind/listen</code>、<code>accept</code>、<code>recv</code>、<code>parse</code> 和 <code>send</code> 属于网络 IO 处理，而 <code>get</code> 属于键值数据操作。既然 Redis 是单线程，那么，最基本的一种实现是在一个线程中依次执行上面说的这些操作。</p><img src="/2021/04/10/Redis/03/image-20210110182324959.png" class="" title="image-20210110182324959"><p>网络 IO 操作中，有潜在的阻塞点，分别是 <code>accept()</code> 和 <code>recv()</code>。当 Redis 监听到一个客户端有连接请求，但一直未能成功建立起连接时，会阻塞在 <code>accept()</code> 函数这里，导致其他客户端无法和 Redis 建立连接。类似的，当 <code>Redis</code> 通过 <code>recv()</code> 从一个客户端读取数据时，如果数据一直没有到达，Redis 也会一直阻塞在 <code>recv()</code>。</p><p>这就导致 Redis 整个线程阻塞，无法处理其他客户端请求，效率很低。不过，幸运的是，<strong>socket 网络模型本身支持非阻塞模式</strong></p><h3 id="非阻塞模式"><a href="#非阻塞模式" class="headerlink" title="非阻塞模式"></a>非阻塞模式</h3><p><code>Socket</code> 网络模型的非阻塞模式设置，主要体现在三个关键的函数调用上，如果想要使用 <code>socket</code> 非阻塞模式，就必须要了解这三个函数的调用返回类型和设置模式</p><p>在 <code>socket</code> 模型中，不同操作调用后会返回不同的套接字类型。<code>socket()</code> 方法会返回主动套接字，然后调用 <code>listen()</code> 方法，将主动套接字转化为监听套接字，此时，可以监听来自客户端的连接请求。最后，调用 <code>accept()</code> 方法接收到达的客户端连接，并返回已连接套接字。</p><img src="/2021/04/10/Redis/03/image-20210110185051995.png" class="" title="image-20210110185051995"><p>针对<strong>监听套接字</strong>设置非阻塞模式：当 Redis 调用 <code>accept()</code> 但一直未有连接请求到达时，Redis 线程可以返回处理其他操作，而不用一直等待。但是，你要注意的是，调用 <code>accept()</code> 时，已经存在监听套接字了。虽然 Redis 线程可以不用继续等待，但是总得有机制继续在监听套接字上等待后续连接请求，并在有请求时通知 Redis。</p><p>针对<strong>已连接套接字</strong>设置非阻塞模式：Redis 调用 <code>recv()</code> 后，如果已连接套接字上一直没有数据到达，Redis 线程同样可以返回处理其他操作。我们也需要有机制继续监听该已连接套接字，并在有数据达到时通知 Redis。</p><p>这样才能保证 Redis 线程，既不会像基本 IO 模型中一直在阻塞点等待，也不会导致 Redis 无法处理实际到达的连接请求或数据。到此，Linux 中的 IO 多路复用机制就要登场了。</p><h3 id="基于多路复用的高性能-I-O-模型"><a href="#基于多路复用的高性能-I-O-模型" class="headerlink" title="基于多路复用的高性能 I/O 模型"></a>基于多路复用的高性能 I/O 模型</h3><p>Linux 中的 IO 多路复用机制是指<strong>一个线程处理多个 IO 流</strong>，就是我们经常听到的 <strong>select/epoll 机制</strong></p><p>在 Redis 只运行单线程的情况下，<strong>该机制允许内核中，同时存在多个监听套接字和已连接套接字</strong>。内核会一直监听这些套接字上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。</p><img src="/2021/04/10/Redis/03/image-20210110190900846.png" class="" title="image-20210110190900846"><p>图中的多个 <code>FD</code> 就是刚才所说的多个套接字。Redis 网络框架调用 epoll 机制，让内核监听这些套接字。此时，<code>Redis</code> 线程不会阻塞在某一个特定的监听或已连接套接字上，也就是说，不会阻塞在某一个特定的客户端请求处理上。正因为此，Redis 可以同时和多个客户端连接并处理请求，从而提升并发性。</p><p>为了在请求到达时能通知到 Redis 线程，<code>select/epoll</code> 提供了<strong>基于事件的回调机制</strong>，即针对不同事件的发生，调用相应的处理函数。<code>select/epoll</code> 一旦监测到 <code>FD</code> 上有请求到达时，就会触发相应的事件。</p><p>这些事件会被放进一个事件队列，Redis 单线程对该事件队列不断进行处理。这样一来，Redis 无需一直轮询是否有请求实际发生，这就可以避免造成 CPU 资源浪费。同时，Redis 在对事件队列中的事件进行处理时，会调用相应的处理函数，这就实现了基于事件的回调。因为 Redis 一直在对事件队列进行处理，所以能及时响应客户端请求，提升 Redis 的响应性能。</p><p>方便理解，再以连接请求和读数据请求为例，具体解释一下。如两个请求分别对应 <code>Accept</code> 事件和 <code>Read</code> 事件，<code>Redis</code> 分别对这两个事件注册 <code>accept</code> 和 <code>get</code> 回调函数。当 Linux 内核监听到有连接请求或读数据请求时，就会触发 <code>Accept</code> 事件和 <code>Read</code> 事件，此时，内核就会回调 <code>Redis</code> 相应的 <code>accept</code> 和 <code>get</code> 函数进行处理。</p>]]></content>
    
    
    <summary type="html">为什么单线程Redis能这么快？</summary>
    
    
    
    <category term="极客时间Redis实战" scheme="http://universeinheart.github.io/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4Redis%E5%AE%9E%E6%88%98/"/>
    
    
    <category term="Redis" scheme="http://universeinheart.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>04、Redis AOF日志</title>
    <link href="http://universeinheart.github.io/2021/04/10/Redis/04/"/>
    <id>http://universeinheart.github.io/2021/04/10/Redis/04/</id>
    <published>2021-04-10T11:50:15.000Z</published>
    <updated>2021-04-13T15:59:42.390Z</updated>
    
    <content type="html"><![CDATA[<p>Redis 的持久化主要有两大机制，即 **AOF（Append Only File）日志 **和  <strong>RDB 快照</strong></p><h2 id="AOF-日志是如何实现的？"><a href="#AOF-日志是如何实现的？" class="headerlink" title="AOF 日志是如何实现的？"></a>AOF 日志是如何实现的？</h2><p>数据库的 <strong>写前日志（Write Ahead Log, WAL）</strong>，在实际写数据前，先把修改的数据记到日志文件中，以便故障时进行恢复。</p><p>不过，AOF 日志正好相反，它是 <strong>写后日志</strong>，“写后”的意思是 <strong>Redis 是先执行命令，把数据写入内存，然后才记录日志</strong>，如下图所示：</p><img src="/2021/04/10/Redis/04/image-20210111232040747.png" class="" title="image-20210111232040747"><h3 id="那-AOF-为什么要先执行命令再记日志呢？"><a href="#那-AOF-为什么要先执行命令再记日志呢？" class="headerlink" title="那 AOF 为什么要先执行命令再记日志呢？"></a>那 AOF 为什么要先执行命令再记日志呢？</h3><p>传统数据库的日志，例如 <strong>redo log（重做日志）</strong>，记录的是修改后的数据，而 AOF 里记录的是 <strong>Redis 收到的每一条命令</strong>，这些命令是以文本形式保存的。</p><blockquote><p>以 Redis 收到“set testkey testvalue”命令后记录的日志为例，看看 AOF 日志的内容。</p><p>其中，“*3”表示当前命令有三个部分，每部分都是由“$+数字”开头，后面紧跟着具体的命令、键或值。这里，“数字”表示这部分中的命令、键或值一共有多少字节。例如，“$3 set”表示这部分有 3 个字节，也就是“set”命令。</p></blockquote><img src="/2021/04/10/Redis/04/image-20210111232612880.png" class="" title="image-20210111232612880"><p>为了避免额外的检查开销，Redis 在向 AOF 里面记录日志的时候，并不会先去对这些命令进行语法检查。所以，如果先记日志再执行命令的话，日志中就有可能记录了错误的命令，Redis 在使用日志恢复数据时，就可能会出错。而写后日志这种方式，就是先让系统执行命令，只有命令能执行成功，才会被记录到日志中，否则，系统就会直接向客户端报错。</p><p>所以，Redis 使用写后日志这一方式的一大好处是，可以 <strong>避免出现记录错误命令</strong> 的情况。AOF 还有一个好处：它是在命令执行后才记录日志，所以<strong>不会阻塞当前的写操作</strong>。</p><h3 id="AOF-也有两个潜在的风险"><a href="#AOF-也有两个潜在的风险" class="headerlink" title="AOF 也有两个潜在的风险"></a>AOF 也有两个潜在的风险</h3><p>首先，如果刚执行完一个命令，还没有来得及记日志就宕机了，那么这个命令和相应的数据就有丢失的风险。如果此时 Redis 是用作缓存，还可以从后端数据库重新读入数据进行恢复，但是，如果 Redis 是直接用作数据库的话，此时，因为命令没有记入日志，所以就无法用日志进行恢复了。</p><p>其次，AOF 虽然避免了对当前命令的阻塞，但可能会给下一个操作带来阻塞风险。这是因为，AOF 日志也是在主线程中执行的，如果在把日志文件写入磁盘时，磁盘写压力大，就会导致写盘很慢，进而导致后续的操作也无法执行了。</p><p>仔细分析的话，你就会发现，这两个风险都是和 <strong>AOF 写回磁盘的时机</strong>相关的。这也就意味着，如果我们能够控制一个写命令执行完后 AOF 日志写回磁盘的时机，这两个风险就解除了。</p><h2 id="三种写回策略"><a href="#三种写回策略" class="headerlink" title="三种写回策略"></a>三种写回策略</h2><p>AOF 机制给我们提供了三个选择，也就是 AOF 配置项 <code>appendfsync</code> 的三个可选值。</p><ul><li><strong>Always</strong>，<strong>同步写回</strong>：每个写命令执行完，立马同步地将日志写回磁盘；不可避免地会影响主线程性能</li><li><strong>Everysec</strong>，<strong>每秒写回</strong>：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘；在避免影响主线程性能和避免数据丢失两者间取了个折中。</li><li><strong>No</strong>，<strong>操作系统控制的写回</strong>：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。落盘的时机已经不在 Redis 手中了，只要 AOF 记录没有写回磁盘，一旦宕机对应的数据就丢失了</li></ul><img src="/2021/04/10/Redis/04/image-20210111233115916.png" class="" title="image-20210111233115916"><p>随着接收的写命令越来越多，AOF 文件会越来越大。一定要小心 AOF 文件过大带来的性能问题。</p><p>一、文件系统本身对文件大小有限制，无法保存过大的文件</p><p>二、如果文件太大，之后再往里面追加命令记录的话，效率也会变低</p><p>三、如果发生宕机，AOF 中记录的命令要一个个被重新执行，用于故障恢复，如果日志文件太大，整个恢复过程就会非常缓慢，这就会影响到 Redis 的正常使用。</p><h2 id="日志文件太大了怎么办？（AOF-重写机制）"><a href="#日志文件太大了怎么办？（AOF-重写机制）" class="headerlink" title="日志文件太大了怎么办？（AOF 重写机制）"></a>日志文件太大了怎么办？（AOF 重写机制）</h2><p>重写机制具有“多变一”功能。旧日志文件中的多条命令，在重写后的新日志中变成了一条命令。</p><p><code>AOF</code> 文件是以追加的方式，逐一记录接收到的写命令的。当一个键值对被多条写命令反复修改时，AOF 文件会记录相应的多条命令。但是，在重写的时候，是根据这个键值对当前的最新状态，为它生成对应的写入命令。这样一来，一个键值对在重写日志中只用一条命令就行了，而且，在日志恢复时，只用执行这条命令，就可以直接完成这个键值对的写入了。</p><img src="/2021/04/10/Redis/04/image-20210113224725050.png" class="" title="image-20210113224725050"><h2 id="AOF-重写会阻塞吗"><a href="#AOF-重写会阻塞吗" class="headerlink" title="AOF 重写会阻塞吗?"></a>AOF 重写会阻塞吗?</h2><p>和 <strong>AOF 日志由主线程写回</strong> 不同，重写过程是由后台子进程 <code>bgrewriteaof</code> 来完成的，这也是为了避免阻塞主线程，导致数据库性能下降。</p><p>每次执行重写时，主线程 fork 出后台的 <code>bgrewriteaof</code> 子进程。此时，fork 会把主线程的内存拷贝一份给 <code>bgrewriteaof</code> 子进程，这里面就包含了数据库的最新数据。然后，<code>bgrewriteaof</code> 子进程就可以在不影响主线程的情况下，逐一把拷贝的数据写成操作，记入重写日志。</p><p>因为主线程未阻塞，仍然可以处理新来的操作。此时，如果有写操作，Redis 会把这个操作写到它的缓冲区。这样一来，即使宕机了，这个 AOF 日志的操作仍然是齐全的，可以用于恢复。这个操作也会被写到重写日志的缓冲区。这样，重写日志也不会丢失最新的操作。等到拷贝数据的所有操作记录重写完成后，重写日志记录的这些最新操作也会写入新的 AOF 文件，以保证数据库最新状态的记录。此时，我们就可以用新的 AOF 文件替代旧文件了。</p><img src="/2021/04/10/Redis/04/image-20210113233333814.png" class="" title="image-20210113233333814"><p>每次 AOF 重写时，Redis 会先执行一个内存拷贝，用于重写；然后，使用两个日志保证在重写过程中，新写入的数据不会丢失。而且，因为 Redis 采用额外的线程进行数据重写，所以，这个过程并不会阻塞主线程。</p>]]></content>
    
    
    <summary type="html">宕机了，Redis如何避免数据丢失</summary>
    
    
    
    <category term="极客时间Redis实战" scheme="http://universeinheart.github.io/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4Redis%E5%AE%9E%E6%88%98/"/>
    
    
    <category term="Redis" scheme="http://universeinheart.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>00、Redis 相关</title>
    <link href="http://universeinheart.github.io/2021/04/09/Redis/0/"/>
    <id>http://universeinheart.github.io/2021/04/09/Redis/0/</id>
    <published>2021-04-09T14:00:15.000Z</published>
    <updated>2021-04-10T12:17:38.083Z</updated>
    
    <content type="html"><![CDATA[<img src="/2021/04/09/Redis/0/image-20210109194509294.png" class="" title="image-20210109194509294"><img src="/2021/04/09/Redis/0/image-20210109194543978.png" class="" title="image-20210109194543978">]]></content>
    
    
    <summary type="html">Redis描述</summary>
    
    
    
    <category term="极客时间Redis实战" scheme="http://universeinheart.github.io/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4Redis%E5%AE%9E%E6%88%98/"/>
    
    
    <category term="Redis" scheme="http://universeinheart.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>01、Redis 基础架构</title>
    <link href="http://universeinheart.github.io/2021/04/09/Redis/01/"/>
    <id>http://universeinheart.github.io/2021/04/09/Redis/01/</id>
    <published>2021-04-09T14:00:15.000Z</published>
    <updated>2021-04-10T12:17:04.651Z</updated>
    
    <content type="html"><![CDATA[<p>更好的学习方式就是先建立起“<code>系统观</code>”</p><p>一个键值数据库包括了<code>访问框架</code>、<code>索引模块</code>、<code>操作模块</code>和<code>存储模块</code>四部分，我们从这四个部分入手，构建我们的 <code>SimpleKV</code></p><img src="/2021/04/09/Redis/01/image-20210109195252143.png" class="" title="image-20210109201055704"><h2 id="采用什么访问模式？"><a href="#采用什么访问模式？" class="headerlink" title="采用什么访问模式？"></a>采用什么访问模式？</h2><p>访问模式通常有两种：</p><p>一、通过函数库调用的方式供外部应用使用，比如，上图中的 libsimplekv.so，就是以动态链接库的形式链接到我们自己的程序中，提供键值存储功能；</p><p>二、通过网络框架以 Socket 通信的形式对外提供键值对操作，网络框架中包括 Socket Server 和协议解析。（Redis使用）</p><blockquote><p>通过网络框架提供键值存储服务，一方面扩大了键值数据库的受用面，但另一方面，也给键值数据库的性能、运行模型提供了不同的设计选择，带来了一些潜在的问题。</p><p>举个例子，当客户端发送一个如下的命令后，该命令会被封装在网络包中发送给键值数据库：<code>PUT hello world</code></p><p>键值数据库网络框架接收到网络包，并按照相应的协议进行解析之后，就可以知道，客户端想写入一个键值对，并开始实际的写入流程。此时，我们会遇到一个系统设计上的问题，简单来说，就是<strong>网络连接的处理</strong>、<strong>网络请求的解析</strong>，以及<strong>数据存取的处理</strong>，是用一个线程、多个线程，还是多个进程来交互处理呢？该如何进行设计和取舍呢？我们一般把这个问题称为 I/O 模型设计。不同的 I/O 模型对键值数据库的性能和可扩展性会有不同的影响。</p><p>举个例子，如果一个线程既要处理网络连接、解析请求，又要完成数据存取，一旦某一步操作发生阻塞，整个线程就会阻塞住，这就降低了系统响应速度。如果我们采用不同线程处理不同操作，那么，某个线程被阻塞时，其他线程还能正常运行。但是，不同线程间如果需要访问共享资源，那又会产生线程竞争，也会影响系统效率，这又该怎么办呢？所以，这的确是个“两难”选择，需要我们进行精心的设计。</p></blockquote><h2 id="如何定位键值对的位置？"><a href="#如何定位键值对的位置？" class="headerlink" title="如何定位键值对的位置？"></a>如何定位键值对的位置？</h2><p>**索引 **的作用是让键值数据库根据 <code>key</code> 找到相应 <code>value</code> 的存储位置，进而执行操作。</p><p><code>Redis</code> 采用哈希表作为 <code>key-value</code> 索引，也会采用跳表（）</p><h2 id="不同操作的具体逻辑是怎样的？"><a href="#不同操作的具体逻辑是怎样的？" class="headerlink" title="不同操作的具体逻辑是怎样的？"></a>不同操作的具体逻辑是怎样的？</h2><ul><li>对于 <code>GET/SCAN</code> 操作而言，此时根据 <code>value</code> 的存储位置返回 <code>value</code> 值即可；</li><li>对于 <code>PUT</code> 一个新的键值对数据而言，需要为该键值对分配内存空间；</li><li>对于 <code>DELETE</code> 操作，需要删除键值对，并释放相应的内存空间，这个过程由分配器完成。</li></ul><p>对于 <code>PUT</code> 和 <code>DELETE</code> 两种操作来说，除了新写入和删除键值对，还需要分配和释放内存。这就需要存储模块了。</p><blockquote><p> SimpleKV 采用了常用的内存分配器 <code>glibc</code> 的 <code>malloc</code> 和 <code>free</code>，因此，SimpleKV 并不需要特别考虑内存空间的管理问题。但是，键值数据库的键值对通常大小不一，<code>glibc</code> 的分配器在处理随机的大小内存块分配时，表现并不好。一旦保存的键值对数据规模过大，就可能会造成较严重的内存碎片问题。因此，分配器是键值数据库中的一个关键因素。</p><p>对于以内存存储为主的 Redis 而言，这点尤为重要。Redis 的内存分配器提供了多种选择，分配效率也不一样 </p></blockquote><h2 id="如何实现重启后快速提供服务？"><a href="#如何实现重启后快速提供服务？" class="headerlink" title="如何实现重启后快速提供服务？"></a>如何实现重启后快速提供服务？</h2><p>存储模块中增加了持久化功能，重启后能快速重新提供服务</p><blockquote><p>不过，鉴于磁盘管理要比内存管理复杂，SimpleKV 就直接采用了文件形式，将键值数据通过调用本地文件系统的操作接口保存在磁盘上。此时，SimpleKV 只需要考虑何时将内存中的键值数据保存到文件中，就可以了。</p><p>一种方式是，对于每一个键值对，SimpleKV 都对其进行落盘保存，这虽然让 SimpleKV 的数据更加可靠，但是，因为每次都要写盘，SimpleKV 的性能会受到很大影响。</p><p>另一种方式是，SimpleKV 只是周期性地把内存中的键值数据保存到文件中，这样可以避免频繁写盘操作的性能影响。但是，一个潜在的代价是 SimpleKV 的数据仍然有丢失的风险。</p><p>和 SimpleKV 一样，Redis 也提供了持久化功能。不过，为了适应不同的业务场景，Redis 为持久化提供了诸多的执行机制和优化改进 </p></blockquote><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>从 <code>SimpleKV</code> 演进到 <code>Redis</code>，有以下几个重要变化：</p><ul><li><code>Redis</code> 主要通过网络框架进行访问，而不再是动态库了，这也使得 Redis 可以作为一个基础性的网络服务进行访问，扩大了 Redis 的应用范围。</li><li><code>Redis</code> 数据模型中的 value 类型很丰富，因此也带来了更多的操作接口，例如面向列表的 <code>LPUSH/LPOP</code>，面向集合的 <code>SADD/SREM</code> 等。</li><li><code>Redis</code> 的持久化模块能支持两种方式：日志（<code>AOF</code>）和快照（<code>RDB</code>），这两种持久化方式具有不同的优劣势，影响到 <code>Redis</code> 的访问性能和可靠性。</li><li><code>SimpleKV</code> 是个简单的单机键值数据库，但是，<code>Redis</code> 支持高可靠集群和高可扩展集群，因此，<code>Redis</code> 中包含了相应的集群功能支撑模块。</li></ul><img src="/2021/04/09/Redis/01/image-20210109201055704.png" class="" title="image-20210109201055704">]]></content>
    
    
    <summary type="html">一个键值数据库包含什么？</summary>
    
    
    
    <category term="极客时间Redis实战" scheme="http://universeinheart.github.io/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4Redis%E5%AE%9E%E6%88%98/"/>
    
    
    <category term="Redis" scheme="http://universeinheart.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>02、Redis 数据结构</title>
    <link href="http://universeinheart.github.io/2021/04/09/Redis/02/"/>
    <id>http://universeinheart.github.io/2021/04/09/Redis/02/</id>
    <published>2021-04-09T14:00:15.000Z</published>
    <updated>2021-04-10T12:17:40.744Z</updated>
    
    <content type="html"><![CDATA[<p>数据库这么多，为啥 Redis 能有这么突出的表现呢？一方面，这是因为它是 <strong>内存数据库</strong>，所有操作都在内存上完成，内存的访问速度本身就很快。另一方面，这要归功于它的<strong>数据结构</strong>。这是因为，键值对是按一定的数据结构来组织的，操作键值对最终就是对数据结构进行增删改查操作，所以高效的数据结构是 Redis 快速处理数据的基础。</p><p>底层数据结构一共有 6 种，分别是 <strong>简单动态字符串</strong>、<strong>双向链表</strong>、<strong>压缩列表</strong>、<strong>哈希表</strong>、<strong>跳表</strong>和<strong>整数数组</strong>。</p><p>它们和数据类型的对应关系如下图所示：</p><img src="/2021/04/09/Redis/02/image-20210110094110377.png" class="" title="image-20210110094110377"><p><code>String</code> 类型的底层实现只有一种数据结构，也就是简单动态字符串。</p><p><code>List</code>、<code>Hash</code>、<code>Set</code> 和 <code>Sorted Set</code> 这四种数据类型，都有两种底层实现结构。特点是<strong>一个键对应了一个集合的数据</strong>。</p><blockquote><p>问题1. 这些数据结构都是值的底层实现，键和值本身之间用什么结构组织？</p><p>问题2. 为什么集合类型有那么多的底层结构，它们都是怎么组织数据的，都很快吗？</p><p>问题3. 什么是简单动态字符串，和常用的字符串是一回事吗？</p></blockquote><h3 id="键和值用什么结构组织？"><a href="#键和值用什么结构组织？" class="headerlink" title="键和值用什么结构组织？"></a>键和值用什么结构组织？</h3><p>为了实现从键到值的快速访问，Redis 使用了一个<strong>哈希表</strong>来保存所有键值对。一个哈希表，其实就是一个数组，数组的每个元素称为一个哈希桶</p><blockquote><p>Q:如果值是集合类型的话，作为数组元素的哈希桶怎么来保存呢？</p><p>A:哈希桶中的元素保存的并不是值本身，而是指向具体值的指针。这也就是说，不管值是 String，还是集合类型，哈希桶中的元素都是指向它们的指针。</p></blockquote><img src="/2021/04/09/Redis/02/image-20210110095737063.png" class="" title="image-20210110095737063"><p><strong>潜在的风险点: 哈希表的冲突问题和 rehash 可能带来的操作阻塞。</strong></p><p>哈希冲突 –&gt;  链式哈希  –&gt;  效率降低 –&gt; rehash(增加哈希桶数量)</p><p>为了使 <code>rehash</code> 操作更高效，<code>Redis</code> 默认使用了两个全局哈希表：<strong>哈希表 1</strong> 和<strong>哈希表 2</strong>。</p><p>一开始，当你刚插入数据时，默认使用<strong>哈希表 1</strong>，此时的<strong>哈希表 2</strong> 并没有被分配空间。</p><p>随着数据逐步增多，Redis 开始执行 <code>rehash</code>，这个过程分为三步：</p><ol><li><p>给<strong>哈希表 2</strong> 分配更大的空间，例如是当前<strong>哈希表 1</strong> 大小的两倍；</p></li><li><p>把<strong>哈希表 1</strong> 中的数据重新映射并拷贝到<strong>哈希表 2</strong> 中；</p></li><li><p>释放<strong>哈希表 1</strong> 的空间。</p></li></ol><p>到此，我们就可以从 <strong>哈希表 1</strong> 切换到 <strong>哈希表 2</strong>，用增大的 <strong>哈希表 2</strong> 保存更多数据，而原来的<strong>哈希表 1</strong> 留作下一次 <code>rehash</code> 扩容备用。</p><p>这个过程看似简单，但是第二步涉及大量的数据拷贝，如果一次性把<strong>哈希表 1</strong> 中的数据都迁移完，会造成 <strong>Redis 线程阻塞</strong>，无法服务其他请求。此时，Redis 就无法快速访问数据了。</p><p>为了避免这个问题，Redis 采用了 <strong>渐进式 rehash</strong>。</p><p><strong>渐进式 rehash</strong>在第二步拷贝数据时，Redis 仍然正常处理客户端请求，每处理一个请求时，从 <strong>哈希表 1</strong> 中的第一个索引位置开始，顺带着将这个索引位置上的所有 <code>entries</code> 拷贝到 <strong>哈希表 2</strong> 中；等处理下一个请求时，再顺带拷贝 <strong>哈希表 1</strong> 中的下一个索引位置的 <code>entries</code>。如下图所示</p><img src="/2021/04/09/Redis/02/image-20210110163432821.png" class="" title="image-20210110163432821"><p>巧妙地把一次性大量拷贝的开销，分摊到了多次处理请求的过程中，避免了耗时操作，保证了数据的快速访问。</p><h3 id="底层数据结构？"><a href="#底层数据结构？" class="headerlink" title="底层数据结构？"></a>底层数据结构？</h3><p>整数数组</p><p>双向链表</p><p>哈希表</p><h4 id="压缩列表"><a href="#压缩列表" class="headerlink" title="压缩列表"></a>压缩列表</h4><p>压缩列表实际上类似于一个数组，数组中的每一个元素都对应保存一个数据。</p><p>和数组不同的是，压缩列表在表头有三个字段 <code>zlbytes</code>、<code>zltail</code> 和 <code>zllen</code>，分别表示 <strong>列表长度</strong>、<strong>列表尾的偏移量</strong> 和 <strong>列表中的 entry 个数</strong>；压缩列表在表尾还有一个 <code>zlend</code>，表示列表结束。</p><img src="/2021/04/09/Redis/02/image-20210110164229889.png" class="" title="image-20210110164229889"><p>在压缩列表中，如果我们要查找定位第一个元素和最后一个元素，可以通过表头三个字段的长度直接定位，复杂度是 O(1)。而查找其他元素时，就没有这么高效了，只能逐个查找，此时的复杂度就是 O(N) 了。</p><h4 id="跳表"><a href="#跳表" class="headerlink" title="跳表"></a>跳表</h4><p>跳表在链表的基础上，增加了多级索引，通过索引位置的几个跳转，实现<strong>有序数据</strong>的快速定位</p><img src="/2021/04/09/Redis/02/image-20210110165006388.png" class="" title="image-20210110165006388"><h3 id="不同操作的复杂度"><a href="#不同操作的复杂度" class="headerlink" title="不同操作的复杂度"></a>不同操作的复杂度</h3><h4 id="单元素操作是基础"><a href="#单元素操作是基础" class="headerlink" title="单元素操作是基础"></a>单元素操作是基础</h4><p>单元素操作，是指每一种集合类型对单个数据实现的增删改查操作。</p><p>例如，<code>Hash</code> 类型的 <code>HGET</code>、<code>HSET</code> 和 <code>HDEL</code>，<code>Set</code> 类型的 <code>SADD</code>、<code>SREM</code>、<code>SRANDMEMBER</code> 等。</p><p>这些操作的复杂度由集合采用的数据结构决定，例如，<code>HGET</code>、<code>HSET</code> 和 <code>HDEL</code> 是对哈希表做操作，所以它们的复杂度都是 O(1)；Set 类型用哈希表作为底层数据结构时，它的 <code>SADD</code>、<code>SREM</code>、<code>SRANDMEMBER</code> 复杂度也是 O(1)。</p><h4 id="范围操作非常耗时"><a href="#范围操作非常耗时" class="headerlink" title="范围操作非常耗时"></a>范围操作非常耗时</h4><p>范围操作，是指集合类型中的遍历操作，可以返回集合中的所有数据，比如 <code>Hash</code> 类型的 <code>HGETALL</code> 和 <code>Set</code> 类型的 <code>SMEMBERS</code>，或者返回一个范围内的部分数据，比如 <code>List</code> 类型的 <code>LRANGE</code> 和 <code>ZSet</code> 类型的 <code>ZRANGE</code>。这类操作的复杂度一般是 O(N)，比较耗时，我们应该尽量避免。</p><p>不过，Redis 从 2.8 版本开始提供了 <code>SCAN</code> 系列操作（包括 <code>HSCAN</code>，<code>SSCAN</code> 和 <code>ZSCAN</code>），这类操作实现了<strong>渐进式遍历</strong>，每次只返回有限数量的数据。这样一来，相比于 <code>HGETALL</code>、<code>SMEMBERS</code> 这类操作来说，就避免了一次性返回所有元素而导致的 Redis 阻塞。</p><h4 id="统计操作通常高效"><a href="#统计操作通常高效" class="headerlink" title="统计操作通常高效"></a>统计操作通常高效</h4><p><strong>集合类型对集合中所有元素个数的记录，例如 <code>LLEN</code> 和 <code>SCARD</code></strong></p><h4 id="例外情况只有几个"><a href="#例外情况只有几个" class="headerlink" title="例外情况只有几个"></a>例外情况只有几个</h4><p>例外情况，是指某些数据结构的特殊记录，例如压缩列表和双向链表都会记录表头和表尾的偏移量。这样一来，对于 List 类型的 <code>LPOP</code>、<code>RPOP</code>、<code>LPUSH</code>、<code>RPUSH</code> 这四个操作来说，它们是在列表的头尾增删元素，这就可以通过偏移量直接定位，所以它们的复杂度也只有 O(1)，可以实现快速操作。</p>]]></content>
    
    
    <summary type="html">快速的Redis有哪些慢操作？</summary>
    
    
    
    <category term="极客时间Redis实战" scheme="http://universeinheart.github.io/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4Redis%E5%AE%9E%E6%88%98/"/>
    
    
    <category term="Redis" scheme="http://universeinheart.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>CAP定理</title>
    <link href="http://universeinheart.github.io/2021/04/05/%E5%88%86%E5%B8%83%E5%BC%8F/CAP/"/>
    <id>http://universeinheart.github.io/2021/04/05/%E5%88%86%E5%B8%83%E5%BC%8F/CAP/</id>
    <published>2021-04-05T09:52:56.000Z</published>
    <updated>2021-04-05T10:04:03.478Z</updated>
    
    <content type="html"><![CDATA[<p>分布式系统的最大难点，就是各个节点的状态如何同步。</p><p>CAP 定理是这方面的基本定理，也是理解分布式系统的起点。</p><h2 id="一、分布式系统的三个指标"><a href="#一、分布式系统的三个指标" class="headerlink" title="一、分布式系统的三个指标"></a>一、分布式系统的三个指标</h2><img src="/2021/04/05/%E5%88%86%E5%B8%83%E5%BC%8F/CAP/image-20210405175903359.png" class="" title="image-20210405175903359"><blockquote><ul><li>Consistency  一致性</li><li>Availability  可用性</li><li>Partition tolerance  分区容错</li></ul><p>这三个指标不可能同时做到。这个结论就叫做 CAP 定理。</p></blockquote><h2 id="二、Partition-tolerance"><a href="#二、Partition-tolerance" class="headerlink" title="二、Partition tolerance"></a>二、Partition tolerance</h2><p>大多数分布式系统都分布在多个子网络。每个子网络就叫做一个区（partition）。分区容错的意思是，区间通信可能失败。比如，一台服务器放在中国，另一台服务器放在美国，这就是两个区，它们之间可能无法通信。</p><img src="/2021/04/05/%E5%88%86%E5%B8%83%E5%BC%8F/CAP/image-20210405175847147.png" class="" title="image-20210405175847147"><p>上图中，G1 和 G2 是两台跨区的服务器。G1 向 G2 发送一条消息，G2 可能无法收到。系统设计的时候，必须考虑到这种情况。</p><p>一般来说，分区容错无法避免，因此可以认为 CAP 的 P 总是成立。CAP 定理告诉我们，剩下的 C 和 A 无法同时做到。</p><h2 id="三、Consistency"><a href="#三、Consistency" class="headerlink" title="三、Consistency"></a>三、Consistency</h2><p>举例来说，某条记录是 v0，用户向 G1 发起一个写操作，将其改为 v1。</p><img src="/2021/04/05/%E5%88%86%E5%B8%83%E5%BC%8F/CAP/image-20210405175832086.png" class="" title="image-20210405175832086"><p>接下来，用户的读操作就会得到 v1。这就叫一致性。</p><img src="/2021/04/05/%E5%88%86%E5%B8%83%E5%BC%8F/CAP/image-20210405175948520.png" class="" title="image-20210405175948520"><p>问题是，用户有可能向 G2 发起读操作，由于 G2 的值没有发生变化，因此返回的是 v0。G1 和 G2 读操作的结果不一致，这就不满足一致性了。</p><img src="/2021/04/05/%E5%88%86%E5%B8%83%E5%BC%8F/CAP/image-20210405180011013.png" class="" title="image-20210405180011013"><p>为了让 G2 也能变为 v1，就要在 G1 写操作的时候，让 G1 向 G2 发送一条消息，要求 G2 也改成 v1。</p><img src="/2021/04/05/%E5%88%86%E5%B8%83%E5%BC%8F/CAP/image-20210405180026995.png" class="" title="image-20210405180026995"><p>这样的话，用户向 G2 发起读操作，也能得到 v1。</p><img src="/2021/04/05/%E5%88%86%E5%B8%83%E5%BC%8F/CAP/image-20210405180038257.png" class="" title="image-20210405180038257"><h2 id="四、Availability"><a href="#四、Availability" class="headerlink" title="四、Availability"></a>四、Availability</h2><p>用户可以选择向 G1 或 G2 发起读操作。不管是哪台服务器，只要收到请求，就必须告诉用户，到底是 v0 还是 v1，否则就不满足可用性。</p><h2 id="五、Consistency-和-Availability-的矛盾"><a href="#五、Consistency-和-Availability-的矛盾" class="headerlink" title="五、Consistency 和 Availability 的矛盾"></a>五、Consistency 和 Availability 的矛盾</h2><p>一致性和可用性，为什么不可能同时成立？答案很简单，因为可能通信失败（即出现分区容错）。</p><p>如果保证 G2 的一致性，那么 G1 必须在写操作时，锁定 G2 的读操作和写操作。只有数据同步后，才能重新开放读写。锁定期间，G2 不能读写，没有可用性不。</p><p>如果保证 G2 的可用性，那么势必不能锁定 G2，所以一致性不成立。</p><p>综上所述，G2 无法同时做到一致性和可用性。系统设计时只能选择一个目标。如果追求一致性，那么无法保证所有节点的可用性；如果追求所有节点的可用性，那就没法做到一致性。</p><blockquote><p><strong>读者问，在什么场合，可用性高于一致性？</strong></p><p>举例来说，发布一张网页到 CDN，多个服务器有这张网页的副本。后来发现一个错误，需要更新网页，这时只能每个服务器都更新一遍。</p><p>一般来说，网页的更新不是特别强调一致性。短时期内，一些用户拿到老版本，另一些用户拿到新版本，问题不会特别大。当然，所有人最终都会看到新版本。所以，这个场合就是可用性高于一致性。</p></blockquote><p>原文：<a href="http://www.ruanyifeng.com/blog/2018/07/cap.html">http://www.ruanyifeng.com/blog/2018/07/cap.html</a></p>]]></content>
    
    
    <summary type="html">分布式系统的CAP定理</summary>
    
    
    
    <category term="分布式" scheme="http://universeinheart.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="CAP" scheme="http://universeinheart.github.io/tags/CAP/"/>
    
    <category term="分布式" scheme="http://universeinheart.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>01、基础架构：一条SQL查询语句是如何执行的</title>
    <link href="http://universeinheart.github.io/2021/04/04/MySQL/01/"/>
    <id>http://universeinheart.github.io/2021/04/04/MySQL/01/</id>
    <published>2021-04-04T14:13:56.000Z</published>
    <updated>2021-04-04T16:59:07.988Z</updated>
    
    <content type="html"><![CDATA[<p>有个最简单的表，表里只有一个ID字段，在执行下面这个查询语句时：</p><p><code>mysql&gt; select * from T where ID=10；</code></p><p> MySQL的基本架构示意图，可以清楚地看到SQL语句在MySQL的各个功能模块中的执行过程。</p><img src="image-20210127222256017.png" alt="image-20210127222256017"  /><p>MySQL可以分为 <strong>Server层</strong> 和 <strong>存储引擎层</strong> 两部分。</p><ol><li>Server层包括 <strong>连接器</strong>、<strong>查询缓存</strong>、<strong>分析器</strong>、<strong>优化器</strong>、<strong>执行器</strong>等，涵盖MySQL的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），<strong>所有跨存储引擎的功能都在这一层实现</strong>，比如存储过程、触发器、视图等。</li><li><strong>存储引擎层负责数据的存储和提取</strong>。其架构模式是插件式的，支持<code>InnoDB</code>、MyISAM、Memory等多个存储引擎。现在最常用的存储引擎是 InnoDB，它从MySQL 5.5.5版本开始成为了默认存储引擎。不同的存储引擎共用一个<strong>Server层</strong>，也就是从连接器到执行器的部分。</li></ol><h2 id="连接器"><a href="#连接器" class="headerlink" title="连接器"></a>连接器</h2><p>第一步，你会先连接到这个数据库上，这时候接待你的就是连接器。连接器负责跟客户端<strong>建立连接</strong>、<strong>获取权限</strong>、<strong>维持和管理连接</strong>。</p><p>连接命令一般是这么写的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql -h$ip -P$port -u$user -p</span><br></pre></td></tr></table></figure><p>输完命令之后，你就需要在交互对话里面输入密码。虽然密码也可以直接跟在-p后面写在命令行中，但这样可能会导致你的密码泄露。如果你连的是生产服务器，强烈建议你不要这么做。</p><p>连接命令中的mysql是客户端工具，用来跟服务端建立连接。在完成经典的TCP握手后，连接器就要开始认证你的身份，这个时候用的就是你输入的用户名和密码。</p><ul><li>如果用户名或密码不对，你就会收到一个”Access denied for user”的错误，然后客户端程序结束执行。</li><li>如果用户名密码认证通过，<strong>连接器会到权限表里面查出你拥有的权限</strong>。之后，这个连接里面的权限判断逻辑，都将依赖于此时读到的权限。</li></ul><p>这就意味着，一个用户成功建立连接后，即使你用管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限。修改完成后，<strong>只有再新建的连接才会使用新的权限设置</strong>。</p><p>连接完成后，如果你没有后续的动作，这个连接就处于空闲状态，你可以在 <code>show processlist</code> 命令中看到它。</p><p>文本中这个图是 <code>show pocesslist</code> 的结果，其中的<code>Command</code>列显示为“<strong>Sleep</strong>”的这一行，就表示现在系统里面有一个空闲连接。</p><img src="image-20210127222851964.png" alt="image-20210127222851964"  /><p>客户端如果太长时间没动静，连接器就会自动将它断开。这个时间是由参数 <strong>wait_timeout</strong> 控制的，默认值是8小时。</p><p>如果在连接被断开之后，客户端再次发送请求的话，就会收到一个错误提醒： <code>Lost connection to MySQL server during query</code>。这时候如果你要继续，就需要重连，然后再执行请求了。</p><p>数据库里面，<strong>长连接</strong>是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。<strong>短连接</strong>则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。建立连接的过程通常是比较复杂的，所以我建议你在使用中要尽量减少建立连接的动作，也就是<strong>尽量使用长连接</strong>。</p><p>但是全部使用长连接后，你可能会发现，有些时候MySQL占用内存涨得特别快，这是因为 <strong>MySQL在执行过程中临时使用的内存是管理在连接对象里面的</strong>。这些资源会在连接断开的时候才释放。所以如果长连接累积下来，可能导致内存占用太大，被系统强行杀掉（OOM），从现象看就是MySQL异常重启了。</p><p>  怎么解决这个问题呢？你可以考虑以下两种方案。</p><ol><li><strong>定期断开长连接</strong>。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。</li><li>如果你用的是MySQL 5.7或更新版本，可以在每次执行一个比较大的操作后，通过执行 <code>mysql_reset_connection</code>来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。</li></ol><h2 id="查询缓存"><a href="#查询缓存" class="headerlink" title="查询缓存"></a>查询缓存</h2><p>MySQL拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以key-value对的形式，被直接缓存在内存中。key是查询的语句，value是查询的结果。如果你的查询能够直接在这个缓存中找到key，那么这个value就会被直接返回给客户端。</p><p>如果语句不在查询缓存中，就会继续后面的执行阶段。执行完成后，执行结果会被存入查询缓存中。你可以看到，如果查询命中缓存，MySQL不需要执行后面的复杂操作，就可以直接返回结果，这个效率会很高。</p><p><strong>建议你不要使用查询缓存</strong>，为什么呢？<strong>因为查询缓存往往弊大于利。</strong>查询缓存的<strong>失效非常频繁</strong>，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。因此很可能你费劲地把结果存起来，还没使用呢，就被一个更新全清空了。        </p><p>对于更新压力大的数据库来说，查询缓存的命中率会非常低。除非你的业务就是有一张静态表，很长时间才会更新一次。比如，一个系统配置表，那这张表上的查询才适合使用查询缓存。</p><p>MySQL 8.0版本直接将查询缓存的整块功能删掉了，也就是说8.0开始彻底没有这个功能了。</p><h2 id="分析器"><a href="#分析器" class="headerlink" title="分析器"></a>分析器</h2><p> <strong>词法分析</strong> : 你输入的是由多个字符串和空格组成的一条SQL语句，MySQL需要识别出里面的字符串分别是什么，代表什么。MySQL从你输入的”select”这个关键字识别出来，这是一个查询语句。它也要把字符串“T”识别成“表名T”，把字符串“ID”识别成“列ID”。</p><p> <strong>语法分析</strong>： 根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个SQL语句是否满足MySQL语法。如果你的语句不对，就会收到 <code>You have an error in your SQL syntax</code> 的错误提醒，比如下面这个语句select少打了开头的字母“s”。一般语法错误会提示第一个出现错误的位置，所以你要关注的是紧接“use near”的内容。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; elect * from t where ID&#x3D;1;</span><br><span class="line"></span><br><span class="line">ERROR 1064 (42000): You have an error in your SQL syntax; </span><br><span class="line">check the manual that corresponds to your MySQL server version </span><br><span class="line">for the right syntax to use near &#39;elect * from t where ID&#x3D;1&#39; at line 1</span><br></pre></td></tr></table></figure><h2 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h2><p>经过了分析器，MySQL就知道你要做什么了。在开始执行之前，还要先经过优化器的处理。</p><p>优化器是在表里面有多个索引的时候，<strong>决定使用哪个索引</strong>；或者在一个语句有多表关联（join）的时候，<strong>决定各个表的连接顺序</strong>。</p><p>比如你执行下面这样的语句，这个语句是执行两个表的join：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t1 <span class="keyword">join</span> t2 <span class="keyword">using</span>(ID) <span class="keyword">where</span> t1.c<span class="operator">=</span><span class="number">10</span> <span class="keyword">and</span> t2.d<span class="operator">=</span><span class="number">20</span>;</span><br></pre></td></tr></table></figure><ul><li>既可以先从表t1里面取出c=10的记录的ID值，再根据ID值关联到表t2，再判断t2里面d的值是否等于20。</li><li>也可以先从表t2里面取出d=20的记录的ID值，再根据ID值关联到t1，再判断t1里面c的值是否等于10。</li></ul><p>这两种执行方法的逻辑结果是一样的，但是执行的效率会有不同，而优化器的作用就是决定选择使用哪一个方案。优化器阶段完成后，这个语句的执行方案就确定下来了，然后进入执行器阶段。</p><h2 id="执行器"><a href="#执行器" class="headerlink" title="执行器"></a>执行器</h2><p>开始执行的时候，要先判断一下你对这个表T有没有执行查询的<strong>权限</strong>，如果没有，就会返回没有权限的错误，如下所示</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> T <span class="keyword">where</span> ID<span class="operator">=</span><span class="number">10</span>; </span><br><span class="line">ERROR <span class="number">1142</span> (<span class="number">42000</span>): <span class="keyword">SELECT</span> command denied <span class="keyword">to</span> <span class="keyword">user</span> <span class="string">&#x27;b&#x27;</span>@<span class="string">&#x27;localhost&#x27;</span> <span class="keyword">for</span> <span class="keyword">table</span> <span class="string">&#x27;T&#x27;</span></span><br></pre></td></tr></table></figure><p>如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。</p><p>比如我们这个例子中的表T中，ID字段没有索引，那么执行器的执行流程是这样的：</p><ol><li>调用InnoDB引擎接口取这个表的第一行，判断ID值是不是10，如果不是则跳过，如果是则将这行存在结果集中；</li><li>调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。</li><li>执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。</li></ol><p>对于有索引的表，执行的逻辑也差不多。第一次调用的是“<strong>取满足条件的第一行</strong>”这个接口，之后循环取“<strong>满足条件的下一行</strong>”这个接口，这些接口都是引擎中已经定义好的。</p><p>你会在数据库的慢查询日志中看到一个 <code>rows_examined</code> 的字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此<strong>引擎扫描行数跟rows_examined并不是完全相同的。</strong></p><h2 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a>思考题</h2><p>如果表T中没有字段k，而你执行了这个语句 select * from T where k=1, 那肯定是会报“不存在这个列”的错误： “Unknown column ‘k’ in ‘where clause’”。</p><p>你觉得这个错误是在我们上面提到的哪个阶段报出来的呢？</p>]]></content>
    
    
    <summary type="html">MySQL</summary>
    
    
    
    <category term="MySQL实战" scheme="http://universeinheart.github.io/categories/MySQL%E5%AE%9E%E6%88%98/"/>
    
    
    <category term="MySQL" scheme="http://universeinheart.github.io/tags/MySQL/"/>
    
  </entry>
  
</feed>
